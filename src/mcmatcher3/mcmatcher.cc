/*********************************************************************/
/*                                                                   */
/* FILE         mcmatcher.cc                                         */
/* AUTHORS      Bastian Leibe                                        */
/* EMAIL        leibe@vision.ee.ethz.ch                              */
/*                                                                   */
/* CONTENT      Interleaved Object Categorization and Segmentation   */
/*              with an Implicit Shape Model.                        */
/*              The program performs simultaneous recognition and    */
/*              segmentation of canonical views of categorical ob-   */
/*              jects, such as sideviews of cars or cows. Prior to   */
/*              recognition, a codebook of local appearance must be  */
/*              generated by the 'clusterer' program. This version   */
/*              of the code currently just handles objects at a      */
/*              single scale.                                        */
/*                                                                   */
/*              Extended version for multi-cue recognition.          */
/*                                                                   */
/*              An explanation of the algorithm can be found in the  */
/*              following papers:                                    */
/*                                                                   */
/*              Bastian Leibe and Bernt Schiele,                     */
/*              Interleaved Object Categorization and Segmentation.  */
/*              In Proc. British Machine Vision Conference (BMVC'03) */
/*              Norwich, GB, Sept. 9-11, 2003.                       */
/*                                                                   */
/*              Bastian Leibe and Bernt Schiele,                     */
/*              Combined Object Categorization and Segmentation with */
/*              an Implicit Shape Model.                             */
/*              submitted to ECCV'04 Workshop on Statistical Lear-   */
/*              ning in Computer Vision, Prague, May 2004.           */
/*                                                                   */
/* BEGIN        Tue Nov 05 2002                                      */
/* LAST CHANGE  Tue Oct 11 2005                                      */
/*                                                                   */
/*********************************************************************/


/****************/
/*   Includes   */
/****************/
#include <iostream>
#include <iomanip>
#include <math.h>
#include <stdlib.h>
#include <string>
#include <algorithm>

#include <qapplication.h>
#include <qfiledialog.h>
#include <qcolor.h>
#include <qpainter.h>
#include <qstring.h>
#include <qstringlist.h>
#include <qinputdialog.h>
#include <qbuttongroup.h>

#include <qtmacros.hh>
#include <qtcoordlabel.hh>
#include <qtimgbrowser.hh>
#include <opgrayimage.hh>

#include <resources.hh>
#include <oprgbimage.hh>
#include <opharrisimage.hh>
#include <featurevector.hh>
#include <pyramidscalespace.hh>
#include <visualhistogram.hh>
#include <pca.hh>
#include <featurematrix.hh>
#include <dogscalespace.hh>
#include <edgesift.hh>
#include <Candidate.h>
#include <chamfermatching.h>
#include <occurrences.hh>
#include <detectorgui.hh>
#include <detectorwidget.hh>
#include <detector.hh>

#include "unixtools.hh"
#include "mcmatcher.hh"


/*******************/
/*   Definitions   */
/*******************/


#define SSLEVEL              4   // depth of pyramid scale space
#define SSMINSIZE            9   // minimal size of image patch


/*===================================================================*/
/*                         Class ISMReco                           */
/*===================================================================*/

/***********************************************************/
/*                          Slots                          */
/***********************************************************/

/*---------------------------------------------------------*/
/*                     Loading Images                      */
/*---------------------------------------------------------*/

void ISMReco::loadImage()
  /*******************************************************************/
  /* Load a new test image.                                          */
  /*******************************************************************/
{
  m_qsLastImage = QFileDialog::getOpenFileName( m_qsLastImage, 
					      "Images (*.png *.xpm *.jpg *.ppm);;all files (*.*)",
                 this);
  if ( m_qsLastImage.isEmpty() )
    return;

  loadImage( m_qsLastImage );
}


void ISMReco::loadImage( QString qsFileName )
  /*******************************************************************/
  /* Load a new test image (including its segmentation mask, if one  */
  /* exists).                                                        */
  /*******************************************************************/
{
  if( m_bShowTxtSteps )
    cout << "  Loading image '" << qsFileName << "'..." << endl;
  m_img.load( qsFileName );

  /*--------------------------------*/
  /* store image name (abbreviated) */
  /*--------------------------------*/
  unsigned pos;
  string tmpstr( qsFileName.latin1() );
  if ( ( pos = tmpstr.rfind( "/" )) != string::npos ) {
    //if ( tmpstr.at(pos+3) != string::npos )
    if ( pos+3 < tmpstr.length() )
      tmpstr = tmpstr.substr( pos+1, 3);
    else
      tmpstr = "Img";
  }
  else
    tmpstr = "Img";
  m_sImgNameShort = tmpstr;
  
  /*-----------------------*/
  /* store long image name */
  /*-----------------------*/
  string sFileName( qsFileName.latin1() );
  int    len  = (int)sFileName.length();
  int    pos1 = (int)sFileName.rfind("/");
  int    pos2 = (int)sFileName.rfind("/", pos1-1);
  m_sImgName = "";
  m_sImgPath = "";
  m_sImgFullName = sFileName;
  if( pos1 != (int)string::npos ) {
    m_sImgName = sFileName.substr( pos1+1, len-pos1 );
    if( pos2 != (int)string::npos )
      m_sImgPath = sFileName.substr( pos2+1, pos1-pos2-1 );
  }

  string sNoExtension( m_sImgName );
  int pos3 = (int)sNoExtension.rfind(".");
  sNoExtension = sNoExtension.substr( 0, pos3 ); 

  /*-----------------------------------------------------*/
  /* if possible load the corresponding segmentation map */
  /*-----------------------------------------------------*/
  QString qsMapName( qsFileName );
  int posDir = qsMapName.findRev( '/' );
  QString qsCurrentDir = qsMapName.left( posDir+1 );
  qsMapName = qsMapName.right( qsMapName.length() - posDir - 1 );
  QString qsMapDir = qsCurrentDir + "maps/";
  posDir = qsMapName.findRev( '.' );
  if ( posDir >= 0 ) 
    qsMapName = qsMapName.left( posDir );
  qsMapName = qsMapName + "-map.png";

  QFile fMapFile( qsMapDir+qsMapName );
  if( m_bShowTxtDetails )
    cout << "    Searching for file '" << qsMapDir+qsMapName << "'..." << endl;
  if ( fMapFile.exists() == false ) {
    if( m_bShowTxtDetails )
      cout << "    No corresponding segmentation map found." << endl;
    m_bMapsOn = false;
    OpGrayImage imgEmpty( m_grayImg.width(), m_grayImg.height() );
    m_grayImgMap = imgEmpty;
  }
  else {
    if( m_bShowTxtDetails )
      cout << "    Corresponding segmentation map found." << endl;
    m_bMapsOn = true;
    QImage imgMap;
    imgMap.load( qsMapDir+qsMapName );
    OpGrayImage grayImgMap( imgMap );
    m_grayImgMap = grayImgMap;

    /* compute the segmentation area */
    float dArea = m_grayImgMap.getSum()/255.0;
    if( m_bShowTxtDetails )
      cout << "      (area: " << dArea << " pixels)." << endl;
  }
   
  /*------------------------------------------------------*/
  /* if possible, load the corresponding calibration file */
  /*------------------------------------------------------*/
  QString qsCalibName( sNoExtension.c_str() );
  int nImgNumber = max( atoi( qsCalibName.right(5).latin1() ),
                        atoi( qsCalibName.right(7).latin1() ));
  if( m_nGPFrame==GP_PREVIOUS )
    nImgNumber -= 2;
  qsCalibName = qsCalibName.sprintf( "camera.%05d", nImgNumber );

  m_calCamera.clear();
  m_bCalibAvailable = false;
  QFile fCalibFile( qsMapDir+qsCalibName );
  if( m_bShowTxtDetails )
    cout << "    Searching for file '" << qsMapDir+qsCalibName 
         << "'..." << endl;
  if( fCalibFile.exists() ) {
    if( m_bShowTxtDetails )
      cout << "    Camera calibration file found." << endl;
    if( m_calCamera.load( qsMapDir+qsCalibName ) ) {
      if( m_bShowTxtSteps )
        m_calCamera.print();
      m_bCalibAvailable = true;
      
      /* rescale the world to m units and set the correct image scale */
      m_calCamera.setWorldScale( m_dWorldScale ); //DEF_WORLD_SCALE );
      m_calCamera.setImgScale  ( m_dImgScale );   //DEF_IMAGE_SCALE ); 
    }

  } else {

    // not found => try loading a default calibration file
    if( m_bShowTxtDetails )
      cout << "    Not found. Trying default calibration file..." << endl;

    QString qsDefaultName = qsMapDir+"camera.default";
    QFile fDefaultFile( qsDefaultName );
    if( fDefaultFile.exists() ) {
      if( m_bShowTxtDetails )
        cout << "    Default calibration file found." << endl;
      if( m_calCamera.load( qsDefaultName ) ) {
        m_calCamera.print();
        m_bCalibAvailable = true;
        
        /* rescale the world to m units and set the correct image scale */
        m_calCamera.setWorldScale( m_dWorldScale ); //DEF_WORLD_SCALE );
        m_calCamera.setImgScale  ( m_dImgScale );   //DEF_IMAGE_SCALE ); 
      }
    }

  }

  /*----------------------------------*/
  /* convert to OpGrayImage structure */
  /*----------------------------------*/
  OpGrayImage grayImg( m_img );

  if( m_bBetterGrayConv ) {
    if( m_bShowTxtDetails )
      cout << "    using better RGB->gray conversion formula..." << endl;
    /* use better conversion formula */
    OpRGBImage  rgbImg ( m_img );
    for( int y=0; y<rgbImg.height(); y++ )
      for( int x=0; x<rgbImg.width(); x++ )
        grayImg(x,y) = ( 0.3*rgbImg(x,y).red() + 0.59*rgbImg(x,y).green() + 
                         0.11*rgbImg(x,y).blue() );
  }

  /* convert back to QImage structure */
  m_qsourceImg = grayImg.getQtImage();
  m_grayImg = grayImg;

  /* display */
  rsSourceImg->loadImage( m_qsourceImg, grayImg );
  rsSourceImg->display();

  /* create an empty result image */
  OpGrayImage imgBlack( m_img.width(), m_img.height() );
  m_resultImg = imgBlack;
  m_qresultImg = m_resultImg.getQtImage();
  rsResultImg->loadImage( m_qresultImg, m_resultImg );
  rsResultImg->display();

  /* draw the ground plane visualization */
  drawGroundPlane();

  if( m_bShowTxtDetails )
    cout << "  done." << endl;
}


void ISMReco::showResultImg( int dummy1, int dummy2 )
{
  showResultImg();
}


void ISMReco::showResultImg()
{
  vector<QImage>      vQImgs;
  vector<OpGrayImage> vImgs;
  vQImgs.push_back( rsSourceImg->getImage() );
  vImgs.push_back( m_grayImg );
  vQImgs.push_back( rsResultImg->getImage() );
  vImgs.push_back( m_resultImg );

  if( m_bShowGUI ) {
    QtImgBrowser *qtResultBrowser = new QtImgBrowser( 0, "result" );
    qtResultBrowser->setGeometry( 400, 200, 
                                  max(100,m_grayImg.width()), 
                                  max(100,m_grayImg.height()) );
    qtResultBrowser->load( vQImgs, vImgs );
    qtResultBrowser->show();
  }
}


/*---------------------------------------------------------*/
/*                 Loading/Adding Detectors                */
/*---------------------------------------------------------*/

void ISMReco::addDetector()
{
  addDetector("");
}


void ISMReco::addDetector( QString sDetFile, bool bVerbose )
{
  unsigned nNewIdx = m_tblDetectors->numRows();

  assert( m_vDetectors.size()==nNewIdx );

  /*----------------------------------*/
  /* Prepare a widget for the new cue */
  /*----------------------------------*/
  DetectorGUI    *guiDetect = NULL;
  RecoGUI        *guiReco   = NULL;
  DetectorWidget *dwDetect  = new DetectorWidget( guiDetect, guiReco, 
                                                  NULL, "det1" );

  dwDetect->setCaption( "Detector " + QString::number(nNewIdx+1) );
  dwDetect->hide();

  /* add a new gui window */
  m_vpDetectorWindows.push_back( dwDetect );

  /* propagate update events from the cue gui */
  connect( dwDetect, SIGNAL(sigCuesChanged()), 
           this, SLOT(collectCueInformation()) );

  /*-----------------*/
  /* Add new objects */
  /*-----------------*/
  /* add a new Detector object */
  m_vDetectors.push_back( Detector() );
  m_vDetectors[nNewIdx].setGUI( guiDetect );

  /* add the new reco parameters */
  m_vParReco.push_back( RecoParams() );
  m_vParReco[nNewIdx].setGUI( guiReco );
  m_vDetectors[nNewIdx].setRecoParams( m_vParReco[nNewIdx] );
  // set the dummy recognition parameters to those of the last detector
  // (those aren't used anyway, they're just needed to initialize the ISM)
  m_parReco = m_vParReco[nNewIdx];

  /* set the bbox color */
  int colidx = nNewIdx % NUM_COLORS;
  guiDetect->m_qcColor     = COL_DETECTION[colidx];
  guiDetect->m_qsColorName = COL_COLORNAME[colidx];

  /*------------------------------*/
  /* Extract detector information */
  /*------------------------------*/
  string sCategory = guiDetect->m_qsCategName;
  string sPose     = guiDetect->m_qsPoseName;
  string sFlipped  = "";
  if( guiDetect->m_bProcessBothDir )
    sFlipped = "X";
  string sThresh   = QString::number(guiReco->m_dScoreThreshSingle,'f',2);
  string sColor    = guiDetect->m_qsColorName;

  /*-------------------------------*/
  /* Add an entry to the cue table */
  /*-------------------------------*/
  addDetectorTableEntry( sCategory, sPose, sFlipped, sThresh, sColor );
  ((QButtonGroup*)m_tblDetectors->parent())->adjustSize();

  /*-----------------------------*/
  /* Update the member variables */
  /*-----------------------------*/
  m_nNumDetectors = nNewIdx+1;

  /*-------------------------*/
  /* Initialize the detector */
  /*-------------------------*/
  /* set the default paths */
  m_vDetectors[nNewIdx].setDefaultDirs( DIR_CODEBOOKS, DIR_RESULTS );
  guiDetect->setDefaultDir( DIR_CODEBOOKS );

  /* connect the detector to the list of active codebooks */
  m_vDetectors[nNewIdx].setActiveCBList   ( &m_mActiveCBs );
  m_vDetectors[nNewIdx].setActiveMatchList( &m_mActiveMatches, 
                                            &m_mActiveMatchesL );

  /* connect the detector to the widget */
  connect( dwDetect, SIGNAL(sigLoadDetectorClicked()),
           &(m_vDetectors[nNewIdx]), SLOT(loadDetector()) );
  connect( dwDetect, SIGNAL(sigSaveDetectorClicked()),
           &(m_vDetectors[nNewIdx]), SLOT(saveDetector()) );
  connect( dwDetect, SIGNAL(sigClearDetectorClicked()),
           &(m_vDetectors[nNewIdx]), SLOT(clearDetector()) );

  /* connect the detector to the gui */
  connect( &(m_vDetectors[nNewIdx]), 
           SIGNAL(sigDrawHypothesis(const Hypothesis&, const QColor&, bool)),
           this, SLOT(drawHypothesis(const Hypothesis&,const QColor&,bool)) );
  connect( &(m_vDetectors[nNewIdx]), SIGNAL(sigRefreshSrcImg()),
           this, SLOT(refreshSrcImg()) );
  connect( &(m_vDetectors[nNewIdx]), 
           SIGNAL(sigDisplayResultImg(const QImage&)),
           this, SLOT(displayResultImg(const QImage&)) );
  connect( &(m_vDetectors[nNewIdx]), 
           SIGNAL(sigDisplayResultImg(const QImage&, OpGrayImage)),
           this, SLOT(displayResultImg(const QImage&, OpGrayImage)) );
  
  /* make sure that the cues are updated after each user interaction */
  connect( &(m_vDetectors[nNewIdx]), SIGNAL(sigCuesChanged()),
           this, SLOT(collectCueInformation()) );
  //connect( m_vDetectors[nNewIdx].params(), SIGNAL(sigCuesChanged()),
  //         this, SLOT(collectCueInformation()) );  

  /* make sure that the detectors are also updated */
  connect( &(m_vDetectors[nNewIdx]), SIGNAL(sigDetectorChanged()),
           this, SLOT(updateDetectorTable()) );

//   /* make sure that the detectors are also updated */
//   connect( &(m_vDetectors[nNewIdx]), SIGNAL(sigDetectorLoaded()),
//            this, SLOT(updateMDLSettings()) );

  /*---------------------*/
  /* Show the cue window */
  /*---------------------*/
  if( m_bShowGUI )
    m_vpDetectorWindows[nNewIdx]->show();

  /*------------------------*/
  /* Load the detector file */
  /*------------------------*/
  if( !sDetFile.isEmpty() ) {
    m_vDetectors[nNewIdx].loadDetector( sDetFile.latin1(), bVerbose );
  }
}


void ISMReco::detectorTableClicked( int nRow, int nCol, int button, 
                                    const QPoint& mousePos )
{
  showDetectorWindow( nRow );
}


void ISMReco::showDetectorWindow( int nIdx )
{
  if( nIdx<0 || nIdx>=(int)m_vpDetectorWindows.size() )
    return;
  
  if( m_bShowGUI )
    m_vpDetectorWindows[nIdx]->show();
}


void ISMReco::addDetectorTableEntry( string sCategory, string sPose,
                                     string sFlipped,
                                     string sThresh, string sColor )
{
  unsigned nNewIdx = m_tblDetectors->numRows();
  m_tblDetectors->setNumRows( nNewIdx+1 );
  m_tblDetectors->setText( nNewIdx, 0, sCategory );
  m_tblDetectors->setText( nNewIdx, 1, sPose );
  m_tblDetectors->setText( nNewIdx, 2, sFlipped );
  m_tblDetectors->setText( nNewIdx, 3, sThresh );
  m_tblDetectors->setText( nNewIdx, 4, sColor );
}


void ISMReco::updateDetectorTable()
{
  /* clear the detector table */
  m_tblDetectors->setNumRows( 0 );
  
  float dMinDetPFig       = 10000; //m_dMinPFig;
  float dMinDetWeightPFig = 1.0; //m_dWeightPFig;
  for(unsigned k=0; k<m_nNumDetectors; k++ ) {
    DetectorGUI *guiDetect = m_vDetectors[k].params();
    RecoGUI     *guiReco   = m_vParReco[k].params();

    /* Extract detector information */
    string sCategory = guiDetect->m_qsCategName;
    string sPose     = guiDetect->m_qsPoseName;
    string sFlipped  = "";
    if( guiDetect->m_bProcessBothDir )
      sFlipped = "X";
    string sThresh   = QString::number(guiReco->m_dScoreThreshSingle,'f',2);
    string sColor    = guiDetect->m_qsColorName;
    
    /* Extract information for MDL stage */
    float dDetPFig       = guiReco->m_dMinPFig / guiDetect->m_dAreaFactor;
    float dDetWeightPFig = guiReco->m_dWeightPFig;
    if( dDetPFig<dMinDetPFig ) 
      dMinDetPFig = dDetPFig;
    if( dDetWeightPFig<dMinDetWeightPFig )
      dMinDetWeightPFig = dDetWeightPFig;

    /* Add an entry to the cue table */
    addDetectorTableEntry( sCategory, sPose, sFlipped, sThresh, sColor );
  }

  /* Update the MDL stage fields */
  m_dMinPFig    = dMinDetPFig;        slotUpdateMinPFig();
  m_dWeightPFig = dMinDetWeightPFig;  slotUpdateWeightPFig();
  qApp->processEvents();
}


/*---------------------------------------------------------*/
/*                   Loading/Adding Cues                   */
/*---------------------------------------------------------*/

void ISMReco::cueTableClicked( int nRow, int nCol, int button, 
                                   const QPoint& mousePos )
{
  showCueWindow( nRow );
}


void ISMReco::showCueWindow( int nIdx )
{
  if( nIdx<0 || nIdx>=(int)m_vpCueWindows.size() )
    return;
  
  if( m_bShowGUI )
    m_vpCueWindows[nIdx]->show();
}


void ISMReco::addCueTableEntry( string sDetector, string sFeature, 
                                string sFlipped,
                                string sNumCl, string sNumOcc )
{
  unsigned nNewIdx = m_tblCues->numRows();
  updateCueTableEntry( nNewIdx, sDetector, sFeature, sFlipped, 
                       sNumCl, sNumOcc );
}


void ISMReco::updateCueTableEntry( unsigned nIdx, string sDetector, 
                                   string sFeature, string sFlipped,
                                   string sNumCl, string sNumOcc )
{
  if( (int)nIdx>=m_tblCues->numRows() )
    m_tblCues->setNumRows( nIdx+1 );
  m_tblCues->setText( nIdx, 0, sDetector );
  m_tblCues->setText( nIdx, 1, sFeature );
  m_tblCues->setText( nIdx, 2, sFlipped );
  m_tblCues->setText( nIdx, 3, sNumCl );
  m_tblCues->setText( nIdx, 4, sNumOcc );  
}


/*---------------------------------------------------------*/
/*                    Extracting Patches                   */
/*---------------------------------------------------------*/

void ISMReco::collectCueInformation()
  /*******************************************************************/
  /* Collect cue information from all available detectors, so that   */
  /* the basic features need to be extracted only once.              */
  /*******************************************************************/
{
  //cout << "    Updating cue information... " << flush;
  /* clear the global cue information */
  m_nNumCues = 0;
  m_vCues.clear();
  m_vProcessBothDir.clear();

  /* clear the per-detector cue index */
  m_vvCueIdx.clear();

  /* clear the cue table */
  m_tblCues->setNumRows( 0 );
  m_vpCueWindows.clear();

  /* clear the intpt/feature storage */
  m_vvPointsInside.clear();
  m_vvPointsInsideLeft.clear();

  m_vvFeatures.clear();
  m_vvFeaturesLeft.clear();

  /* process all detectors */
  for(unsigned k=0; k<m_nNumDetectors; k++ ) {
    //cout << "    Checking detector " << k+1 << "/" << m_nNumDetectors 
    //     << "..." << endl;
    vector<int> vTmp;
    m_vvCueIdx.push_back( vTmp );

    /* look at all cues from detector k */
    for(unsigned j=0; j<m_vDetectors[k].m_nNumCues; j++ ) {
      //cout << "      Checking cue " << j+1 << "/" 
      //     << m_vDetectors[k].m_nNumCues << "..." << endl;
      FeatureCue &fcCue = m_vDetectors[k].m_vCues[j];

      /* check if this cue is already included in the list */
      int idx = -1;
      for(unsigned i=0; i<m_nNumCues && idx<0; i++ )
        if( (fcCue.params()->m_nPatchExtMethod ==
             m_vCues[i].params()->m_nPatchExtMethod) && 
            (fcCue.params()->m_nFeatureType ==
             m_vCues[i].params()->m_nFeatureType) )
          idx = i;

      if( idx<0 ) {
        /*-------------------------------*/
        /* New cue => add it to the list */
        /*-------------------------------*/
        bool bProcessBothDir = m_vDetectors[k].params()->m_bProcessBothDir;
        m_vProcessBothDir.push_back( bProcessBothDir );
        m_vCues.push_back( fcCue );
        m_nNumCues++;

        /* set the cue index */
        m_vvCueIdx[k].push_back( m_nNumCues-1 );

        /* add the gui window */
        m_vpCueWindows.push_back( m_vDetectors[k].params()->m_vpCueWindows[j]);
        
        /* add an entry to the cue table */
        FeatureGUI *guiCue = m_vCues[m_nNumCues-1].params();
        string sDetector= NAMES_PATCHEXT[guiCue->m_nPatchExtMethod];
        string sFeature = NAMES_FEATURE [guiCue->m_nFeatureType];
        string sFlipped = "";
        if( bProcessBothDir )
          sFlipped = "X";
        string sMinScale= QString::number(guiCue->m_dMinScale,'f',1).latin1();
        string sMaxScale= QString::number(guiCue->m_dMaxScale,'f',1).latin1();
        addCueTableEntry( sDetector, sFeature, sFlipped,
                          sMinScale, sMaxScale );

        /* add an entry to the intpt/feature storage */
        PointVector vTmp;
        m_vvPointsInside.push_back( vTmp );
        m_vvPointsInsideLeft.push_back( vTmp );

        vector<FeatureVector> vTmp2;
        m_vvFeatures.push_back( vTmp2 );
        m_vvFeaturesLeft.push_back( vTmp2 );

      } else {
        /*------------------------------------*/
        /* Known cue => adapt the scale range */
        /*------------------------------------*/
        float dMinScale1 = m_vCues[idx].params()->m_dMinScale;
        float dMaxScale1 = m_vCues[idx].params()->m_dMaxScale;
        float dMinScale2 = fcCue.params()->m_dMinScale;
        float dMaxScale2 = fcCue.params()->m_dMaxScale;
        m_vCues[idx].params()->slotSetMinScale(QString::number(min(dMinScale1,
                                                                   dMinScale2),
                                                               'f',1) );
        m_vCues[idx].params()->slotSetMaxScale(QString::number(max(dMaxScale1,
                                                                   dMaxScale2),
                                                               'f',1) );

        /* adapt the 'ProcessBothDir' flag */
        m_vProcessBothDir[idx] = (m_vProcessBothDir[idx] ||
                                  m_vDetectors[k].params()->m_bProcessBothDir);
        
        /* set the cue index */
        m_vvCueIdx[k].push_back( idx );

        /* update the cue table entry */
        FeatureGUI *guiCue = m_vCues[idx].params();
        string sDetector= NAMES_PATCHEXT[guiCue->m_nPatchExtMethod];
        string sFeature = NAMES_FEATURE [guiCue->m_nFeatureType];
        string sFlipped = "";
        if( m_vProcessBothDir[idx] )
          sFlipped = "X";
        string sMinScale= QString::number(guiCue->m_dMinScale,'f',1).latin1();
        string sMaxScale= QString::number(guiCue->m_dMaxScale,'f',1).latin1();
        updateCueTableEntry( idx, sDetector, sFeature, sFlipped, 
                             sMinScale, sMaxScale );
      } // end if
    } // end forall cues of detector k
  } // end forall detectors

  /* Initialize the intpt/feature storage */
  for(unsigned k=0; k<m_nNumCues; k++ ) {
    m_vvPointsInside[k].clear();
    m_vvFeatures[k].clear();

    m_vvPointsInsideLeft[k].clear();
    m_vvFeaturesLeft[k].clear();
 }

  //cout << "done." << endl;
}


void ISMReco::processImage( QString qsFileName )
  /*******************************************************************/
  /* Process a new image, i.e. load it and extract patches using the */
  /* methods selected in the used interface. The extracted patches   */
  /* are then stored in m_vImagePatches.                             */
  /*******************************************************************/
{
  loadImage( qsFileName );
  qApp->processEvents(); // finish drawing

  /* save original image */
  OpGrayImage imgOriginal( m_grayImg );
  /* perform histogram equalization */
  if( m_bPerformGammaNorm ) {
    if( m_bShowTxtSteps )
      cout << "  Performing gamma normalization..." << endl;
    m_grayImg = m_grayImg.opHistEq();
    for(int y=0; y<m_grayImg.height(); y++ )
      for(int x=0; x<m_grayImg.width(); x++ )
        m_grayImg(x,y) = sqrt(m_grayImg(x,y).value());
  }

  collectPatches( true );
  qApp->processEvents();

  /* restore original image */
  if( m_bPerformGammaNorm )
    m_grayImg = imgOriginal;
}


void ISMReco::collectPatches( bool process )
  /*******************************************************************/
  /* Collect patches from the current image, either by uniform sam-  */
  /* pling, or by applying an interest point detector.               */
  /*******************************************************************/
{
  for(unsigned k=0; k<m_nNumCues; k++ ) {
    /* process the original image */
    m_vCues[k].processImage( m_sImgFullName, m_grayImg, m_grayImgMap, m_img, 
                             m_vCues[k].params()->m_nFeatureType,
                             m_vPoints, m_vvPointsInside[k], 
                             m_vImagePatches, m_vvFeatures[k],
                             m_bShowTxtDetails );
    
    if( m_vProcessBothDir[k] ) {
      /* process the flipped image */
      //OpGrayImage imgLeft    = m_grayImg.flipHorizontal();
      //OpGrayImage imgMapLeft = m_grayImgMap.flipHorizontal();
      //vector<OpGrayImage> vImgPatchesLeft;
      //PointVector         vPoints;
      //m_vCues[k].processImage( m_sImgFullName, imgLeft, imgMapLeft, 
      //                         imgLeft.getQtImage(), 
      //                         m_vCues[k].params()->m_nFeatureType,
      //                         vPoints, m_vvPointsInsideLeft[k], 
      //                         vImgPatchesLeft, m_vvFeaturesLeft[k] );
      m_vCues[k].getMirroredFeatures( m_grayImg, m_grayImgMap, 
                                      m_vvPointsInside[k], 
                                      m_vvFeatures[k],
                                      m_vvPointsInsideLeft[k], 
                                      m_vvFeaturesLeft[k] );
    }
    m_vPoints = m_vvPointsInside[k];

    if( m_bShowIntPts ) {
      if( m_bShowTxtDetails )
        cout << "  Drawing interest points..." << endl;
      drawInterestPointsEllipse( m_vCues[k].params()->m_dScaleFactor );
      qApp->processEvents();
    }
    
    /*------------------------*/
    /* Normalize the features */
    /*------------------------*/
    if( m_bShowTxtDetails )
      cout << "  Normalizing the features..." << endl;
    m_cbCodebook.normalizeFeatures( m_vvFeatures[k], 
                                    m_vCues[k].params()->m_nFeatureType );
    if( m_vProcessBothDir[k] )
      m_cbCodebook.normalizeFeatures( m_vvFeaturesLeft[k], 
                                      m_vCues[k].params()->m_nFeatureType );
  }
  if( m_bShowTxtDetails )
    cout << "  done." << endl;

  if (!process)
    displayPatchesForBrowsing(m_vImagePatches);
  qApp->processEvents();
}


void ISMReco::drawInterestPoints()
  /*******************************************************************/
  /* Draw the interest points returned by the Int.Pt. detector.      */
  /*******************************************************************/
{
  if ( m_vPoints.empty() ) 
    return;

  // display original image first (clean any drawings)
  rsSourceImg->display();
  for(unsigned i=0; i < m_vPoints.size(); i++) {
    rsSourceImg->drawCross( m_vPoints[i].x, m_vPoints[i].y, 
                            QColor::QColor(255,255,0), OVERDRAW_IMG );
    if( m_vPoints[i].scale > 1.0 )
      rsSourceImg->drawCircle( m_vPoints[i].x, m_vPoints[i].y, 
                               m_vPoints[i].scale*3.0,
                               QColor::QColor(255,255,0), OVERDRAW_IMG );
  }
  qApp->processEvents();
}


void ISMReco::drawInterestPointsEllipse( float dScaleFactor )
/*******************************************************************/
/* Draw the interest points returned by the Int.Pt. detector.      */
/*******************************************************************/
{
  if ( m_vPoints.empty() )
    return;
 
  if( m_bShowTxtDetails )
    cout << "  Drawing " << m_vPoints.size() << " points..." << endl;
 
  // display original image first (clean any drawings)
  rsSourceImg->display();
  for( int i=0; i <(int)m_vPoints.size(); i++) {
    rsSourceImg->drawCross( m_vPoints[i].x, m_vPoints[i].y,
                            QColor::QColor(255,255,0), OVERDRAW_IMG );
    //float dScaleFactor = m_fcCue.params()->m_dScaleFactor;
    if( m_vPoints[i].scale > 1.0 )
      if( m_vPoints[i].l1 != m_vPoints[i].l2 )
        rsSourceImg->drawEllipse( m_vPoints[i].x, m_vPoints[i].y,
                                  m_vPoints[i].l1*dScaleFactor, 
                                  m_vPoints[i].l2*dScaleFactor,
                                  -m_vPoints[i].angle,
                                  QColor::QColor(255,255,0), OVERDRAW_IMG );
    else
      rsSourceImg->drawCircle( m_vPoints[i].x, m_vPoints[i].y,
                               m_vPoints[i].scale*3.0,
                               QColor::QColor(255,255,0), OVERDRAW_IMG );
  }
  qApp->processEvents();
}


void ISMReco::displayPatchesForBrowsing(vector<OpGrayImage> &vPatches,
                                          int pos_x, int pos_y )
  /*******************************************************************/
  /* Display the extracted image patches in a separate window.       */
  /*******************************************************************/
{
  if ( vPatches.empty() ) 
    return;

  if( m_bShowGUI ) {
    vector<QImage> vPatchImages;
    for (unsigned i=0; i < vPatches.size(); i++) {
      vPatchImages.push_back( vPatches[i].getQtImage() );
    }
    
    QtImgBrowser *qtPatchBrowser = new QtImgBrowser( 0, "patches" );
    qtPatchBrowser->setGeometry( pos_x, pos_y, 100, 150 );
    qtPatchBrowser->load( vPatchImages );
    connect( qtPatchBrowser, SIGNAL(imageClicked(int)), 
             this, SLOT(highlightPoint(int)) );
    qtPatchBrowser->show();
  }
}


/*---------------------------------------------------------*/
/*           Comparing Features with the Codebook          */
/*---------------------------------------------------------*/

void ISMReco::compareFeatures()
{
  for(unsigned k=0; k<m_nNumDetectors; k++ ) {
    /* Initialize the interest point variables */
    
    for(unsigned j=0; j<m_vDetectors[k].m_nNumCues; j++ ) {
      int idx = m_vvCueIdx[k][j];

      /* Transfer the interest points to the detector */
      m_vDetectors[k].m_vvPointsInside[j] = m_vvPointsInside[idx];
      if( m_vDetectors[k].params()->m_bProcessBothDir )
        m_vDetectors[k].m_vvPointsInsideLeft[j] = m_vvPointsInsideLeft[idx];

      /* Compare the features with the detector's codebook */
      m_vDetectors[k].compareFeatures( j, m_vvFeatures[idx] );
      if( m_vDetectors[k].params()->m_bProcessBothDir )
        m_vDetectors[k].compareFeaturesLeft( j, m_vvFeaturesLeft[idx] );      
    }
  }
  
  if( m_bShowTxtDetails )
    cout << "Image size is: (" << m_resultImg.width() << "," 
         << m_resultImg.height() << ")" << endl;
}

/*---------------------------------------------------------*/
/*                  Processing a Test Image                */
/*---------------------------------------------------------*/

void ISMReco::processTestImg(  QString qsFileName, int nImgNumber,
                               vector<Hypothesis>  &vResultHypos,
                               vector<Hypothesis>  &vResultHyposTight,
                               vector<OpGrayImage> &vResultImgSegment,
                               vector<OpGrayImage> &vResultImgPFig,
                               vector<OpGrayImage> &vResultImgPGnd,
                               bool bDisplayResults )
{
  return processTestImgBothDir( qsFileName, nImgNumber, 
                                vResultHypos, vResultHyposTight,
                                vResultImgSegment, vResultImgPFig, 
                                vResultImgPGnd, bDisplayResults );
}


void ISMReco::processTestImgBothDir( QString qsFileName, int nImgNumber,
                                     vector<Hypothesis>  &vResultHypos,
                                     vector<Hypothesis>  &vResultHyposTight,
                                     vector<OpGrayImage> &vResultImgSegment,
                                     vector<OpGrayImage> &vResultImgPFig,
                                     vector<OpGrayImage> &vResultImgPGnd,
                                     bool bDisplayResults )
{
  // TIMING CODE
  time_t  tu1, tu2, tu3, tu4, tu5, tu6, tu7;
  double  tc1, tc2, tc3, tc4, tc5, tc6, tc7;
  time(&tu1);
  tc1 = CPUTIME();

  /***************************************/
  /*   Initialize the global variables   */
  /***************************************/
  m_vImagePatches.clear();
  m_vPoints.clear();
  for(unsigned k=0; k<m_nNumCues; k++ ) {
    m_vvPointsInside[k].clear();
    m_vvFeatures[k].clear();
    
    m_vvPointsInsideLeft[k].clear();
    m_vvFeaturesLeft[k].clear();
  }
  
  // clear the shared matchinginfo table
  m_mActiveMatches.clear();
  m_mActiveMatchesL.clear();

  /******************************************************************/
  /*   Load the next image, calculate the interest points and ex-   */
  /*   tract all patches.                                           */
  /******************************************************************/
  if( m_bShowTxtSteps )  
    cout << "  Extracting image features..." << endl;
  processImage( qsFileName );

  // TIMING CODE
  time(&tu2);
  tc2 = CPUTIME();

  /***************************************************/
  /*   Match the extracted patches to the codebook   */
  /***************************************************/
  if( m_bShowTxtSteps )  
    cout << "  Comparing image patches with all matches..." << endl;
  compareFeatures();

  // TIMING CODE
  time(&tu3);
  tc3 = CPUTIME();

  /*********************************/
  /*   Initialize some variables   */
  /*********************************/
  vResultHypos.clear();
  vResultHyposTight.clear();
  vResultImgSegment.clear();
  vResultImgPFig.clear();
  vResultImgPGnd.clear();
 
  float dMSMESizeS    = m_parReco.params()->m_dMSMESizeS;
  int   nImgWidth     = m_grayImg.width();
  int   nImgHeight    = m_grayImg.height();
  float dRecoScaleMin = m_parReco.params()->m_dRecoScaleMin;
  float dRecoScaleMax = m_parReco.params()->m_dRecoScaleMax;

  /*------------------------------*/
  /*   Initialize the Detectors   */
  /*------------------------------*/
  for(unsigned k=0; k<m_nNumDetectors; k++ )
    if( m_bCalibAvailable )
      m_vDetectors[k].setCalibration( m_calCamera );
    else
      m_vDetectors[k].clearCalibration();

  /*--------------------------------------*/
  /*   Initialize a VotingSpace for MDL   */
  /*--------------------------------------*/
  float dScaleMin = dRecoScaleMin - dMSMESizeS/2.0;
  float dScaleMax = dRecoScaleMax + dMSMESizeS/2.0;
  int   nScaleSteps = (int)floor((dScaleMax - dScaleMin)/
                                 dMSMESizeS +0.5) + 1;

  /* prepare a common voting space */
  m_ismMDL.setRecoParams    ( m_parReco );
  m_ismMDL.createVotingSpace( nImgWidth, nImgHeight, SIZE_VOTINGBINS,
                              dScaleMin, dScaleMax, nScaleSteps, 
                              false );

  /**********************************/
  /*   Apply each detector in turn  */
  /**********************************/
  vResultHypos.clear();
  vector<Segmentation> vSegmentations;
  vector<unsigned>     vHypoSrc;
  for(unsigned k=0; k<m_nNumDetectors; k++ ) {
    vector<Hypothesis>   vDetHypos;
    vector<Segmentation> vDetSegment;
    
    if( m_bShowTxtSteps ) {
      if( m_bShowTxtDetails )
        cout << endl;
      cout << "  Applying detector " << k+1 << " for '" 
           << m_vDetectors[k].params()->m_qsCategName << "/"
           << m_vDetectors[k].params()->m_qsPoseName << "'..." << endl;
    }
    m_vDetectors[k].processTestImg( nImgWidth, nImgHeight, SIZE_VOTINGBINS,
                                    vDetHypos, vDetSegment, 
                                    m_bDisplayVS, false, 
                                    m_bShowTxtVoting, m_bShowTimings );

    /* add the results to the list */
    if( m_bShowTxtDetails ) {
      cout << "  adding the result hypothesis to the list..." << endl;
      cout << "    #hypos: " << vDetHypos.size() << endl;
      cout << "    #segm:  " << vDetSegment.size() << endl;
    }
    for(unsigned i=0; i<vDetHypos.size(); i++ ) {
      vDetHypos[i].nCategory = k;
      vResultHypos.push_back( vDetHypos[i] );
      vSegmentations.push_back( vDetSegment[i] );
      vHypoSrc.push_back( k );
    }
  }


  // TIMING CODE
  time(&tu4);
  tc4 = CPUTIME();

  /*=====================*/
  /* Resample hypotheses */
  /*=====================*/
  // resample the interest points for each hypothesis
  bool bResampled = false;
  for(unsigned i=0; i<vResultHypos.size(); i++ ) {
    Hypothesis &hypo  = vResultHypos[i];
    unsigned   nDetId = hypo.nCategory;
    //Detector   &det   = m_vDetectors[nDetId];

    if( m_vParReco[nDetId].params()->m_bResampleHypos ) {
      if( m_bShowTxtDetails ) {
        cout << "  Resampling hypothesis " << i << "..." << endl;
        cout << "    (x,y,s) = (" << hypo.x << "," << hypo.y 
             << "," << hypo.dScale << ")" << endl;
      }
      bResampled = true;

      Segmentation segResult;
      resampleHypothesis( hypo, vSegmentations[i] );

    } // end if(resample hypothesis)
  } // end forall hypotheses

  // print the results
  if( bResampled ) {
    if( m_bShowTxtDetails ) {
      cout << "=======================================" << endl;
      cout << "Hypothesis scores after resampling:" 
           << endl;
      for(unsigned i=0; i<vResultHypos.size(); i++ ) {
        Hypothesis &hypo  = vResultHypos[i];
        unsigned   nDetId = hypo.nCategory;
        
        if( m_vParReco[nDetId].params()->m_bResampleHypos ) {
          cout << "  " << setw(2) << i+1 << ". ";
          printHypothesisMDL( vResultHypos[i] );
        }
      }
      cout << "=======================================" << endl;
      cout << endl;
    }
  }

  // TIMING CODE
  time(&tu5);
  tc5 = CPUTIME();

  /*==============================================*/
  /* Sort the hypotheses based on their MDL score */
  /*==============================================*/
  //if( !m_parReco.params()->m_bDoMDL && m_parReco.params()->m_bRejectPFig ) {
  if( !m_bDoMDL && m_bRejectPFig ) {
    /* sort the hypothesis list according to the MDL scores */
    int numHypos = vResultHypos.size();
    for( int j=0; j<numHypos-1; j++ )
      for( int i=1; i<numHypos-j; i++ )
        if( vResultHypos[i].dScoreMDL > vResultHypos[i-1].dScoreMDL ) {
          Hypothesis hTmp   = vResultHypos[i-1];
          vResultHypos[i-1] = vResultHypos[i];
          vResultHypos[i]   = hTmp;

          Segmentation sTmp   = vSegmentations[i-1];
          vSegmentations[i-1] = vSegmentations[i];
          vSegmentations[i]   = sTmp;
          
          int nTmp      = vHypoSrc[i-1];
          vHypoSrc[i-1] = vHypoSrc[i];
          vHypoSrc[i]   = nTmp;
        }
  }


  /*================================*/
  /* Apply MDL hypothesis selection */
  /*================================*/
  vector<Hypothesis> vResultsMDL;
  vector<int>  vRanks;
  for(unsigned i=0; i<vResultHypos.size(); i++ )
    vRanks.push_back( i );
  //if( m_parReco.params()->m_bDoMDL ) {
  if( m_bDoMDL ) {
    /*--------------------*/
    /* Get MDL Parameters */
    /*--------------------*/
    float dMinPFig;
    if( !bResampled )
      //dMinPFig = m_parReco.params()->m_dMinPFig;
      dMinPFig = m_dMinPFig;
    else
      //dMinPFig = m_parReco.params()->m_dMinPFigRefined;
      dMinPFig = m_dMinPFigRefined;
    //float dWeightPFig = m_parReco.params()->m_dWeightPFig;
    float dWeightPFig = m_dWeightPFig;

    /*-----------------------*/
    /* Perform MDL Selection */
    /*-----------------------*/
    if( m_bShowTxtSteps )
      cout << "  Performing MDL Selection..." << endl;
    vResultsMDL = m_ismMDL.doMDLSelection( vResultHypos, 
                                           vSegmentations,
                                           dMinPFig, dWeightPFig, 
                                           vRanks, false, m_bShowTxtMDL );

    vResultHypos = vResultsMDL;
  }


  // TIMING CODE
  time(&tu6);
  tc6 = CPUTIME();

  /*==================================*/
  /* Check for overlapping hypotheses */
  /*==================================*/
  if( m_bShowTxtSteps )
    cout << "  Checking for overlapping hypotheses..." << endl;
  /* prepare the display */
  rsSourceImg->loadImage( m_qsourceImg, m_grayImg );
  rsSourceImg->display();
  qApp->processEvents();

  vector<Hypothesis>   vHyposOverlap;
  vector<int>          vRanksOverlap;
  //vector<Hypothesis>   vHyposOverlapTight;
  //bool  bRejectOverlap     = m_parReco.params()->m_bRejectOverlap;
  //float dMaxOverlap        = m_parReco.params()->m_dMaxOverlap;
  bool  bRejectOverlap     = m_bRejectOverlap;
  float dMaxOverlap        = m_dMaxOverlap;
  for(unsigned i=0; i<vResultHypos.size(); i++ ) {
    int idx = vRanks[i];

    Hypothesis hypo = vResultHypos[i];
    /* apply object-specific bounding box */
    int   nDetect     = vHypoSrc[idx];
    int   nDetWidth   = m_vDetectors[nDetect].m_parReco.params()->m_nObjWidth;
    int   nDetHeight  = m_vDetectors[nDetect].m_parReco.params()->m_nObjHeight;

    int width  = (int) floor(nDetWidth*hypo.dScale + 0.5);
    int height = (int) floor(nDetHeight*hypo.dScale + 0.5);
    hypo.nBoxX1 = (int)(hypo.x - width/2);
    hypo.nBoxY1 = (int)(hypo.y - height/2);
    hypo.nBoxWidth = width;
    hypo.nBoxHeight = height;
    
    /* check if the hypothesis overlaps with higher-ranking hypos */
    bool bOverlaps = false;
    if( bRejectOverlap )
      for(unsigned j=0; j<vHyposOverlap.size() && !bOverlaps; j++ ) {
        float dOverlap = computeBoundingBoxOverlap( vHyposOverlap[j],
                                                    hypo );
        if( dOverlap >= dMaxOverlap )
          bOverlaps = true;
      }
    
    /* Draw a rectangle around the detection */
    int nScaleWidth  = (int) floor(nDetWidth*vResultHypos[i].dScale);
    int nScaleHeight = (int) floor(nDetHeight*vResultHypos[i].dScale);
    QColor qcol; 
    if( bOverlaps ) {
      /* rejected => draw a red rectangle */
      qcol = QColor::QColor(255, 0, 0);
      if( m_bDrawRejectedHypos )
        rsSourceImg->drawRect( vResultHypos[i].x - nScaleWidth/2,
                               vResultHypos[i].y - nScaleHeight/2,
                               nScaleWidth, nScaleHeight, qcol, true );
      
    } else {
      /* accepted => draw a green rectangle */
      //qcol = QColor::QColor(0, 255, 0);
      qcol = m_vDetectors[vHypoSrc[idx]].params()->m_qcColor;
      
      rsSourceImg->drawRect( vResultHypos[i].x - nScaleWidth/2,
                             vResultHypos[i].y - nScaleHeight/2,
                             nScaleWidth, nScaleHeight, qcol, true );
      
      if( m_bDrawTightBB ) {
        /* draw the tight bounding box => yellow rectangle */
        qcol = QColor::QColor(250, 250, 0);
        Hypothesis &hTight = vResultHyposTight[i];
        rsSourceImg->drawRect( hTight.nBoxX1, hTight.nBoxY1, 
                               hTight.nBoxWidth, hTight.nBoxHeight, 
                               qcol, true );
      }
    }
    
    if( !bOverlaps ) {
      vHyposOverlap.push_back( hypo );
      vRanksOverlap.push_back( idx );
      //vHyposOverlapTight.push_back( vResultHyposTight[i] );
    }
  }
  vResultHypos      = vHyposOverlap;
  vRanks            = vRanksOverlap;
  //vResultHyposTight = vHyposOverlapTight;
  qApp->processEvents();


  /*------------------------------*/
  /* Compute tight bounding boxes */
  /*------------------------------*/
  if( m_bShowTxtSteps )
    cout << "  Preparing result output..." << endl;
  vector<OpGrayImage> vResultImgs;
  vector<OpGrayImage> vResultThumbs;
  vector<int>         vAssoc;
  for(unsigned i=0; i<vRanks.size(); i++ ) {
    int idx = vRanks[i];
      
    //cout << "\r  Preparing hypothesis " << i << " for display..." << flush;
    OpGrayImage imgSeg = vSegmentations[idx].getImgSeg();
    int nOffX = vSegmentations[idx].getOffsetX();
    int nOffY = vSegmentations[idx].getOffsetY();
    if( m_bShowTxtDetails )
      cout << "." << flush;
    // tight bboxes are no longer needed
    //vResultHyposTight.push_back( computeTightBBox( imgSeg, nOffX, nOffY )); 
    if( m_bShowTxtDetails )
      cout << "." << flush;
    if( m_bDisplaySegment || m_parVeri.params()->m_bDoVerif || m_bWriteSegs )
      vResultImgSegment.push_back( vSegmentations[idx].getFullImgSeg() );
    else
      vResultImgSegment.push_back( vSegmentations[idx].getImgSeg() );
    
    if( m_bDisplaySupport || m_parVeri.params()->m_bDoVerif || m_bWriteSegs ) {
      vResultImgPFig.push_back( vSegmentations[idx].getFullImgPFig() );
      vResultImgPGnd.push_back( vSegmentations[idx].getFullImgPGnd() );
    } else {
      vResultImgPFig.push_back( vSegmentations[idx].getImgPFig() );
      vResultImgPGnd.push_back( vSegmentations[idx].getImgPGnd() );
    }
    
    if( m_bDisplayMultiCue ) {
      vResultThumbs.push_back( vSegmentations[idx].getFullImgSeg().opRescaleToWidth(100) );
        
        string sHypNr = string("H") + QString::number(i).latin1();
        vResultImgs.push_back( vSegmentations[idx].getFullImgPFig() );
        vAssoc.push_back(i);
        vResultImgs.push_back( vSegmentations[idx].getFullImgSeg() );
        vAssoc.push_back(i);
    }

    if( m_bDisplayMultiCue && !vResultThumbs.empty() ) {
      if( m_bShowTxtDetails )
        cout << "  Displaying visualizations..." << endl;
      m_qcvResultView->loadImageSets( vResultThumbs, "Hypo", 
                                      vResultImgs, vAssoc );
    }   
  }
  // tight bboxes are no longer needed:
  vResultHyposTight = vResultHypos;
  vSegmentations.clear();

  
  // TIMING CODE
  time(&tu7);
  tc7 = CPUTIME();

  /*==================================*/
  /* Display the accepted hypotheses */
  /*==================================*/
  cout << "=======================================" << endl;
  cout << "Final Hypotheses:" << endl;
  for(unsigned k=0; k<vResultHypos.size(); k++ ) {
    cout << "  " << setw(2) << k+1 << ". ";
    printHypothesisMDL( vResultHypos[k] );

    if( m_bCalibAvailable ) {
      //float dDist, dSize;
      /* compute the object's size and distance */
      //::getRealObjSize( m_calCamera, vResultHypos[k], dDist, dSize );

      if( vResultHypos[k].dRealDist>=0.0 )
        cout << "         distance=" << vResultHypos[k].dRealDist << "m" 
             << flush; 
      else
        cout << "         distance=INFINITY" << flush;

      if( vResultHypos[k].dRealSize>=0.0 )
        cout << ", size=" << vResultHypos[k].dRealSize << "m" << endl;
      else
        cout << ", size=INFINITE" << endl;
    }

    /* extract the hypothesis support */
//     FeatureVector fvWindowPos( 3 );
//     fvWindowPos.setValue( 0, vResultHypos[k].x );
//     fvWindowPos.setValue( 1, vResultHypos[k].y );
//     fvWindowPos.setValue( 2, vResultHypos[k].dScale );

//     vector<HoughVote> vSupporting;
//     vSupporting = m_ismMultiCue.getSupportingVotes( fvWindowPos );
    
//     vector<vector<HoughVote> > vvCueSupport;
//     vvCueSupport = splitUpCueVotes( vSupporting );

//     for(unsigned nIdx=0; nIdx<m_nNumCues; nIdx++ )
//       countPatches( vResultHypos[k], nIdx, vvCueSupport[nIdx] );
  }
  cout << "=======================================" << endl;
  cout << endl;

  /*----------------------*/
  /* Print timing results */
  /*----------------------*/
  if( m_bShowTimings ) {
    cout << "----------------------" << endl;
    cout << "Time spent for..." << endl;
    cout << "  Feature extraction: " << setw(12)
         << tc2-tc1 << "s (system), "
         << tu2-tu1 << "s (user)" << endl;
    cout << "  Matching          : " << setw(12)
         << tc3-tc2 << "s (system), "
         << tu3-tu2 << "s (user)" << endl;
    cout << "  Detectors         : " << setw(12)
         << tc4-tc3 << "s (system), "
         << tu4-tu3 << "s (user)" << endl;
    if( bResampled ) {
      cout << "  Resampling        : " << setw(12)
           << tc5-tc4 << "s (system), "
           << tu5-tu4 << "s (user)" << endl;
    }
    cout << "  MDL Selection     : " << setw(12)
         << tc6-tc5 << "s (system), "
         << tu6-tu5 << "s (user)" << endl;
    cout << "  Postprocessing    : " << setw(12)
         << tc7-tc6 << "s (system), "
         << tu7-tu6 << "s (user)" << endl;
    cout << "  TOTAL             : " << setw(12)
         << tc7-tc1 << "s (system), "
         << tu7-tu1 << "s (user)" << endl;
    //cout << endl;
    cout << "----------------------" << endl;
    cout << endl;
  }
}


void ISMReco::drawGroundPlane()
{
  /* draw a reference grid for short distances up to 10m */
  float dLeft    = -2.5;
  float dRight   =  2.5;
  float dFarLeft = -7.5;
  float dFarRight=  7.5;

  for( float x=dFarLeft; x<=dFarRight; x+=1.0 ) {
    drawDistZLine( x, 1.0, 10.0, 0.0, Qt::blue );
    drawDistZLine( x, 1.0, 10.0, 2.0, Qt::red );
  }
  
  for( float z=1.0; z<=10.0; z+=1.0 ) {
    drawDistHLine( dFarLeft, dFarRight, z, 0.0, Qt::blue );
    drawDistHLine( dFarLeft, dFarRight, z, 2.0, Qt::red );
    drawDistVLine( dLeft, z, 0.0, 2.0, Qt::green );
    drawDistVLine( dRight, z, 0.0, 2.0, Qt::green );
  }
  drawDistHLine( dFarLeft, dFarRight, 5.0, 0.0, Qt::darkBlue );
  drawDistHLine( dFarLeft, dFarRight, 5.0, 2.0, Qt::darkRed );
  drawDistVLine( dLeft, 5.0, 0.0, 2.0, Qt::darkGreen );
  drawDistVLine( dRight, 5.0, 0.0, 2.0, Qt::darkGreen );

  /* draw some reference lines for far distances */
  float zmin = 10.0;
  float zmax = 70.0;
  for( float z=zmin; z<=zmax; z+=10.0 ) {
    drawDistHLine( dLeft, dRight, z, 0.0, Qt::cyan );
    drawDistHLine( dLeft, dRight, z, 2.0, Qt::magenta );
    drawDistVLine( dLeft, z, 0.0, 2.0, Qt::yellow );
    drawDistVLine( dRight, z, 0.0, 2.0, Qt::yellow );
  }
  drawDistHLine( dFarLeft, dFarRight, zmin, 0.0, Qt::cyan );
  drawDistHLine( dFarLeft, dFarRight, zmin, 2.0, Qt::magenta );
  drawDistHLine( dFarLeft, dFarRight, 50.0, 0.0, Qt::blue );
  drawDistHLine( dFarLeft, dFarRight, 50.0, 2.0, Qt::red );
  drawDistHLine( dLeft, dRight, zmax, 0.0, Qt::cyan );
  drawDistHLine( dLeft, dRight, zmax, 2.0, Qt::magenta );
  drawDistVLine( dLeft, 50.0, 0.0, 2.0, Qt::green );
  drawDistVLine( dRight, 50.0, 0.0, 2.0, Qt::green );

  drawDistZLine( dFarLeft, 1.0, zmax, 0.0, Qt::cyan );
  drawDistZLine( dFarLeft, 1.0, zmax, 2.0, Qt::magenta );
  drawDistZLine( dFarRight, 1.0, zmax, 0.0, Qt::cyan );
  drawDistZLine( dFarRight, 1.0, zmax, 2.0, Qt::magenta );

  drawDistZLine( dLeft, 1.0, zmax, 0.0, Qt::cyan );
  drawDistZLine( dLeft, 1.0, zmax, 1.0, Qt::white );
  drawDistZLine( dLeft, 1.0, zmax, 2.0, Qt::magenta );
  drawDistZLine( dRight, 1.0, zmax, 0.0, Qt::cyan );
  drawDistZLine( dRight, 1.0, zmax, 1.0, Qt::white );
  drawDistZLine( dRight, 1.0, zmax, 2.0, Qt::magenta );

  rsResultImg->display();
}


void ISMReco::drawDistHLine( float x1, float x2, float d, float h, QColor col )
  /*******************************************************************/
  /* Draw a line at the specified distance in the input image (if a  */
  /* camera calibration is available).                               */
  /*******************************************************************/
{
  if( m_bCalibAvailable ) {
    FeatureVector fvUp(3);
    FeatureVector fvForw(3);
    FeatureVector fvLeft(3);
    fvUp.at(0)   =  0.0; fvUp.at(1)   =  1.0; fvUp.at(2)   =  0.0;
    fvForw.at(0) =  0.0; fvForw.at(1) =  0.0; fvForw.at(2) =  1.0;
    fvLeft.at(0) = -1.0; fvLeft.at(1) =  0.0; fvLeft.at(2) =  0.0;

    //cout << "\r    Transforming camera direction: " << flush;
    FeatureMatrix mR   = m_calCamera.getR();
    fvUp   = mR*fvUp;
    fvForw = mR*fvForw;
    fvLeft = mR*fvLeft;
    //cout << fvForw << endl;
    //cout << "\r    Transforming camera up vector: " << flush;
    //cout << fvUp << endl;

    FeatureMatrix mK   = m_calCamera.getK();

    //cout << "\r    Getting camera pos... " << flush;
    //FeatureVector fvT  = mR.transpose() * m_calCamera.getT();
    FeatureVector fvT  = m_calCamera.getT();

    FeatureMatrix mG(4,4);
    mG(0,0)=mR(0,0);  mG(0,1)=mR(0,1);  mG(0,2)=mR(0,2);  mG(0,3)=fvT.at(0);
    mG(1,0)=mR(1,0);  mG(1,1)=mR(1,1);  mG(1,2)=mR(1,2);  mG(1,3)=fvT.at(1);
    mG(2,0)=mR(2,0);  mG(2,1)=mR(2,1);  mG(2,2)=mR(2,2);  mG(2,3)=fvT.at(2);
    mG(3,0)=0.0;      mG(3,1)=0.0;      mG(3,2)=0.0;      mG(3,3)=1.0;

    FeatureVector fvT2 = mR.transpose()*fvT;
    FeatureMatrix mH(4,4);
    mH(0,0)=mR(0,0);  mH(0,1)=mR(1,0);  mH(0,2)=mR(2,0);  mH(0,3)=fvT2.at(0);
    mH(1,0)=mR(0,1);  mH(1,1)=mR(1,1);  mH(1,2)=mR(2,1);  mH(1,3)=fvT2.at(1);
    mH(2,0)=mR(0,2);  mH(2,1)=mR(1,2);  mH(2,2)=mR(2,2);  mH(2,3)=fvT2.at(2);
    mH(3,0)=0.0;      mH(3,1)=0.0;      mH(3,2)=0.0;      mH(3,3)=1.0;

    FeatureMatrix mI(3,4);
    mI(0,0)=1.0;  mI(0,1)=0.0;  mI(0,2)=0.0;  mI(0,3)=0.0;
    mI(1,0)=0.0;  mI(1,1)=1.0;  mI(1,2)=0.0;  mI(1,3)=0.0;
    mI(2,0)=0.0;  mI(2,1)=0.0;  mI(2,2)=1.0;  mI(2,3)=0.0;
    
    FeatureMatrix mP = mK*mI*mH;

    //cout << "\r    Computing view plane normal... " << flush;
    FeatureVector fvVPN(3);
    fvVPN.at(0)=mP(2,0); fvVPN.at(1)=mP(2,1); fvVPN.at(2)=mP(2,2);
    fvForw = fvVPN;
    //cout << fvVPN << endl;
    
    //cout << "\r    Getting ground plane normal... " << flush;
    FeatureVector fvN  = m_calCamera.getGPN();
    //float         dGPd = m_calCamera.getGPd();
    //cout << fvN << endl;

    float dWorldScale = m_dWorldScale; // DEF_WORLD_SCALE;

    //cout << "\r    Computing dist from ground... " << flush;
    float dCamHeight   = m_calCamera.distFromGround( fvT );
    //cout << dCamHeight << endl;

    //cout << "\r    Computing camera base point... " << flush;
    //FeatureVector fvB  = mR.transpose()*(fvT - fvN*dCamHeight);
    FeatureVector fvB  = fvT - (fvUp*dCamHeight);

    //cout << "\r    Computing left world point... " << flush;
    FeatureVector fvU1 = ( fvT + fvForw*(d/dWorldScale) 
                           + fvLeft*(x1/dWorldScale) );
    float         dGP1 = m_calCamera.distFromGround( fvU1 );
    FeatureVector fvW1 = ( fvU1 - (fvN*dGP1) - (fvUp*(h/dWorldScale)) );

    //cout << "\r    Computing right world point... " << flush;
    FeatureVector fvU2 = ( fvT + fvForw*(d/dWorldScale) 
                          + fvLeft*(x2/dWorldScale) );
    float         dGP2 = m_calCamera.distFromGround( fvU2 );
    FeatureVector fvW2 = ( fvU2 - (fvN*dGP2) - (fvUp*(h/dWorldScale)) );

    FeatureVector fvX1(3);
    FeatureVector fvX2(3);
    //cout << "\r    Converting left point to image... " << flush;
    m_calCamera.world2Img( fvW1 , fvX1 );
    //cout << "\r    Converting right point to image... " << flush;
    m_calCamera.world2Img( fvW2 , fvX2 );

    /* draw the line in the image */
    //cout << "\r    Drawing line at " << d << "m distance... " << flush;
    rsSourceImg->drawLine( (int)fvX1.at(0), (int)fvX1.at(1),
                           (int)fvX2.at(0), (int)fvX2.at(1), col );
    //cout << "OK." << endl;
  }
}


void ISMReco::drawDistVLine( float x, float d, float h1, float h2, QColor col )
  /*******************************************************************/
  /* Draw a line at the specified distance in the input image (if a  */
  /* camera calibration is available).                               */
  /*******************************************************************/
{
  if( m_bCalibAvailable ) {
    FeatureVector fvUp(3);
    FeatureVector fvForw(3);
    FeatureVector fvLeft(3);
    fvUp.at(0)   =  0.0; fvUp.at(1)   =  1.0; fvUp.at(2)   =  0.0;
    fvForw.at(0) =  0.0; fvForw.at(1) =  0.0; fvForw.at(2) =  1.0;
    fvLeft.at(0) = -1.0; fvLeft.at(1) =  0.0; fvLeft.at(2) =  0.0;

    //cout << "\r    Transforming camera direction: " << flush;
    FeatureMatrix mR   = m_calCamera.getR();
    fvUp   = mR*fvUp;
    fvForw = mR*fvForw;
    fvLeft = mR*fvLeft;
    //cout << fvForw << endl;
    //cout << "\r    Transforming camera up vector: " << flush;
    //cout << fvUp << endl;

    FeatureMatrix mK   = m_calCamera.getK();

    //cout << "\r    Getting camera pos... " << flush;
    //FeatureVector fvT  = mR.transpose() * m_calCamera.getT();
    FeatureVector fvT  = m_calCamera.getT();

    FeatureMatrix mG(4,4);
    mG(0,0)=mR(0,0);  mG(0,1)=mR(0,1);  mG(0,2)=mR(0,2);  mG(0,3)=fvT.at(0);
    mG(1,0)=mR(1,0);  mG(1,1)=mR(1,1);  mG(1,2)=mR(1,2);  mG(1,3)=fvT.at(1);
    mG(2,0)=mR(2,0);  mG(2,1)=mR(2,1);  mG(2,2)=mR(2,2);  mG(2,3)=fvT.at(2);
    mG(3,0)=0.0;      mG(3,1)=0.0;      mG(3,2)=0.0;      mG(3,3)=1.0;

    FeatureVector fvT2 = mR.transpose()*fvT;
    FeatureMatrix mH(4,4);
    mH(0,0)=mR(0,0);  mH(0,1)=mR(1,0);  mH(0,2)=mR(2,0);  mH(0,3)=fvT2.at(0);
    mH(1,0)=mR(0,1);  mH(1,1)=mR(1,1);  mH(1,2)=mR(2,1);  mH(1,3)=fvT2.at(1);
    mH(2,0)=mR(0,2);  mH(2,1)=mR(1,2);  mH(2,2)=mR(2,2);  mH(2,3)=fvT2.at(2);
    mH(3,0)=0.0;      mH(3,1)=0.0;      mH(3,2)=0.0;      mH(3,3)=1.0;

    FeatureMatrix mI(3,4);
    mI(0,0)=1.0;  mI(0,1)=0.0;  mI(0,2)=0.0;  mI(0,3)=0.0;
    mI(1,0)=0.0;  mI(1,1)=1.0;  mI(1,2)=0.0;  mI(1,3)=0.0;
    mI(2,0)=0.0;  mI(2,1)=0.0;  mI(2,2)=1.0;  mI(2,3)=0.0;
    
    FeatureMatrix mP = mK*mI*mH;

    //cout << "\r    Computing view plane normal... " << flush;
    FeatureVector fvVPN(3);
    fvVPN.at(0)=mP(2,0); fvVPN.at(1)=mP(2,1); fvVPN.at(2)=mP(2,2);
    fvForw = fvVPN;
    //cout << fvVPN << endl;
    
    //cout << "\r    Getting ground plane normal... " << flush;
    FeatureVector fvN  = m_calCamera.getGPN();
    //float         dGPd = m_calCamera.getGPd();
    //cout << fvN << endl;

    float dWorldScale = m_dWorldScale; // DEF_WORLD_SCALE;

    //cout << "\r    Computing dist from ground... " << flush;
    float dCamHeight   = m_calCamera.distFromGround( fvT );
    //cout << dCamHeight << endl;

    //cout << "\r    Computing camera base point... " << flush;
    //FeatureVector fvB  = mR.transpose()*(fvT - fvN*dCamHeight);
    FeatureVector fvB  = fvT - (fvUp*dCamHeight);

    //cout << "\r    Computing left world point... " << flush;
    FeatureVector fvU1 = ( fvT + fvForw*(d/dWorldScale) 
                           + fvLeft*(x/dWorldScale) );
    float         dGP1 = m_calCamera.distFromGround( fvU1 );
    FeatureVector fvW1 = ( fvU1 - (fvN*dGP1) - (fvUp*(h1/dWorldScale)) );

    //cout << "\r    Computing right world point... " << flush;
    FeatureVector fvU2 = ( fvT + fvForw*(d/dWorldScale) 
                           + fvLeft*(x/dWorldScale) );
    float         dGP2 = m_calCamera.distFromGround( fvU2 );
    FeatureVector fvW2 = ( fvU2 - (fvN*dGP2) - (fvUp*(h2/dWorldScale)) );

    FeatureVector fvX1(3);
    FeatureVector fvX2(3);
    //cout << "\r    Converting left point to image... " << flush;
    m_calCamera.world2Img( fvW1 , fvX1 );
    //cout << "\r    Converting right point to image... " << flush;
    m_calCamera.world2Img( fvW2 , fvX2 );

    /* draw the line in the image */
    //cout << "\r    Drawing line at " << d << "m distance... " << flush;
    rsSourceImg->drawLine( (int)fvX1.at(0), (int)fvX1.at(1),
                           (int)fvX2.at(0), (int)fvX2.at(1), col );
    //cout << "OK." << endl;
  }
}


void ISMReco::drawDistZLine( float x, float d1, float d2, float h, QColor col )
  /*******************************************************************/
  /* Draw a line at the specified horizontal position in the input   */
  /* image (if a camera calibration is available).                   */
  /*******************************************************************/
{
  if( m_bCalibAvailable ) {
    FeatureVector fvUp(3);
    FeatureVector fvForw(3);
    FeatureVector fvLeft(3);
    fvUp.at(0)   =  0.0; fvUp.at(1)   =  1.0; fvUp.at(2)   =  0.0;
    fvForw.at(0) =  0.0; fvForw.at(1) =  0.0; fvForw.at(2) =  1.0;
    fvLeft.at(0) = -1.0; fvLeft.at(1) =  0.0; fvLeft.at(2) =  0.0;

    //cout << "\r    Transforming camera direction: " << flush;
    FeatureMatrix mR   = m_calCamera.getR();
    fvUp   = mR*fvUp;
    fvForw = mR*fvForw;
    fvLeft = mR*fvLeft;
    //cout << fvForw << endl;
    //cout << "\r    Transforming camera up vector: " << flush;
    //cout << fvUp << endl;

    FeatureMatrix mK   = m_calCamera.getK();

    //cout << "\r    Getting camera pos... " << flush;
    //FeatureVector fvT  = mR.transpose() * m_calCamera.getT();
    FeatureVector fvT  = m_calCamera.getT();

    FeatureMatrix mG(4,4);
    mG(0,0)=mR(0,0);  mG(0,1)=mR(0,1);  mG(0,2)=mR(0,2);  mG(0,3)=fvT.at(0);
    mG(1,0)=mR(1,0);  mG(1,1)=mR(1,1);  mG(1,2)=mR(1,2);  mG(1,3)=fvT.at(1);
    mG(2,0)=mR(2,0);  mG(2,1)=mR(2,1);  mG(2,2)=mR(2,2);  mG(2,3)=fvT.at(2);
    mG(3,0)=0.0;      mG(3,1)=0.0;      mG(3,2)=0.0;      mG(3,3)=1.0;

    FeatureVector fvT2 = mR.transpose()*fvT;
    FeatureMatrix mH(4,4);
    mH(0,0)=mR(0,0);  mH(0,1)=mR(1,0);  mH(0,2)=mR(2,0);  mH(0,3)=fvT2.at(0);
    mH(1,0)=mR(0,1);  mH(1,1)=mR(1,1);  mH(1,2)=mR(2,1);  mH(1,3)=fvT2.at(1);
    mH(2,0)=mR(0,2);  mH(2,1)=mR(1,2);  mH(2,2)=mR(2,2);  mH(2,3)=fvT2.at(2);
    mH(3,0)=0.0;      mH(3,1)=0.0;      mH(3,2)=0.0;      mH(3,3)=1.0;

    FeatureMatrix mI(3,4);
    mI(0,0)=1.0;  mI(0,1)=0.0;  mI(0,2)=0.0;  mI(0,3)=0.0;
    mI(1,0)=0.0;  mI(1,1)=1.0;  mI(1,2)=0.0;  mI(1,3)=0.0;
    mI(2,0)=0.0;  mI(2,1)=0.0;  mI(2,2)=1.0;  mI(2,3)=0.0;
    
    FeatureMatrix mP = mK*mI*mH;

    //cout << "\r    Computing view plane normal... " << flush;
    FeatureVector fvVPN(3);
    fvVPN.at(0)=mP(2,0); fvVPN.at(1)=mP(2,1); fvVPN.at(2)=mP(2,2);
    fvForw = fvVPN;
    //cout << fvVPN << endl;
    
    //cout << "\r    Getting ground plane normal... " << flush;
    FeatureVector fvN  = m_calCamera.getGPN();

    //cout << "\r    Computing dist from ground... " << flush;
    float dCamHeight   = m_calCamera.distFromGround( fvT );

    //cout << "\r    Computing camera base point... " << flush;
    //FeatureVector fvB  = mR.transpose()*(fvT - fvN*dCamHeight);
    FeatureVector fvB  = fvT - (fvUp*dCamHeight);

    //cout << "\r    Computing front world point... " << flush;
    float dWorldScale = m_dWorldScale;
    FeatureVector fvU1 = ( fvT + fvForw*(d1/dWorldScale) 
                           + fvLeft*(x/dWorldScale) );
    float         dGP1 = m_calCamera.distFromGround( fvU1 );
    FeatureVector fvW1 = ( fvU1 - (fvN*dGP1)- (fvUp*(h/dWorldScale))  );

    //cout << "\r    Computing right world point... " << flush;
    FeatureVector fvU2 = ( fvT + fvForw*(d2/dWorldScale) 
                           + fvLeft*(x/dWorldScale) );
    float         dGP2 = m_calCamera.distFromGround( fvU2 );
    FeatureVector fvW2 = ( fvU2 - (fvN*dGP2)- (fvUp*(h/dWorldScale))  );

    FeatureVector fvX1(3);
    FeatureVector fvX2(3);
    //cout << "\r    Converting left point to image... " << flush;
    m_calCamera.world2Img( fvW1, fvX1 );
    //cout << "\r    Converting right point to image... " << flush;
    m_calCamera.world2Img( fvW2, fvX2 );

    /* draw the line in the image */
    //cout << "\r    Drawing line at " << d1 << "-" << d2 << "m distance... " 
    //     << flush;
    rsSourceImg->drawLine( (int)fvX1.at(0), (int)fvX1.at(1),
                           (int)fvX2.at(0), (int)fvX2.at(1), col );
    //cout << "OK." << endl;
  }
}


void ISMReco::processTestImgStd()
  /*******************************************************************/
  /* Apply the recognition procedure to a test image. This function  */
  /* just opens a file dialog to ask for a file to process, then it  */
  /* calls the more general function below.                          */
  /*******************************************************************/
{
  m_qsLastImage = QFileDialog::getOpenFileName( m_qsLastImage, 
					      "Images (*.png *.xpm *.jpg *.ppm);;all files (*.*)",
                 this);
  if ( m_qsLastImage.isEmpty() )
    return;

  ofstream ofDummy;
  vector<OpGrayImage> vDummy1;
  vector<OpGrayImage> vDummy2;
  vector<OpGrayImage> vDummy3;
  processTestImgStd( m_qsLastImage, 0, m_vHyposSingle, 
                     vDummy1, vDummy2, vDummy3, ofDummy );
}


void ISMReco::processTestImgStd( QString qsFileName )
  /*******************************************************************/
  /* Apply the recognition procedure to a test image. This function  */
  /* just calls the more general function below.                     */
  /*******************************************************************/
{
  ofstream ofDummy;
  vector<OpGrayImage> vDummy1;
  vector<OpGrayImage> vDummy2;
  vector<OpGrayImage> vDummy3;
  processTestImgStd( qsFileName, 0, m_vHyposSingle, 
                     vDummy1, vDummy2, vDummy3, ofDummy );
}


void ISMReco::processTestImgStd( QString qsFileName, int nImgNumber,
                                 vector<Hypothesis>  &vResultHypos,
                                 vector<OpGrayImage> &vResultImgSeg,
                                 vector<OpGrayImage> &vResultImgPFig,
                                 vector<OpGrayImage> &vResultImgPGnd,
                                 ofstream &ofileSingle, 
                                 bool bDisplayResults )
  /*******************************************************************/
  /* Apply the recognition procedure to the given test image. The    */
  /* function first calls the various preprocessing steps (loading   */
  /* an image, extracting patches, matching to the codebook, etc.)   */
  /* sequentially, then generates votes from the matches and sear-   */
  /* ches for maxima in the Hough space. If the corresponding option */
  /* is selected in the interface, it the applies the MDL-based      */
  /* hypothesis verification stage.                                  */
  /* Results are written into the provided vectors and to disk in an */
  /* ASCII file format.                                              */
  /*******************************************************************/
{
  /*---------------------------*/
  /* Initialize some variables */
  /*---------------------------*/
  //int   nObjWidth     = m_parReco.params()->m_nObjWidth;
  //int   nObjHeight    = m_parReco.params()->m_nObjHeight;

  /*------------------------*/
  /* Process the test image */
  /*------------------------*/
  vResultHypos.clear();
  vResultImgPFig.clear();
  vResultImgPGnd.clear();
  vResultImgSeg.clear();
  vector<Hypothesis>  vResultHyposTight;
  //vector<OpGrayImage> vResultImgSeg;
  //vector<OpGrayImage> vResultImgPFig;
  //vector<OpGrayImage> vResultImgPGnd;
  processTestImg( qsFileName, nImgNumber, vResultHypos, vResultHyposTight,
                  vResultImgSeg, vResultImgPFig, vResultImgPGnd, 
                  bDisplayResults ); 

  //vResultImgPFig.clear();
  //vResultImgPGnd.clear();
    
  /*------------------------------*/
  /* Adapt the bounding box sizes */
  /*------------------------------*/
//   for(unsigned i=0; i<vResultHypos.size(); i++ ) {
//     Hypothesis hypo = vResultHypos[i];
//     /* apply user-specified bounding box size */
//     int width  = (int) floor(nObjWidth*hypo.dScale + 0.5);
//     int height = (int) floor(nObjHeight*hypo.dScale + 0.5);
//     hypo.nBoxX1 = (int)(hypo.x - width/2);
//     hypo.nBoxY1 = (int)(hypo.y - height/2);
//     hypo.nBoxWidth = width;
//     hypo.nBoxHeight = height;

//     vResultHypos[i] = hypo;
//   }   
    

  /*------------------------------------*/
  /* Write the results to a result file */
  /*------------------------------------*/
  writeResultsToDiskScore( ofileSingle, nImgNumber+1, vResultHypos );
  

  /*-------------------------------*/
  /* Display the results on-screen */
  /*-------------------------------*/
  displayRecoResults( vResultHypos, vResultImgSeg, 
                      vResultImgPFig, vResultImgPGnd, bDisplayResults );


  /*--------------------------------*/
  /* Apply the Chamfer verification */
  /*--------------------------------*/
  if( m_parVeri.params()->m_bDoVerif && (vResultHypos.size() > 0) ) {

    vector<QImage>     vQImgs;
    vector<Hypothesis> vVerifiedHypos;
    vector<Hypothesis> vVerifiedHyposTight;
    vector<EdgePtVec>  vVerTemplates;
    vector<int>        vVerTemplateIds;

    int nVerifMethod = m_parVeri.params()->m_nVerifMethod;
    switch( nVerifMethod ) {
    case VERI_CHAMFER:
      verifyHyposTemplate( vResultHypos, vResultHyposTight, 
                           vResultImgSeg, vResultImgPFig, vResultImgPGnd,
                           vVerifiedHypos, vVerifiedHyposTight,
                           vVerTemplates, vVerTemplateIds,
                           vQImgs );
      break;
      
    default:
      cerr << "  Error in ISMReco::processTestImgStd(): "
           << "Unknown verification method (" << nVerifMethod << ")!" << endl;
    }
 

    /*==================================*/
    /* Display the accepted hypotheses */
    /*==================================*/
    cout << "=======================================" << endl;
    cout << "Final Hypotheses:" << endl;
    for(unsigned k=0; k<vVerifiedHypos.size(); k++ ) {
      cout << "  " << setw(2) << k+1 << ". ";
      printHypothesisMDL( vVerifiedHypos[k] );
    }
    cout << "=======================================" << endl;

    /* draw verified hypotheses */
    rsSourceImg->loadImage( m_grayImg.getQtImage(), m_grayImg );
    rsSourceImg->display();
    for(unsigned i=0; i<vVerifiedHyposTight.size(); i++ ) {
      QColor qcol = QColor::QColor(255, 255, 0);

      Hypothesis &hTight = vVerifiedHyposTight[i];
      rsSourceImg->drawRect( hTight.nBoxX1, hTight.nBoxY1, 
                             hTight.nBoxWidth, hTight.nBoxHeight, 
                             qcol, true );
      /* draw the template */
      int pos_x = hTight.nBoxX1;
      int pos_y = hTight.nBoxY1;
      float dScale = hTight.dScale/m_parVeri.params()->m_dTemplateScale;

      // draw template on output //
      OpGrayImage imgScTempl = m_vSilhouettes[vVerTemplateIds[i]];
      int nNewWidth = (int)floor( imgScTempl.width()*dScale + 0.5 );
      imgScTempl = imgScTempl.opRescaleToWidth( nNewWidth );

      int tpl_h = imgScTempl.height();
      int tpl_w = imgScTempl.width();
      int img_h = m_grayImg.height();
      int img_w = m_grayImg.width();

      int minx = max(0, pos_x);
      int miny = max(0, pos_y);
      int maxx = min(pos_x + tpl_w, img_w);
      int maxy = min(pos_y + tpl_h, img_h);
      for( int y = miny; y < maxy; y++ )
        for( int x = minx; x < maxx;  x++ ) {
          float dVal = imgScTempl(x-pos_x, y-pos_y).value();
          if(  dVal != 0.0 ) {
            //if( dVal >= 0.5 )
            int nColVal = (int)floor(255.0*(0.5 + dVal/2.0) + 0.5);
            QColor qcol = QColor::QColor(nColVal, nColVal, 0);
            rsSourceImg->drawPoint( x, y, qcol, true );
          }
        }

    }
    vResultHypos = vVerifiedHyposTight;
    qApp->processEvents();

    if( !vQImgs.empty() && bDisplayResults && m_bShowGUI ) {
      QtImgBrowser *qtCutOutBrowser = new QtImgBrowser( 0,"CutOuts"); 
      qtCutOutBrowser->setGeometry( 950, 550, 300, 350 );
      qtCutOutBrowser->load( vQImgs );
      qtCutOutBrowser->show();
    }
  }
}
    

void ISMReco::processTestImgIDL( QString qsFileName, int nImgNumber,
                                 QString qsResultDir,
                                 vector<Hypothesis> &vResultHypos,
                                 ImgDescr &idInitial, ImgDescr &idTight, 
                                 bool bDisplayResults )
  /*******************************************************************/
  /* Apply the recognition procedure to the given test image. The    */
  /* function first calls the various preprocessing steps (loading   */
  /* an image, extracting patches, matching to the codebook, etc.)   */
  /* sequentially, then generates votes from the matches and sear-   */
  /* ches for maxima in the Hough space. If the corresponding option */
  /* is selected in the interface, it the applies the MDL-based      */
  /* hypothesis verification stage.                                  */
  /*******************************************************************/
{
  /*---------------------------*/
  /* Initialize some variables */
  /*---------------------------*/
  //int   nObjWidth     = m_parReco.params()->m_nObjWidth;
  //int   nObjHeight    = m_parReco.params()->m_nObjHeight;

  /*------------------------*/
  /* Process the test image */
  /*------------------------*/
  vResultHypos.clear();
  vector<Hypothesis>  vResultHyposTight;
  vector<OpGrayImage> vResultImgSeg;
  vector<OpGrayImage> vResultImgPFig;
  vector<OpGrayImage> vResultImgPGnd;
  processTestImg( qsFileName, nImgNumber, vResultHypos, vResultHyposTight, 
                  vResultImgSeg, vResultImgPFig, vResultImgPGnd,
                  bDisplayResults ); 

    
  /*------------------------------*/
  /* Adapt the bounding box sizes */
  /*------------------------------*/
//   for(unsigned i=0; i<vResultHypos.size(); i++ ) {
//     Hypothesis hypo = vResultHypos[i];
//     /* apply user-specified bounding box size */
//     int width  = (int) floor(nObjWidth*hypo.dScale + 0.5);
//     int height = (int) floor(nObjHeight*hypo.dScale + 0.5);
//     hypo.nBoxX1 = (int)(hypo.x - width/2);
//     hypo.nBoxY1 = (int)(hypo.y - height/2);
//     hypo.nBoxWidth = width;
//     hypo.nBoxHeight = height;

//     vResultHypos[i] = hypo;
//   }   
    

  /*------------------------------------*/
  /* Write the results to the idl files */
  /*------------------------------------*/
  idInitial.vRectList.clear();
  idTight.vRectList.clear();
  for(unsigned i=0; i<vResultHypos.size(); i++ ) {
    Hypothesis hypo = vResultHypos[i];

    float dScore = hypo.dScore;
    //if( m_parReco.params()->m_bDoMDL || m_parReco.params()->m_bRejectPFig )
    if( m_bDoMDL || m_bRejectPFig )
      dScore = hypo.dScoreMDL;

      idInitial.vRectList.push_back( Rect( hypo.nBoxX1, hypo.nBoxY1,
                                           hypo.nBoxX1+hypo.nBoxWidth,
                                           hypo.nBoxY1+hypo.nBoxHeight,
                                           dScore,
                                           hypo.nTemplateId ) );
      
      hypo = vResultHyposTight[i];
      idTight.vRectList.push_back( Rect( hypo.nBoxX1, hypo.nBoxY1,
                                         hypo.nBoxX1+hypo.nBoxWidth,
                                         hypo.nBoxY1+hypo.nBoxHeight,
                                         dScore,
                                         hypo.nTemplateId ) );
//     }
  }

  /*----------------------------------------------------*/
  /* Write the results to disk in a simpler file format */
  /*----------------------------------------------------*/
  if( m_bWriteResults || m_bWriteSegs ) {
    ofstream ofile( m_qsDefResultFile.latin1(), 
                    ios_base::out | ios_base::app );
    if( ofile ) {
      for(unsigned i=0; i<vResultHypos.size(); i++ ) {
        Hypothesis &hypo = vResultHypos[i];
        
        /* get 3D information about the hypothesis */
        FeatureVector fvPosI1(3), fvPosI2(3), fvPosI3(3), fvPosI4(3);
        FeatureVector fvDirV1(3), fvObjDir(3);
        FeatureVector fvPosW1(3), fvPosW2(3), fvPosW3(3), fvPosW4(3);
        //float dDist = -1.0;
        //float dSize = -1.0;
        if( m_bCalibAvailable ) {
          // get the object base point in 3D
          fvPosI1.at(0) = hypo.x;
          fvPosI1.at(1) = hypo.y + hypo.nBoxHeight/2;
          fvPosI1.at(2) = 1.0;

          if( m_calCamera.posOnGroundPlane( fvPosI1, fvPosW1 ) ) {
            // project the direction into the GP
            m_calCamera.projectIntoGroundPlane( fvPosI1, fvDirV1 );

            // get the object center base point in 3D
            float dDistCenter = 
              m_vDetectors[hypo.nCategory].params()->m_dDistCenter/m_dWorldScale; //DEF_WORLD_SCALE;
            fvPosW3 = fvPosW1 + fvDirV1*dDistCenter;
            //cout << "    projected dir=" << fvDirV1 << endl;
            //cout << "    distToCenter=" << dDistCenter << endl;
            //cout << "    object center=" << fvPosW3 << endl;
            
            // draw the object center base point in the image
            m_calCamera.world2Img( fvPosW3, fvPosI3 );
            rsSourceImg->drawLine( (int)round(fvPosI1.at(0)), 
                                   (int)round(fvPosI1.at(1)),
                                   (int)round(fvPosI3.at(0)), 
                                   (int)round(fvPosI3.at(1)),
                                   QColor::QColor(255,255,255), true );
            rsSourceImg->drawCross( (int)round(fvPosI3.at(0)), 
                                    (int)round(fvPosI3.at(1)),
                                    QColor::QColor(200,200,200), true );
            
            // get the object top point in 3D
            fvPosI2.at(0) = hypo.x;
            fvPosI2.at(1) = hypo.y - hypo.nBoxHeight/2;
            fvPosI2.at(2) = 1.0;
            FeatureVector fvVPN = m_calCamera.getVPN();
            m_calCamera.intersectWithPlane(fvPosI2, fvVPN, fvPosW1, fvPosW2);
            
            // get the object size and distance
            //getRealObjSize( m_calCamera, hypo, dDist, dSize );
            
            // get the object pose
            int nPose = hypo.nCategory;
            
            // get the object orientation vector in 3D
            float dAngle = -1.0;
            QString qsPoseName = m_vDetectors[nPose].params()->m_qsPoseName;
            int pos = qsPoseName.find("az");
            if( pos>=0 ) { // name is built up after scheme azXXXdeg
              dAngle = -(float)atoi( qsPoseName.mid(pos+2,3) );
              if( hypo.bPoseFlipped )
                dAngle = 180.0 - dAngle;
              dAngle += 90.0;
              dAngle *= M_PI/180.0;
              
              // rotate fvDirV1 by the angle around the GPN
              m_calCamera.rotateInGroundPlane( dAngle, fvDirV1, fvObjDir );
              
              // get a second point along this direction in 3D
              fvPosW4 = fvPosW3 + fvObjDir*(2.0/m_dWorldScale); //DEF_WORLD_SCALE);
              
              // project this point back onto the image plane
              m_calCamera.world2Img( fvPosW4, fvPosI4 );
              
              // draw the object direction in the result image
              rsSourceImg->drawLine( (int)round(fvPosI3.at(0)), 
                                     (int)round(fvPosI3.at(1)),
                                     (int)round(fvPosI4.at(0)), 
                                     (int)round(fvPosI4.at(1)),
                                     QColor::QColor(255,255,255), true );
              rsSourceImg->drawCross( (int)round(fvPosI4.at(0)), 
                                      (int)round(fvPosI4.at(1)),
                                      QColor::QColor(255,255,255), true );
            }
          }
        }
        
        ofile << nImgNumber << "  " << i << "  "
              << hypo.x << "  " << hypo.y << "  " << hypo.dScale << "  "
              << hypo.nCategory << "  "
              << hypo.nBoxX1 << "  " << hypo.nBoxY1 << "  "
              << hypo.nBoxWidth << "  " << hypo.nBoxHeight << "  "
              << hypo.dScore << "  " << hypo.dScoreMDL << "  "
              << hypo.dRealDist << "  " << hypo.dRealSize << "  "
              << fvPosW1.at(0) << "  " << fvPosW1.at(1) << "  " 
              << fvPosW1.at(2) << "  "
          //<< fvPosW2.at(0) << "  " << fvPosW2.at(1) << "  "
          //<< fvPosW2.at(2) << "  "
              << fvPosW3.at(0) << "  " << fvPosW3.at(1) << "  "
              << fvPosW3.at(2) << "  "
              << fvObjDir.at(0) << "  " << fvObjDir.at(1) << "  "
              << fvObjDir.at(2) << "  "
              << endl;
        
      }
      ofile.close();
    }
  }
  

  /*-------------------------------*/
  /* Display the results on-screen */
  /*-------------------------------*/
  displayRecoResults( vResultHypos, vResultImgSeg, 
                      vResultImgPFig, vResultImgPGnd, bDisplayResults );


  /*-----------------------------------*/
  /* Perform single-scale verification */
  /*-----------------------------------*/
  if( m_parVeri.params()->m_bDoVerif && (vResultHypos.size() > 0) ) {

    vector<QImage>     vQImgs;
    vector<Hypothesis> vVerifiedHypos;
    vector<Hypothesis> vVerifiedHyposTight;
    vector<EdgePtVec>  vVerTemplates;
    vector<int>        vVerTemplateIds;

    int nVerifMethod = m_parVeri.params()->m_nVerifMethod;
    switch( nVerifMethod ) {
    case VERI_CHAMFER:
      verifyHyposTemplate( vResultHypos, vResultHyposTight, 
                           vResultImgSeg, vResultImgPFig, vResultImgPGnd,
                           vVerifiedHypos, vVerifiedHyposTight,
                           vVerTemplates, vVerTemplateIds,
                           vQImgs );
      break;
      
    default:
      cerr << "  Error in ISMReco::processTestImgStd(): "
           << "Unknown verification method (" << nVerifMethod << ")!" << endl;
    }

 
    /*==================================*/
    /* Display the accepted hypotheses */
    /*==================================*/
    cout << "=======================================" << endl;
    cout << "Final Hypotheses:" << endl;
    for(unsigned k=0; k<vVerifiedHypos.size(); k++ ) {
      cout << "  " << setw(2) << k+1 << ". ";
      printHypothesisMDL( vVerifiedHypos[k] );
    }
    cout << "=======================================" << endl;
    
    /* draw verified hypotheses */
    rsSourceImg->loadImage( m_grayImg.getQtImage(), m_grayImg );
    rsSourceImg->display();
    for(unsigned i=0; i<vVerifiedHypos.size(); i++ ) {
      QColor qcol = QColor::QColor(255, 255, 0);
      
      Hypothesis &hTight = vVerifiedHyposTight[i];
      rsSourceImg->drawRect( hTight.nBoxX1, hTight.nBoxY1, 
                             hTight.nBoxWidth, hTight.nBoxHeight, 
                             qcol, true );
      /* draw the template */
      int pos_x = hTight.nBoxX1;
      int pos_y = hTight.nBoxY1;
      float dScale = hTight.dScale/m_parVeri.params()->m_dTemplateScale;

      //for( int j=0; j<(int)vVerTemplates[i].size(); j++ ) {
      //  int cx = (int)floor(pos_x + vVerTemplates[i][j].x()*hTight.dScale+0.5);
      //  int cy = (int)floor(pos_y + vVerTemplates[i][j].y()*hTight.dScale+0.5);
      //  rsSourceImg->drawPoint( cx, cy, qcol, true );
      //}

      // draw template on output
      OpGrayImage imgScTempl = m_vSilhouettes[vVerTemplateIds[i]];
      int nNewWidth = (int)floor( imgScTempl.width()*dScale + 0.5 );
      imgScTempl = imgScTempl.opRescaleToWidth( nNewWidth );

      int tpl_h = imgScTempl.height();
      int tpl_w = imgScTempl.width();
      int img_h = m_grayImg.height();
      int img_w = m_grayImg.width();

      int minx = max(0, pos_x);
      int miny = max(0, pos_y);
      int maxx = min(pos_x + tpl_w, img_w);
      int maxy = min(pos_y + tpl_h, img_h);
      for( int y = miny; y < maxy; y++ )
        for( int x = minx; x < maxx;  x++ ) {
          float dVal = imgScTempl(x-pos_x, y-pos_y).value();
          if(  dVal != 0.0 ) {
            //if( dVal >= 0.5 )
            int nColVal = (int)floor(255.0*(0.5 + dVal/2.0) + 0.5);
            QColor qcol = QColor::QColor(nColVal, nColVal, 0);
            rsSourceImg->drawPoint( x, y, qcol, true );
          }
        } 
    }
    qApp->processEvents();

    /* write verified hypotheses to the result files */
    /* (and overwrite initial hypotheses...)         */
    idInitial.vRectList.clear();
    idTight.vRectList.clear();
    for(unsigned i=0; i<vVerifiedHypos.size(); i++ ) {
      Hypothesis hypo = vVerifiedHypos[i];
      
      float dScore = hypo.dScore;
      //if( m_parReco.params()->m_bDoMDL )
      if( m_bDoMDL )
        dScore = hypo.dScoreMDL;
      
      if( m_parVeri.params()->m_bDoVerif )
        dScore = hypo.dScoreMDL;
      
      idInitial.vRectList.push_back( Rect( hypo.nBoxX1, hypo.nBoxY1,
                                           hypo.nBoxX1+hypo.nBoxWidth,
                                           hypo.nBoxY1+hypo.nBoxHeight,
                                           dScore, hypo.nTemplateId ) );
      
      hypo = vVerifiedHyposTight[i];
      idTight.vRectList.push_back( Rect( hypo.nBoxX1, hypo.nBoxY1,
                                         hypo.nBoxX1+hypo.nBoxWidth,
                                         hypo.nBoxY1+hypo.nBoxHeight,
                                         dScore, hypo.nTemplateId ) );

    }
  }  

  /*--------------------------------*/
  /* Write the result image to disk */
  /*--------------------------------*/
  /* prepare the result file name */
  QString qsName = m_sImgName.c_str();
  int pos = qsName.findRev('.');
  if( pos>=0 )
    qsName = qsName.left( pos );
  qsName = qsResultDir + "/" + qsName;

  if( m_bWriteResults ) {
    QImage  qimg = rsSourceImg->getImage();
    bool bOK = qimg.save( qsName+"-detect.png", "PNG" );
    if ( !bOK ) {
      cerr << "WARNING: Result image couldn't be saved. " << endl
           << "Please make sure to enter a valid destination path." << endl;
    }
  }
  
  /*---------------------------------*/
  /* Write the segmentations to disk */
  /*---------------------------------*/
  if( m_bWriteSegs ) {
    /* save all individual segmentations */
    for(unsigned k=0; k<vResultImgSeg.size(); k++ ) {
      QString qsResName = qsName+"-obj"+QString::number(k+1);

#ifdef USE_MATWRITER
      // save the segmentations in Matlab format
      savePFigPGndMatlab( vResultImgPFig[k], vResultImgPGnd[k], 
                          qsResName+".mat" );

#else
      // save p(figure) image
      //saveImage( vResultImgPFig[k], qsResName+"-pfig.png" );
      saveImageAscii( vResultImgPFig[k], qsResName+"-pfig.tab" );

      // save p(ground) image
      //saveImage( vResultImgPGnd[k], qsResName+"-pgnd.png" );
      saveImageAscii( vResultImgPGnd[k], qsResName+"-pgnd.tab" );
#endif      

      // save segmentation image
      //saveImage( vResultImgSeg[k], qsResName+"-seg.png" );
    }

    /* save the final scene segmentation */
    OpGrayImage imgSceneSeg( m_grayImg.width(), m_grayImg.height() );
    for( int y=0; y<m_grayImg.height(); y++ )
      for( int x=0; x<m_grayImg.width(); x++ ) {
        float dMaxVal = 0.0;
        for( int k=0; k<(int)vResultImgSeg.size(); k++ )
          if( vResultImgSeg[k](x,y).value()>dMaxVal )
            dMaxVal = vResultImgSeg[k](x,y).value();
        imgSceneSeg(x,y) = dMaxVal;
      }
    saveImage( imgSceneSeg, qsName+"-scene-seg.png" );
  }
}
    

void ISMReco::displayRecoResults( const vector<Hypothesis> &vResultHypos,
                                  const vector<OpGrayImage> &vResultImgSeg,
                                  const vector<OpGrayImage> &vResultImgPFig,
                                  const vector<OpGrayImage> &vResultImgPGnd,
                                  bool bDisplayResults )
{
  /* prepare for displaying the results */
  vector<OpGrayImage> vResultImgs;
  vector<QImage>      vResultQImgs;
  vector<QImage>      vRefResultImgs;

  /********************************/
  /* Draw the accepted hypotheses */
  /********************************/
  vector<HoughVote> vAllSupporting;
  for(unsigned i=0; i<vResultHypos.size(); i++ ) {
    
    /*--------------------------------*/
    /* Extract the hypothesis support */
    /*--------------------------------*/
    FeatureVector fvWindowPos( 3 );
    if( bDisplayResults ) {
      fvWindowPos.setValue( 0, vResultHypos[i].x );
      fvWindowPos.setValue( 1, vResultHypos[i].y );
      fvWindowPos.setValue( 2, vResultHypos[i].dScale );
      
      OpGrayImage imgSeg  = vResultImgSeg[i];
      OpGrayImage imgPFig = vResultImgPFig[i];;
      OpGrayImage imgPGnd = vResultImgPGnd[i];;

      vRefResultImgs.push_back( vResultImgSeg[i].getQtImage() );
       
      if( m_bDisplaySupport ) {
        if( m_bDrawConfidence ) {
            vResultImgs.push_back ( imgPFig ); 
            vResultQImgs.push_back( imgPFig.getQtImage() ); 
        } else {
            vResultImgs.push_back ( imgPGnd ); 
            vResultQImgs.push_back( imgPGnd.getQtImage() ); 
        }
      }
      
    }  
  }
  qApp->processEvents();

      
  /**********************************************/
  /* Display the detections in a browser window */
  /**********************************************/
  if( bDisplayResults && m_bShowGUI && 
      m_bDisplaySupport && (vResultImgs.size() > 0) ) {
    QtImgBrowser *qtResultBrowser = new QtImgBrowser( 0,"Reco Results"); 
    qtResultBrowser->setGeometry( 950, 200, 300, 350 );
    qtResultBrowser->load( vResultQImgs, vResultImgs );
    qtResultBrowser->show();
  }
  
  if( bDisplayResults && m_bDisplaySegment && (vRefResultImgs.size() > 0) ) {
    /* create a scene segmentation */
    OpGrayImage imgSceneSeg( m_grayImg.width(), m_grayImg.height() );
    for( int y=0; y<m_grayImg.height(); y++ )
      for( int x=0; x<m_grayImg.width(); x++ ) {
        float dMaxVal = 0.0;
        for( int k=0; k<(int)vResultImgSeg.size(); k++ )
          if( vResultImgSeg[k](x,y).value()>dMaxVal )
            dMaxVal = vResultImgSeg[k](x,y).value();
        imgSceneSeg(x,y) = dMaxVal;
      }
        
    vRefResultImgs.push_back( imgSceneSeg.getQtImage() );

    /* create a grayscale segmentation image */
    OpGrayImage imgSegGray = m_grayImg.mul( imgSceneSeg ).div( 255.0 );
    vRefResultImgs.push_back( imgSegGray.getQtImage() );
    rsResultImg->loadImage( imgSceneSeg.getQtImage() );
    rsResultImg->display();

		/* create a colored segmentation image */
    imgSceneSeg.opThresholdOutside ( 100.0, 255.0 );
		QPixmap pmImg;
		pmImg.convertFromImage( m_img ); 
    QBitmap bmMask;
		bmMask.operator=( imgSceneSeg.getQtImage() ); 
		pmImg.setMask( bmMask );
    vRefResultImgs.push_back( pmImg.convertToImage() );

    rsResultImg2->loadImage( pmImg.convertToImage() );
    rsResultImg2->display();
    qApp->processEvents();
  }

  if( bDisplayResults && m_bShowGUI && (vRefResultImgs.size() > 0) ) {
    QtImgBrowser *qtRefResultBrowser = new QtImgBrowser( 0,
                                                        "Reco Results(Ref)"); 
    qtRefResultBrowser->setGeometry( 950, 600, 300, 350 );
    qtRefResultBrowser->load( vRefResultImgs );
    qtRefResultBrowser->show();
  } 
}


Hypothesis ISMReco::computeTightBBox( OpGrayImage imgSeg, 
                                      int nOffX, int nOffY )
  /* Compute a tight bounding box from the segmentation */
{
  Hypothesis result;

  int nObjHeight = m_parReco.params()->m_nObjHeight;
  Histogram hProjX( imgSeg.width(), 0, imgSeg.width()-1 );
  Histogram hProjY( imgSeg.height(), 0, imgSeg.height()-1 );
  for( int y=0; y<imgSeg.height(); y++ )
    for( int x=0; x<imgSeg.width(); x++ ) {
      hProjX.incrementValue( x, imgSeg(x,y).value() );
      hProjY.incrementValue( y, imgSeg(x,y).value() );
    }
  result.nBoxX1     = ((int)hProjX.getQuantile( 0.01, true ) + nOffX);
  result.nBoxWidth  = ((int)hProjX.getQuantile( 0.01, false ) + nOffX - 
                       result.nBoxX1);
  result.nBoxY1     = ((int)hProjY.getQuantile( 0.01, true ) + nOffY);
  result.nBoxHeight = ((int)hProjY.getQuantile( 0.01, false ) +nOffY - 
                       result.nBoxY1);

  result.x      = result.nBoxX1 + result.nBoxWidth/2;
  result.y      = result.nBoxY1 + result.nBoxHeight/2;
  result.dScale = ( (result.nBoxHeight/(float)nObjHeight) * 1.02 ); 
                   // 0.5*(result.nBoxWidth/(float)m_nObjWidth + 
                   //      result.nBoxHeight/(float)m_nObjHeight);

  return result;
}


void ISMReco::countPatches( Hypothesis &hypo, unsigned nIdx,
                            const vector<HoughVote> &vSupporting )
{
  /* Count the number of patches that contributed to the hypothesis */
  vector<bool> vContrib( m_vvPointsInside[nIdx].size(), false );
  for(unsigned k=0; k<vSupporting.size(); k++ ) {
    int nImgPointId = vSupporting[k].getImgPointId();
    vContrib[nImgPointId] = true;
  }

  long nNumContrib = 0;
  for(unsigned i=0; i<vContrib.size(); i++ )
    if( vContrib[i] )
      nNumContrib++;

  /* Count the number of patches that fall inside the bounding box */
  long nNumInside = 0;
  int  radx = (int)floor( (hypo.nBoxWidth/2)*1.1 + 0.5 );
  int  rady = (int)floor( (hypo.nBoxHeight/2)*1.1 + 0.5 );
  int  minx = hypo.x - radx;
  int  miny = hypo.y - rady;
  int  maxx = hypo.x + radx;
  int  maxy = hypo.y + rady;
  for(unsigned i=0; i<m_vvPointsInside[nIdx].size(); i++ ) {
    InterestPoint &pt = m_vvPointsInside[nIdx][i];
    if( (pt.x>=minx) && (pt.y>=miny) && (pt.x<=maxx) && (pt.y<=maxy) )
      nNumInside++;
  }

  /* Compute the voting score for this cue */
  float dScore = 0.0;
  for(unsigned k=0; k<vSupporting.size(); k++ ) {
    dScore += vSupporting[k].getValue();
  }  
  
  /* Print a report */
  cout << "        cue " << nIdx << ": score=" << setprecision(4) << dScore 
       << ", #contrib=" << nNumContrib << "/" << nNumInside << " (" 
       << setprecision(3) << 100.0*nNumContrib/((float)nNumInside)
       << "%)" << endl;
}


/*---------------------------------------------------------*/
/*                   Supporting Functions                  */
/*---------------------------------------------------------*/


void ISMReco::drawHypothesis( const Hypothesis &hypo, const QColor &col, 
                              bool bPermanent )
{
  rsSourceImg->drawRect( hypo.nBoxX1, hypo.nBoxY1, 
                         hypo.nBoxWidth, hypo.nBoxHeight,
                         bPermanent );
  qApp->processEvents();
}


void ISMReco::refreshSrcImg()
{
  rsSourceImg->loadImage( m_qsourceImg, m_grayImg );
  rsSourceImg->display();
  qApp->processEvents();
}


void ISMReco::displayResultImg( const QImage &qimg )
{
  m_resultImg  = OpGrayImage( qimg );
  m_qresultImg = qimg;
  rsResultImg->loadImage( qimg );
  rsResultImg->display();
  qApp->processEvents();
}


void ISMReco::displayResultImg( const QImage &qimg, OpGrayImage img)
{
  m_resultImg  = img;
  m_qresultImg = qimg;
  rsResultImg->loadImage( qimg, img );
  rsResultImg->display();
  qApp->processEvents();
}


void ISMReco::displayScaleFootprint()
  /*******************************************************************/
  /* Display a scale footprint of the current interest point detec-  */
  /* tor. That is, show a histogram of the scales on which interest  */
  /* points were found.                                              */
  /*******************************************************************/
{
  /* initialize scale histograms */
  VisualHistogram hPointScales( 100, 1.0, 9.0 );

  /* initialize image vectors */
  vector<QImage> vQImgs;
  QImage imgQScaleHisto; 

  /* Create a histogram for each cue */
  for(unsigned nIdx=0; nIdx<m_nNumCues; nIdx++ ) {
    /* create a scale footprint for the interest points */
    for(unsigned i=0; i<m_vvPointsInside[nIdx].size(); i++ )
      hPointScales.insertValue( m_vvPointsInside[nIdx][i].scale );
    hPointScales.drawHistogram( imgQScaleHisto );
    vQImgs.push_back( imgQScaleHisto );
  }

  /* display the footprints in a browser window */
  if( m_bShowGUI ) {
    QtImgBrowser *qtBrowser = new QtImgBrowser( 0, "Scale Footprints" ); 
    qtBrowser->setGeometry( 950, 200, 300, 350 );
    qtBrowser->load( vQImgs );
    
    qtBrowser->show();  
  }
}


int ISMReco::transformPoint( InterestPoint &ipt )
  /*******************************************************************/
  /* Support function: Transform a patch point to the vector repre-  */
  /* senting the result image.                                       */
  /*******************************************************************/
{
  int pos;
  pos = ( ipt.y * m_qresultImg.width() );
  pos += ipt.x;
  return pos;
}


int  ISMReco::transformPoint( int w, int h )
  /*******************************************************************/
  /* Support function: Transform patch coordinates to the correspon- */
  /* ding vector index.                                              */
  /*******************************************************************/
{
  int pos;
  pos = h * m_qresultImg.width();
  pos += w;
  return pos;
}


float ISMReco::computeBoundingBoxOverlap( Hypothesis h1, Hypothesis h2 )
  /*******************************************************************/
  /* Compute the overlap between two bounding boxes with the         */
  /* intersection criterion.                                         */
  /*******************************************************************/
{
  int common_x1 = max( h1.nBoxX1, h2.nBoxX1 );
  int common_y1 = max( h1.nBoxY1, h2.nBoxY1 );
  int common_x2 = min( h1.nBoxX1+h1.nBoxWidth,  h2.nBoxX1+h2.nBoxWidth );
  int common_y2 = min( h1.nBoxY1+h1.nBoxHeight, h2.nBoxY1+h2.nBoxHeight );

  float area1 = (float)h1.nBoxWidth * h1.nBoxHeight;
  float area2 = (float)h2.nBoxWidth * h2.nBoxHeight;
  float common_area;
  if( (common_x2 > common_x1) && (common_y2 > common_y1) )
    common_area = (common_x2-common_x1)*(common_y2-common_y1);
  else
    common_area = 0.0;

  float inter = 0.5*(common_area/area1 + common_area/area2);
  return inter;
}


/*---------------------------------------------------------*/
/*                        Test Series                      */
/*---------------------------------------------------------*/

void ISMReco::performIDLTestSeries()
  /*******************************************************************/
  /* Perform a test series from an experiment file in the idl for-   */
  /* mat.                                                            */
  /*******************************************************************/
{ 
  /********************************/
  /*   Open the experiment file   */
  /********************************/
  QString qsExpFile = 
    QFileDialog::getOpenFileName( DIR_IMAGES.c_str(), 
                                  "Experiment files (*.idl);;All files (*.*)",
                                  this, "save1", 
                                  "Select Experiment File (IDL)" );
  if( qsExpFile == "" ) {
    cerr << "ERROR: No experiment file selected!" << endl;
    return;
  }
  
  /*****************************/
  /*   Open the result files   */
  /*****************************/
  QString qsResultFile1 = 
    QFileDialog::getSaveFileName( DIR_RESULTS.c_str(), 
                                  "Result files (*.idl);;All files (*.*)",  
                                  this, "save1", 
                                  "Select Result File" );

  /**********************************/
  /*   Ask for a result directory   */
  /**********************************/
  QString qsSaveDirName    = "";
  QString qsTextResultFile = "";
  if( m_bWriteResults || m_bWriteSegs ) {
    qsSaveDirName = QFileDialog::getExistingDirectory( DIR_RESULTS.c_str(), 
                                                       this, "savedir", 
                                       "Select directory for result images");
    if ( qsSaveDirName.isEmpty() )
      return;

    qsTextResultFile = QFileDialog::getSaveFileName( qsSaveDirName, 
                                  "Result files (*.txt);;All files (*.*)",  
                                                      this, "save1", 
                                   "Select Result Text File" );

    if ( qsTextResultFile.isEmpty() )
      return;
  }

  performIDLTestSeries( qsExpFile, qsResultFile1, 
                        qsSaveDirName, qsTextResultFile );
}


void ISMReco::performIDLTestSeries( QString qsExpFile, QString qsResultFile1,
                                    QString qsSaveDirName, 
                                    QString qsTextResultFile )
  /*******************************************************************/
  /* Perform a test series from an experiment file in the idl for-   */
  /* mat.                                                            */
  /*******************************************************************/
{ 
  /********************************/
  /*   Load the experiment file   */
  /********************************/
  ImgDescrList idlExperiment( qsExpFile.latin1() );

  /* extract the path from the idl file name */
  string sFileName( qsExpFile.latin1() );
  string sPath;
  unsigned pos = sFileName.rfind( "/" );
  if( pos != string::npos )
    sPath = sFileName.substr( 0, pos + 1 );
  QString qsExpPath = sPath.c_str();

  // and call the main function
  performIDLTestSeries( idlExperiment, qsExpPath, qsResultFile1, qsSaveDirName,
                        qsTextResultFile );
}


void ISMReco::performIDLTestSeries( ImgDescrList &idlExperiment, 
                                    QString qsExpPath,
                                    QString qsResultFile1,
                                    QString qsSaveDirName, 
                                    QString qsTextResultFile )
  /*******************************************************************/
  /* Perform a test series from an experiment file in the idl for-   */
  /* mat.                                                            */
  /*******************************************************************/
{ 
  /*****************************/
  /*   Open the result files   */
  /*****************************/
  ofstream ofInitial( qsResultFile1 );
  if( ofInitial == 0 ) {
    cerr << "ERROR: Couldn't open file " << qsResultFile1 << "!" << endl;
    return;
  }
  ofInitial.close();

//   ofstream ofRefined( qsResultFile2 );
//   if( ofRefined == 0 ) {
//     cerr << "ERROR: Couldn't open file " << qsResultFile2 << "!" << endl;
//     return;
//   }
//   ofRefined.close();
 
  /**********************************/
  /*   Ask for a result directory   */
  /**********************************/
  m_qsDefResultFile = qsTextResultFile;
  if( m_bWriteResults || m_bWriteSegs ) {
    // check the result dir
    if( qsSaveDirName.isEmpty() ) {
      cerr << "ERROR: Result dir requested, but dir name is empty!"
           << endl;
      return;
    }

    // check if the result dir exists
    QDir qdSaveDir( qsSaveDirName );
    if( qdSaveDir.exists() == false ) {
      cout << "  Creating result directory..." << endl;
      qdSaveDir.mkdir( qsSaveDirName );
    }

    // check the text result file
    if( m_qsDefResultFile.isEmpty() ) {
      cerr << "ERROR: Result dir requested, but text result file is empty!"
           << endl;
      return;
    }

    // delete an old result file if one exists
    ofstream ofile( m_qsDefResultFile.latin1() );
    ofile.close();
  }
  
  
  /********************************/
  /*   Load the experiment file   */
  /********************************/
  //ImgDescrList idlExperiment( qsExpFile.latin1() );

  /* and make two copies for the results */
  ImgDescrList idlInitial( idlExperiment );
  ImgDescrList idlRefined( idlExperiment );

  /* extract the path from the idl file name */
//   string sFileName( qsExpFile.latin1() );
//   string sPath;
//   unsigned pos = sFileName.rfind( "/" );
//   if( pos != string::npos )
//     sPath = sFileName.substr( 0, pos + 1 );
  string sPath = qsExpPath.latin1();

  /*******************************/
  /*   Process all test images   */
  /*******************************/
  vector< vector<Hypothesis> > vvHypoSingle  ( idlExperiment.size() );

  cout << "    Debugging info for idlExperiment:" << endl;
  idlExperiment.print();

  /* process all test images */
  for( int i=0; i<idlExperiment.size(); i++ ) {
    cout << "  Processing image " << i+1 << " of " << idlExperiment.size() 
         << "..." << endl;
    cout << endl;
    
    if( idlExperiment[i].sName.empty() ) continue;

    string sFileName = (idlExperiment[i].sName[0]=='/') ?  
           idlExperiment[i].sName : sPath + idlExperiment[i].sName;
    sFileName = sPath + idlExperiment[i].sName;
    idlInitial[i].sName = sFileName;
    idlRefined[i].sName = sFileName;

    processTestImgIDL( sFileName.c_str(), i,
                       qsSaveDirName,
                       vvHypoSingle[i], 
                       idlInitial[i], idlRefined[i],
                       false );

    /* save the result files (in case the program crashes) */
    idlInitial.save( qsResultFile1.latin1() );
    //idlRefined.save( qsResultFile2.latin1() );

    /* free some memory */
    m_vActiveVotes.clear();
    m_vHyposSingle.clear();
  }


  /*****************************/
  /*   Save the result files   */
  /*****************************/
  idlInitial.save( qsResultFile1.latin1() );
  //idlRefined.save( qsResultFile2.latin1() );

  cout << "================================" << endl;
}


void ISMReco::processImageSeries()
  /*******************************************************************/
  /* Process a series of images (specified by an experiment file, as */
  /* described below) and write result hypotheses and segmentations  */
  /* to disk for every image.                                        */
  /*******************************************************************/
{ 
  QString qsFileName = 
    QFileDialog::getOpenFileName( DIR_IMAGES.c_str(), 
                                  "Experiment files (*.txt);;All files (*.*)",
                                  this, "testseries", 
                                  "Load 'Test series' file");
  if ( qsFileName.isEmpty() )
    return;
  
  QString qsSaveDirName = 
    QFileDialog::getExistingDirectory( DIR_RESULTS.c_str(), 
                                       this, "testseries-savedir", 
                                       "Specify directory for result files");
  if ( qsSaveDirName.isEmpty() )
    return;
  
  /********************************/
  /*   Load the experiment file   */
  /********************************/
  /* (with image names and annotations) */
  vector<string>               vImgNames;
  vector< vector<Hypothesis> > vvAnnots;

  loadExperimentFile( qsFileName, vImgNames, vvAnnots );

  /* extract the path from the file name */
  string sFileName( qsFileName.latin1() );
  string sPath;
  unsigned pos = sFileName.rfind( "/" );
  if( pos != string::npos )
    sPath = sFileName.substr( 0, pos + 1 );

  /*******************************************/
  /*   Print ground truth for verification   */
  /*******************************************/
  cout << "  Path='" << sPath << "'." << endl;
  for(unsigned i=0; i<vImgNames.size(); i++ ) {
    cout << "  " << i+1 << ". file='" << vImgNames[i] << "'";

    for(unsigned j=0; j<vvAnnots[i].size(); j++ )
      cout << ", Categ=" << vvAnnots[i][j].nCategory << " at (" 
           << vvAnnots[i][j].x << "," << vvAnnots[i][j].y << ")";
    cout << endl;
  }
  cout << endl;

  /****************************/
  /*  Open the result files   */
  /****************************/
  QString qsResultFile1 = 
    QFileDialog::getSaveFileName( DIR_RESULTS.c_str(), 
                                  "Result files (*.tab);;All files (*.*)",  
                                  this, "save1", 
                                  "Select Result File for Single Voting" );

  ofstream ofSingle( qsResultFile1 );
  if( ofSingle == 0 ) {
    cerr << "ERROR: Couldn't open file " << qsResultFile1 << "!" << endl;
    return;
  }

  QString qsResultFile3;
  ofstream ofDetect;
  if( m_bWriteDetections ) {
    qsResultFile3 = 
      QFileDialog::getSaveFileName( DIR_RESULTS.c_str(), 
                                    "Result files (*.tab);;All files (*.*)",  
                                    this, "save1", 
                                    "Select Protocol File for Detections" );
    
    ofDetect.open( qsResultFile3 );
    if( ofDetect == 0 ) {
      cerr << "ERROR: Couldn't open file " << qsResultFile3 << "!" << endl;
      return;
    }
  }


  /*******************************/
  /*   Process all test images   */
  /*******************************/
  for(unsigned i=0; i<vImgNames.size(); i++ ) {
    cout << "  Processing image " << i+1 << " of " << vImgNames.size() 
         << "..." << endl;
    cout << endl;
    string sFileName = sPath + vImgNames[i];

    vector<OpGrayImage> vImgSegment;
    vector<OpGrayImage> vImgPFig;
    vector<OpGrayImage> vImgPGnd;
    processTestImgStd( sFileName.c_str(), i, 
                       m_vHyposSingle, vImgSegment, vImgPFig, vImgPGnd, 
                       ofSingle, false );

    /*------------------------------*/
    /* Write the detection protocol */
    /*------------------------------*/
    if( m_bWriteDetections ) {
      ofDetect << sFileName << endl;
      ofDetect << m_vHyposSingle.size() << endl;
    }
    
    /*------------------------------------------------*/
    /* create the segmentation for the top hypotheses */
    /*------------------------------------------------*/
    /* prepare the file name */
    unsigned posDir = sFileName.rfind( '/', string::npos );
    string   sSaveFileName;
    if( posDir != string::npos )
      sSaveFileName = sFileName.substr( posDir+1, sFileName.length()-posDir-1);
    unsigned posDot = sSaveFileName.rfind( '.', string::npos );
    if( posDot != string::npos )
      sSaveFileName.erase( posDot, string::npos );
    QString qsSaveFileName = sSaveFileName.c_str();
    
    /*--------------------------------*/
    /* Save the image with detections */
    /*--------------------------------*/
    QString qsExtension;
    qsExtension = "-detections.png";
    rsSourceImg->getImage().save( qsSaveDirName + "/" + qsSaveFileName + 
                                  qsExtension, "PNG" );

    FeatureVector fvWindowPos( 3 );
    //OpGrayImage imgAllSupport( m_grayImg.width(), m_grayImg.height() );
    OpGrayImage imgAllSegment( m_grayImg.width(), m_grayImg.height() );
    OpGrayImage imgTemp( m_grayImg.width(), m_grayImg.height() );
    //vector<OpGrayImage> vImgSupport;
    //vector<OpGrayImage> vImgSegment;
    //vector<OpGrayImage> vImgPFig;
    //vector<OpGrayImage> vImgPGnd;
    vector<OpGrayImage> vImgVisualize;
    vector<float> vFigArea( m_vHyposSingle.size() );
    vector<float> vSumPFig( m_vHyposSingle.size() );
    //vector<HoughVote> vAllSupporting;
    for( int j=0; j<(int)m_vHyposSingle.size(); j++ ) {
      cout << "  Processing hypothesis " << j+1 << " of " 
           << m_vHyposSingle.size() << "..." << endl;

      /*------------------------------*/
      /* Write the detection protocol */
      /*------------------------------*/
      if( m_bWriteDetections ) {
        ofDetect << m_vHyposSingle[j].dScore << " "
                 << m_vHyposSingle[j].dScoreMDL << " "
                 << m_vHyposSingle[j].x << " "
                 << m_vHyposSingle[j].y << " "
                 << m_vHyposSingle[j].dScale << " "
                 << m_vHyposSingle[j].nBoxX1 << " " 
                 << m_vHyposSingle[j].nBoxY1 << " " 
                 << m_vHyposSingle[j].nBoxWidth << " " 
                 << m_vHyposSingle[j].nBoxHeight << " "
                 << m_vHyposSingle[j].nTemplateId << endl;
      }

      /* recover the hypothesis positions */
      fvWindowPos.setValue(0, m_vHyposSingle[j].x );
      fvWindowPos.setValue(1, m_vHyposSingle[j].y );
      fvWindowPos.setValue(2, m_vHyposSingle[j].dScale );

      /*-----------------------------------*/
      /* Save the individual segmentations */
      /*-----------------------------------*/
      cout << "    Saving segmentation images..." << endl;      
      QString qsExtension;
      qsExtension.sprintf("-detect%02d", j );
      QString qsMatlabFName = ( qsSaveDirName + "/" + qsSaveFileName + 
                                qsExtension );
        
      /* save the segmentation */
      saveImageAscii( vImgSegment[j], (qsMatlabFName + "-seg.tab").latin1() );
      saveImage( vImgSegment[j], (qsMatlabFName + "-seg.png").latin1() );
      
      /* save the probabilities for "figure" */
      saveImageAscii( vImgPFig[j], (qsMatlabFName + "-pfig.tab").latin1() );
      saveImage( vImgPFig[j], (qsMatlabFName + "-pfig.png").latin1() );
      
      /* save the probabilities for "ground" */
      saveImageAscii( vImgPGnd[j], (qsMatlabFName + "-pgnd.tab").latin1() );
      saveImage( vImgPGnd[j], (qsMatlabFName + "-pgnd.png").latin1() );
    }
    
    /*---------------------------*/
    /* Save the "scene pictures" */
    /*---------------------------*/
    /* create a scene segmentation with the max operator */
    OpGrayImage imgSegMax( imgAllSegment.width(), imgAllSegment.height() );
    for( int y=0; y<imgSegMax.height(); y++ )
      for( int x=0; x<imgSegMax.width(); x++ ) {
        float dMax = 0.0;
        for(unsigned k=0; k<vImgSegment.size(); k++ )
          if( vImgSegment[k](x,y).value() > dMax ) 
            dMax = vImgSegment[k](x,y).value();
        imgSegMax(x,y) = dMax;
      }

    saveImage( imgSegMax, string((qsSaveDirName + "/" + qsSaveFileName + 
                                  "-scene-seg-max.png" ).latin1()) );    



    /*---------------------------*/
    /*   Refine the hypotheses   */
    /*---------------------------*/
//     if( m_bRefineHypothesis && (m_vHyposSingle.size()>0) ) {
//       refineHypotheses( false );
      
//       saveImage( m_resultImg, string((qsSaveDirName + "/" + qsSaveFileName + 
//                                       "-scene-refinedseg.png" ).latin1()) );
//       saveSegmentationsMatlab( qsSaveDirName + "/" + qsSaveFileName + 
//                                "-scene-refinedseg.tab" );
//     }

  }


  /******************************/
  /*   Close the result files   */
  /******************************/
  ofSingle.close();
  if( m_bWriteDetections )
    ofDetect.close();
}


void ISMReco::loadExperimentFile( QString qsFileName, 
                                  vector<string> &vImgNames, 
                                  vector< vector<Hypothesis> > &vvAnnots )
  /*******************************************************************/
  /* Read in an experiment file containing a list of images to be    */
  /* processed.                                                      */
  /*******************************************************************/
{
  cout << "ISMReco::loadExperimentFile() called." << endl;

  ifstream ifile( qsFileName.latin1() );
  if ( !ifile ) {
    cerr << "  No corresponding experiment file (*.txt) found." << endl;
    return;
  }
  
  vImgNames.clear();
  vvAnnots.clear();
  vector<Hypothesis> tmp;
  int nCountImgs = 0;

  while( ifile.peek() != EOF ) {
    string line;
    getline(ifile, line );
    
    /* process the current line */
    cout << "  Processing line " << nCountImgs << "..." << endl;
    vector<string> vTokens = extractListItems( line );
    cout << "    found " << vTokens.size() << " entries in line... " << endl;
    
    if( (vTokens.size() < 1) || (vTokens[0].empty()) )
      continue;
    else {
      cout << "    found image name:'" << vTokens[0] << "'." << endl;
      vImgNames.push_back( vTokens[0] );
      nCountImgs++;

      vvAnnots.push_back( tmp );

      if( vTokens.size() < 6 ) // no annotations
        continue;

      cout << "    Preparing Annotations...." << endl;
      /* extract the annotations */
      unsigned nCount = 0;
      while( vTokens.size() >= 1+(nCount+1)*5 ) {
        cout << "    Extracting Annotation " << nCount << "...." << endl;
        Hypothesis newAnnot;
        
        int nCategory = atoi(vTokens[1+nCount*5 + 0].c_str());
        int nPosX1    = atoi(vTokens[1+nCount*5 + 1].c_str());
        int nPosY1    = atoi(vTokens[1+nCount*5 + 2].c_str());
        int nWidth    = atoi(vTokens[1+nCount*5 + 3].c_str());
        int nHeight   = atoi(vTokens[1+nCount*5 + 4].c_str());
      
        newAnnot.nBoxX1     = nPosX1;
        newAnnot.nBoxY1     = nPosY1;
        newAnnot.nBoxWidth  = nWidth;
        newAnnot.nBoxHeight = nHeight;

        newAnnot.x = nPosX1 + nWidth/2;
        newAnnot.y = nPosY1 + nHeight/2;
        newAnnot.dScore    = -1.0;
        newAnnot.nCategory = nCategory;
        newAnnot.nPose     = -1;
        vvAnnots[nCountImgs-1].push_back( newAnnot );
        nCount++;
      }
    }
  }
  cout << "  found " << nCountImgs << " entries." << endl;
  
  cout << "ISMReco::loadExperimentFile() done." << endl;  
}


void ISMReco::listenToSocket()
{


}
