/*********************************************************************/
/*                                                                   */
/* FILE         scmatcher.cc                                         */
/* AUTHORS      Bastian Leibe                                        */
/* EMAIL        leibe@informatik.tu-darmstadt.de                     */
/*                                                                   */
/* CONTENT      Interleaved Object Categorization and Segmentation   */
/*              with an Implicit Shape Model.                        */
/*              The program performs simultaneous recognition and    */
/*              segmentation of canonical views of categorical ob-   */
/*              jects, such as sideviews of cars or cows. Prior to   */
/*              recognition, a codebook of local appearance must be  */
/*              generated by the 'clusterer' program. This version   */
/*              of the code currently just handles objects at a      */
/*              single scale.                                        */
/*                                                                   */
/*              An explanation of the algorithm can be found in the  */
/*              following papers:                                    */
/*                                                                   */
/*              Bastian Leibe and Bernt Schiele,                     */
/*              Interleaved Object Categorization and Segmentation.  */
/*              In Proc. British Machine Vision Conference (BMVC'03) */
/*              Norwich, GB, Sept. 9-11, 2003.                       */
/*                                                                   */
/*              Bastian Leibe and Bernt Schiele,                     */
/*              Combined Object Categorization and Segmentation with */
/*              an Implicit Shape Model.                             */
/*              submitted to ECCV'04 Workshop on Statistical Lear-   */
/*              ning in Computer Vision, Prague, May 2004.           */
/*                                                                   */
/* BEGIN        Tue Nov 05 2002                                      */
/* LAST CHANGE  Sat Jul 03 2004                                      */
/*                                                                   */
/*********************************************************************/


/****************/
/*   Includes   */
/****************/
#include <iostream>
#include <iomanip>
#include <math.h>
#include <stdlib.h>
#include <string>
#include <algorithm>

#include <qapplication.h>
#include <qfiledialog.h>
#include <qcolor.h>
#include <qpainter.h>
#include <qstring.h>
#include <qstringlist.h>
#include <qinputdialog.h>

#include <qtmacros.hh>
#include <qtcoordlabel.hh>
#include <qtimgbrowser.hh>
#include <opgrayimage.hh>

#include <opharrisimage.hh>
#include <featurevector.hh>
#include <pyramidscalespace.hh>
#include <visualhistogram.hh>
#include <pca.hh>
#include <featurematrix.hh>
#include <dogscalespace.hh>
#include <edgesift.hh>
#include <imgdescrlist.hh>
#include <Candidate.h>
#include <chamfermatching.h>
#include <occurrences.hh>

//#include "gauss.hh"
#include "unixtools.hh"
//#include "parts.hh"
#include "scmatcher.hh"


/*******************/
/*   Definitions   */
/*******************/


#define SSLEVEL              4   // depth of pyramid scale space
#define SSMINSIZE            9   // minimal size of image patch


/*===================================================================*/
/*                         Class ISMReco                           */
/*===================================================================*/

/***********************************************************/
/*                          Slots                          */
/***********************************************************/

/*---------------------------------------------------------*/
/*                Loading Images / Codebooks               */
/*---------------------------------------------------------*/

void ISMReco::loadImage()
  /*******************************************************************/
  /* Load a new test image.                                          */
  /*******************************************************************/
{
  m_qsLastImage = QFileDialog::getOpenFileName( m_qsLastImage, 
					      "Images (*.png *.xpm *.jpg *.ppm);;all files (*.*)",
                 this);
  if ( m_qsLastImage.isEmpty() )
    return;

  loadImage( m_qsLastImage );
}


void ISMReco::loadImage( QString qsFileName )
  /*******************************************************************/
  /* Load a new test image (including its segmentation mask, if one  */
  /* exists).                                                        */
  /*******************************************************************/
{
  cout << "  Loading image '" << qsFileName << "'..." << endl;
  m_img.load( qsFileName );

  /* if possible load the corresponding segmentation map */
  QString qsMapName( qsFileName );
  int posDir = qsMapName.findRev( '/' );
  QString qsCurrentDir = qsMapName.left( posDir+1 );
  qsMapName = qsMapName.right( qsMapName.length() - posDir - 1 );
  QString qsMapDir("maps/");
  qsCurrentDir.append( qsMapDir );
  posDir = qsMapName.findRev( '.' );
  if ( posDir >= 0 ) 
    qsMapName = qsMapName.left( posDir );
  QString qsEnd("-map");
  qsMapName.append( qsEnd );
  QString qsExt(".png");
  qsMapName.append( qsExt );
  qsCurrentDir.append( qsMapName );

  QFile mapfile( qsCurrentDir );
  if ( mapfile.exists() == false ) {
    cout << "    No corresponding segmentation map found." << endl;
    m_bMapsOn = false;
    OpGrayImage imgEmpty( m_grayImg.width(), m_grayImg.height() );
    m_grayImgMap = imgEmpty;
  }
  else {
    cout << "    Corresponding segmentation map found." << endl;
    m_bMapsOn = true;
    QImage imgMap;
    imgMap.load( qsCurrentDir );
    OpGrayImage grayImgMap( imgMap );
    m_grayImgMap = grayImgMap;
  }
   
  /* store image name (abbreviated) */
  unsigned pos;
  string tmpstr( qsFileName.latin1() );
  if ( ( pos = tmpstr.rfind( "/" )) != string::npos ) {
    if ( tmpstr.at(pos+3) != string::npos )
      tmpstr = tmpstr.substr( pos+1, 3);
    else
      tmpstr = "Img";
  }
  else
    tmpstr = "Img";
  m_sImgNameShort = tmpstr;
  
  /* store long image name */
  string sFileName( qsFileName.latin1() );
  int    len  = (int)sFileName.length();
  int    pos1 = (int)sFileName.rfind("/");
  int    pos2 = (int)sFileName.rfind("/", pos1-1);
  m_sImgName = "";
  m_sImgPath = "";
  m_sImgFullName = sFileName;
    if( pos1 != (int)string::npos ) {
    m_sImgName = sFileName.substr( pos1+1, len-pos1 );
    if( pos2 != (int)string::npos )
      m_sImgPath = sFileName.substr( pos2+1, pos1-pos2-1 );
  }

  /* convert to OpGrayImage structure */
  OpGrayImage grayImg( m_img );
  /* convert back to QImage structure */
  m_qsourceImg = grayImg.getQtImage();
  m_grayImg = grayImg;

  /* display */
  rsSourceImg->loadImage( m_qsourceImg, grayImg );
  rsSourceImg->display();

  /* create an empty result image */
  OpGrayImage imgBlack( m_img.width(), m_img.height() );
  m_resultImg = imgBlack;
  m_qresultImg = m_resultImg.getQtImage();
  rsResultImg->loadImage( m_qresultImg, m_resultImg );
  rsResultImg->display();

  cout << "  done." << endl;
}


void ISMReco::loadImageBBox( QString qsName, const Rect &rBBox )
{
  // load the image
  loadImage( qsName );

  // rescale it so that the object has uniform size
  cout << "  Object bbox: (" << rBBox.x1 << "," << rBBox.y1 
       << "," << rBBox.x2 << "," << rBBox.y2 << ")" << endl;
  int w = abs(rBBox.x1 - rBBox.x2);
  int h = abs(rBBox.y1 - rBBox.y2);
  
  if( w==0 || h==0 ) {
    cerr << "WARNING in ISMReco::loadImageBBox(): "
         << "bbox has size zero!" << endl;
    return;
  }

  float dFactor=1.0;
  if( m_nFixObjDim==OBJDIM_WIDTH )
    dFactor = ((float)m_nObjWidth/(float)w);
  else
    dFactor = ((float)m_nObjHeight/(float)h);

  // rescale the input image
  cout << "  Rescaling the image by a factor of " << dFactor << "..." << endl;
  m_grayImg = m_grayImg.opRescaleToWidth( (int)round(m_grayImg.width()*
                                                     dFactor) );
  m_img = m_grayImg.getQtImage();

  // compute the new bbox in the rescaled image
  Rect rBBNew( (int)round(rBBox.x1*dFactor), (int)round(rBBox.y1*dFactor), 
               (int)round(rBBox.x2*dFactor), (int)round(rBBox.y2*dFactor), 
               0.0, -1 );

  // limit the bbox to lie fully inside the image
  int wnew = m_grayImg.width()-1;
  int hnew = m_grayImg.height()-1;
  if( rBBNew.x1<0 )    rBBNew.x1=0;
  if( rBBNew.x1>wnew ) rBBNew.x1=wnew;
  if( rBBNew.y1<0 )    rBBNew.y1=0;
  if( rBBNew.y1>hnew ) rBBNew.y1=hnew;
  if( rBBNew.x2<0 )    rBBNew.x2=0;
  if( rBBNew.x2>wnew ) rBBNew.x2=wnew;
  if( rBBNew.y2<0 )    rBBNew.y2=0;
  if( rBBNew.y2>hnew ) rBBNew.y2=hnew;

  cout << "  New object bbox: (" << rBBNew.x1 << "," << rBBNew.y1 
       << "," << rBBNew.x2 << "," << rBBNew.y2 << ")" << endl;

  if( m_bMapsOn ) {
    // if a segmentation map is available, also rescale it
    m_grayImgMap = m_grayImgMap.opRescaleToWidth( (int)round(m_grayImg.width()*
                                                             dFactor) );

  } else {
    // create an artificial segmentation map with a blurred elliptical prior
    m_grayImgMap = OpGrayImage( m_grayImg.width(), m_grayImg.height() );
    
    // draw an ellipse
    int a = (int)round(abs(rBBNew.x1 - rBBNew.x2)*0.5);
    int b = (int)round(abs(rBBNew.y1 - rBBNew.y2)*0.5);
    m_grayImgMap.drawEllipse( (rBBNew.x1+rBBNew.x2)/2, 
                              (rBBNew.y1+rBBNew.y2)/2, a, b, 1.0 );

    // fill it 
    m_grayImgMap = m_grayImgMap.opAreaDistanceTransform();
    m_grayImgMap.opThresholdAbove( 1.0, 255.0, 0.0 );

    // blur it with a Gaussian of scale 0.05*{w|h}
    float dSigma;
    if( m_nFixObjDim==OBJDIM_WIDTH )
      dSigma = m_nObjWidth*0.05;
    else
      dSigma = m_nObjHeight*0.05;
    m_grayImgMap = m_grayImgMap.opGauss( dSigma );

    m_bMapsOn = true;
  }

  // display the rescaled image
  rsSourceImg->loadImage( m_img );
  rsSourceImg->drawRect( rBBNew.x1, rBBNew.y1, 
                         rBBNew.x2-rBBNew.x1, rBBNew.y2-rBBNew.y1, 
                         Qt::green );
  rsSourceImg->display();
  QImage timg = m_grayImgMap.getQtImage();
  rsResultImg->loadImage( timg, m_grayImgMap );
  rsResultImg->display();  
}


void ISMReco::loadCodebook()
/*******************************************************************/
/* Load a stored codebook and display it in the IconViewer window. */
/*******************************************************************/
{
  /*---------------------*/
  /* Ask for a file name */
  /*---------------------*/
  QString qsStartDir( DIR_CL_FVECS );
  QString qsFileName = QFileDialog::getOpenFileName( qsStartDir,
                   "Vectors (*.fls *.flz);;All files (*.*)",
                                                     this );
  if ( qsFileName.isEmpty() )
    return;

  int pos1 = qsFileName.findRev( ".fls" );
  int pos2 = qsFileName.findRev( ".flz" );
  if ( (pos1 == -1) && (pos2 == -1) ) {
    cout << "No valid file (*.fls or *.flz) selected." << endl;
    return;
  }

  loadCodebook( qsFileName.latin1() );
}


void ISMReco::loadCodebook( string sFileName )
  /*******************************************************************/
  /* Load a stored codebook and display it in the IconViewer window. */
  /*******************************************************************/
{
  cout << "LoadCodebook() called..." << endl;
  
  /* set the cursor to an hourglass */
  setCursor( waitCursor );
    
  /*-----------------------------------------------*/
  /* Prepare the file name and erase the extension */
  /*-----------------------------------------------*/
  string sRawName( sFileName );
  int pos = sRawName.rfind( "." );
  sRawName.erase( pos );

  /*-------------------------*/
  /* Load the parameter file */
  /*-------------------------*/
  cout << "  Loading parameters ..." << endl;
  string sParamName( sRawName + ".params" );
  loadParams( sParamName );
  cout << "  done." << endl;

  /*------------------------*/
  /* Load the main codebook */
  /*------------------------*/
  m_cbCodebook.loadCodebook( sFileName, m_fcCue, m_bUsePatches );

  /*------------------------*/
  /* Normalize the clusters */
  /*------------------------*/
  m_cbCodebook.normalizeClusters( m_fcCue.params()->m_nFeatureType );

  /*----------------------*/
  /* Display the clusters */
  /*----------------------*/
  if( m_bUsePatches ) {
    cout << "    Displaying the clusters..." << endl;
    m_cbCodebook.drawClusters( qClassView );
  }
  
  /* reset the cursor back to normal */
  setCursor( arrowCursor );
  qApp->processEvents();

  cout << "New codebook loaded." << endl;
}


/*---------------------------------------------------------*/
/*                    Extracting Patches                   */
/*---------------------------------------------------------*/

void ISMReco::processImage( QString qsFileName )
  /*******************************************************************/
  /* Process a new image, i.e. load it and extract patches using the */
  /* methods selected in the used interface. The extracted patches   */
  /* are then stored in m_vImagePatches.                             */
  /*******************************************************************/
{
  loadImage( qsFileName );
  qApp->processEvents(); // finish drawing

  /* save original image */
  OpGrayImage imgOriginal( m_grayImg );
  /* perform histogram equalization */
  if( m_bPerformHistEq ) {
    cout << "  Performing histogram equalization..." << endl;
    m_grayImg = m_grayImg.opHistEq();
  }

  collectPatches( true );
  qApp->processEvents();

  /* restore original image */
  if( m_bPerformHistEq )
    m_grayImg = imgOriginal;
}


void ISMReco::processImageBBox( QString qsFileName, const Rect &rBBox )
  /*******************************************************************/
  /* Process a new image, i.e. load it and extract patches using the */
  /* methods selected in the used interface. The extracted patches   */
  /* are then stored in m_vImagePatches.                             */
  /*******************************************************************/
{
  loadImageBBox( qsFileName, rBBox );
  qApp->processEvents(); // finish drawing

  /* save original image */
  OpGrayImage imgOriginal( m_grayImg );
  /* perform histogram equalization */
  if( m_bPerformHistEq ) {
    cout << "  Performing histogram equalization..." << endl;
    m_grayImg = m_grayImg.opHistEq();
  }

  collectPatches( true );
  qApp->processEvents();

  /* restore original image */
  if( m_bPerformHistEq )
    m_grayImg = imgOriginal;
}


void ISMReco::collectPatches( bool process )
  /*******************************************************************/
  /* Collect patches from the current image, either by uniform sam-  */
  /* pling, or by applying a Harris corner detector.                 */
  /*******************************************************************/
{
  m_fcCue.processImage( m_sImgFullName, m_grayImg, m_grayImgMap, m_img, 
                        m_nFeatureType,
                        m_vPoints, m_vPointsInside, 
                        m_vImagePatches, m_vFeatures );

  drawInterestPointsEllipse();
  qApp->processEvents();

  /*------------------------*/
  /* Normalize the features */
  /*------------------------*/
  m_cbCodebook.normalizeFeatures( m_vFeatures, 
                                  m_fcCue.params()->m_nFeatureType );

  if (!process)
    displayPatchesForBrowsing(m_vImagePatches);
  qApp->processEvents();
}


void ISMReco::drawInterestPoints()
  /*******************************************************************/
  /* Draw the interest points returned by the Int.Pt. detector.      */
  /*******************************************************************/
{
  if ( m_vPoints.empty() ) 
    return;

  // display original image first (clean any drawings)
  rsSourceImg->display();
  for(int i=0; i < (int)m_vPoints.size(); i++) {
    rsSourceImg->drawCross( m_vPoints[i].x, m_vPoints[i].y, 
                            QColor::QColor(255,255,0), OVERDRAW_IMG );
    if( m_vPoints[i].scale > 1.0 )
      rsSourceImg->drawCircle( m_vPoints[i].x, m_vPoints[i].y, 
                               m_vPoints[i].scale*3.0,
                               QColor::QColor(255,255,0), OVERDRAW_IMG );
  }
  qApp->processEvents();
}


void ISMReco::drawInterestPointsEllipse()
/*******************************************************************/
/* Draw the interest points returned by the Int.Pt. detector.      */
/*******************************************************************/
{
  if ( m_vPoints.empty() )
    return;
 
  cout << "  Drawing " << m_vPoints.size() << " points..." << endl;
 
  // display original image first (clean any drawings)
  rsSourceImg->display();
  for( int i=0; i <(int)m_vPoints.size(); i++) {
    rsSourceImg->drawCross( m_vPoints[i].x, m_vPoints[i].y,
                            QColor::QColor(255,255,0), OVERDRAW_IMG );
    float dScaleFactor = m_fcCue.params()->m_dScaleFactor;
    if( m_vPoints[i].scale > 1.0 )
      if( m_vPoints[i].l1 != m_vPoints[i].l2 )
        rsSourceImg->drawEllipse( m_vPoints[i].x, m_vPoints[i].y,
                                  m_vPoints[i].l1*dScaleFactor, 
                                  m_vPoints[i].l2*dScaleFactor,
                                  -m_vPoints[i].angle,
                                  QColor::QColor(255,255,0), OVERDRAW_IMG );
    else
      rsSourceImg->drawCircle( m_vPoints[i].x, m_vPoints[i].y,
                               m_vPoints[i].scale*3.0,
                               QColor::QColor(255,255,0), OVERDRAW_IMG );
  }
  qApp->processEvents();
}


void ISMReco::displayPatchesForBrowsing(vector<OpGrayImage> &vPatches,
                                          int pos_x, int pos_y )
  /*******************************************************************/
  /* Display the extracted image patches in a separate window.       */
  /*******************************************************************/
{
  if ( vPatches.empty() ) 
    return;

  vector<QImage> vPatchImages;

  for (int i=0; i < (int)vPatches.size(); i++) {
    vPatchImages.push_back( vPatches[i].getQtImage() );
  }
  QtImgBrowser *qtPatchBrowser = new QtImgBrowser( 0, "patches" );
  qtPatchBrowser->setGeometry( pos_x, pos_y, 100, 150 );
  qtPatchBrowser->load( vPatchImages );
  connect( qtPatchBrowser, SIGNAL(imageClicked(int)), 
           this, SLOT(highlightPoint(int)) );
  qtPatchBrowser->show();
}


void ISMReco::highlightPoint( int idx )
  /*******************************************************************/
  /* Show the position of the selected image patch in the original   */
  /* image.                                                          */
  /*******************************************************************/
{
  if( (idx >= 0) && (idx < (int)m_vPointsInside.size()) ) {
    cout << "Patch[" << idx << "] clicked." << endl;
    
    rsSourceImg->drawCross( m_vPointsInside[idx].x, m_vPointsInside[idx].y, 
                            QColor::QColor(255, 0, 0) ); 
  }
}


/*---------------------------------------------------------*/
/*            Comparing Patches with the Codebook          */
/*---------------------------------------------------------*/

void ISMReco::compareFeatures()
{
  compareFeatures( true );
}


void ISMReco::compareFeatures( bool bShowPatches )
  /*******************************************************************/
  /* Compare the extracted image patches with the current codebook   */
  /* and display the matching entries.                               */
  /*******************************************************************/
{
  if ( m_vPoints.empty() ) {
    cout << "ISMReco::compareCodebook(): No interest points computed yet." 
         << endl;
    return;
  }
  if ( m_vFeatures.empty() ) {
    cout << "ISMReco::compareCodebook(): No features computed yet." << endl;
    return;
  }
  if ( m_cbCodebook.getNumClusters()<=0 ) {
    cout << "ISMReco::compareCodebook(): No codebook loaded." << endl;
    return;
  }
  
  /*--------------------------------------*/
  /* Compare the features to the codebook */
  /*--------------------------------------*/
  cout << "    Comparing image patches with codebook..." << endl;
  float dRejectionThresh = m_parMatching.params()->m_dRejectionThresh;
  m_cbCodebook.setMatchingParams( m_parMatching );
  m_cbCodebook.matchToCodebook( m_vFeatures, 
                                dRejectionThresh,
                                m_fcCue.params()->m_nFeatureType,
                                m_vNearestNeighbor, 
                                m_vNearestNeighborSim,
                                m_vvAllNeighbors, m_vvAllNeighborsSim );
  cout << "    done." << endl;
  
  /*---------------------------*/
  /* Show the matching results */
  /*---------------------------*/
  if( bShowPatches && m_bUsePatches ) {
    vector<OpGrayImage> nextClusters;
    vector<OpGrayImage> vClusterPatches = m_cbCodebook.getClusterPatches();
    OpGrayImage tempImg;
    for(int i=0; i < (int)m_vNearestNeighbor.size(); i++)
      if( m_vNearestNeighbor[i] >= 0 ) {
        tempImg.loadFromData(2*m_fcCue.params()->m_nPatchSize+1, 
                             2*m_fcCue.params()->m_nPatchSize+1,
                             vClusterPatches[m_vNearestNeighbor[i]].getData());
        if( m_vNearestNeighborSim[i] < dRejectionThresh ) {
          tempImg.drawLine( 1, 1, 2*m_fcCue.params()->m_nPatchSize-1, 
                            2*m_fcCue.params()->m_nPatchSize-1, 255.0 );
          tempImg.drawLine( 2*m_fcCue.params()->m_nPatchSize-1, 1, 
                            1, 2*m_fcCue.params()->m_nPatchSize-1, 255.0 );
        }
        nextClusters.push_back( tempImg );
      }
    
    displayPatchesForBrowsing( nextClusters );
  }
  
  /*-----------------------------*/
  /* Display the matched patches */
  /*-----------------------------*/
  if( m_bDrawMatchedPs ) {
    cout << "    Drawing matched patches..." << endl;
    m_resultImg = drawMatchedPatches();

    m_qresultImg = m_resultImg.getQtImage();
    rsResultImg->loadImage( m_qresultImg, m_resultImg );
    rsResultImg->display();
  }

  cout << "Image size is: (" << m_resultImg.width() << "," 
       << m_resultImg.height() << ")" << endl;
}


/*---------------------------------------------------------*/
/*                  Computing Occurrences                  */
/*---------------------------------------------------------*/

void ISMReco::computeOccurrences()
  /*******************************************************************/
  /* Load a set of images and compute occurrences from them. That    */
  /* means, load each image separately, extract patches from it,     */
  /* match them to the codebook, and record for each codebook entry  */
  /* where (relative to the object center) it matched. In order to   */
  /* compute the object center, this version of the method assumes   */
  /* that a segmentation mask is available for each image (the ob-   */
  /* ject center is then taken as the center of gravity of the seg-  */
  /* mentation mask). If no segmentation mask is available, the      */
  /* method needs to be adapted to take the image center as refe-    */
  /* rence point.                                                    */
  /*******************************************************************/
{
  QStringList qslImageList = getFileList();
  
  if( qslImageList.isEmpty() ) 
    return;

  m_ismReco.initOccurrences( m_cbCodebook.getNumClusters() );

  int nOccMapIdx = 0;
  VecVecOccurrence       vvOccurrences;
  vector<OpGrayImage>    vOccMaps;
  
  /* process the training images */
  cout << "  Processing the training images..." << endl;
  for( int i=0; i<(int)qslImageList.count(); i++ ) {
    /* initialize the global variables */
    m_vImagePatches.clear();
    m_vFeatures.clear();
    m_vPointsInside.clear();

    /* initialize the occurrences */
    vvOccurrences.clear();
    VecVecOccurrence tmp( m_cbCodebook.getNumClusters() );
    vvOccurrences = tmp;
    vOccMaps.clear();
    
    /* load the next image, calculate the interest points and ex-    */
    /* tract all patches.                                            */
    cout << "    Processing image " << i << ": " << qslImageList[i] << endl;
    processImage( qslImageList[i] );

    /* extract the pose information from the file name */
    int nPose = 0;

    /* match the extracted patches to the codebook */
    cout << "    Comparing image patches with all matches." << endl;
    compareFeatures( false );

    /* for every matched cluster, save an "occurrence" vector */
    int center_x, center_y;
    if( m_bMapsOn )
      m_grayImgMap.opComputeCoG( center_x, center_y );
    else {
      center_x = m_qresultImg.width()/2;
      center_y = m_qresultImg.height()/2;
    }
    cout << "    Object center is at (" << center_x << "," << center_y << ")"
         << endl;

    cout << "    Counting occurrences..." << endl;
    long nCountOccs = 0;
    float dRejectionThresh = m_parMatching.params()->m_dRejectionThresh;
    /* for all extracted patches */
    for( int j=0; j<(int)m_vvAllNeighbors.size(); j++ ) {
      if( m_vvAllNeighbors[j].size() > 0 )
        if( m_bMapsOn ) {
          /* extract the segmentation map for this patch */
          int nPatchSize = (int) floor(m_vPointsInside[j].scale*
                                       m_fcCue.params()->m_dScaleFactor+0.5);
          if( nPatchSize<=0 ) {
            cerr << "  ERROR in ISMReco::computeOccurrences(): "
                 << "patch size <= 0 (" << nPatchSize << ")!" << endl
                 << "    for point " << j << " with scale " 
                 << m_vPointsInside[j].scale << endl
                 << "    and patch scale factor " 
                 << m_fcCue.params()->m_dScaleFactor << endl;
          }
          //int nPatchArea = (2*nPatchSize+1)*(2*nPatchSize+1);
          int nNormSize  = m_fcCue.params()->m_nPatchSize;
          //int nNormArea  = (2*nNormSize+1)*(2*nNormSize+1);
          //float dAreaFactor = (float)nPatchArea/((float) nNormArea);
          OpGrayImage imgMap; 

          if( m_vPointsInside[j].l1 == m_vPointsInside[j].l2 ) {
            /*-=-=-=-=-=-=-=-=-*/
            /* Circular region */
            /*-=-=-=-=-=-=-=-=-*/
            imgMap = 
              m_grayImgMap.extractRegion( m_vPointsInside[j].x - nPatchSize,
                                          m_vPointsInside[j].y - nPatchSize,
                                          m_vPointsInside[j].x + nPatchSize,
                                          m_vPointsInside[j].y + nPatchSize);

            /* for compatibility reasons, rescale the map to a */
            /* standard size.                                  */
            if( nPatchSize != m_fcCue.params()->m_nPatchSize )
              imgMap = imgMap.opRescaleToWidth( 2*nNormSize+1 );

          } else {
            /*-=-=-=-=-=-=-=-=-=-*/
            /* Elliptical region */
            /*-=-=-=-=-=-=-=-=-=-*/
            m_fcCue.extractAffineRegion( m_grayImgMap, m_vPointsInside[j], 
                                         2*m_fcCue.params()->m_nPatchSize+1, 
                                         imgMap );
          }
          
          /* if the patch lies on the object */
          if( imgMap.getSum() >= m_fcCue.params()->m_nMinFigurePixels*255.0 ) {
            /* get the index of the next occurrence map */
            int nNextOccMap    = nOccMapIdx + vOccMaps.size();
            bool bMatchedEntry = false;

            /* for all matched codebook entries */
            for( int k=0; k<(int)m_vvAllNeighbors[j].size(); k++ ) 
              if( m_vvAllNeighborsSim[j][k] > dRejectionThresh ) {
                /* create a new occurrence */
                ClusterOccurrence occ;
                occ.dSimilarity = m_vvAllNeighborsSim[j][k];
                occ.nCategory = m_nCateg;
                if( nPose != -1 )
                  occ.nPose = nPose;
                else if( m_bSavePose )
                  occ.nPose = m_nPose;
                else
                  occ.nPose = -1;
                
                occ.dScale     = m_vPointsInside[j].scale;
                occ.dPosX      = m_vPointsInside[j].x - center_x;
                occ.dPosY      = m_vPointsInside[j].y - center_y;
                occ.nOccMapIdx = nNextOccMap;
                occ.nImgNumber = i;
                occ.dWeight    = 1.0;
                occ.dAngle     = m_vPointsInside[j].angle;
                if( fabs(m_vPointsInside[j].l2) >= 0.01 )
                  occ.dAxisRatio = m_vPointsInside[j].l1/m_vPointsInside[j].l2;
                else
                  occ.dAxisRatio = m_vPointsInside[j].l1/0.01;
                occ.dBBRatio   = 1.0;
                
                /* store the occurrence */
                vvOccurrences[m_vvAllNeighbors[j][k]].push_back( occ );
                nCountOccs++;
                bMatchedEntry = true;
              }

            if( bMatchedEntry )
              /* store a segmentation map for the occurrences */
              vOccMaps.push_back( imgMap );
          } // end if (patch lies on object)

        } else { /* no map available => always store the occurrence */
          /* for all matched codebook entries */
          for( int k=0; k<(int)m_vvAllNeighbors[j].size(); k++ ) 
            if( m_vvAllNeighborsSim[j][k] > dRejectionThresh ) {
              /* create a new occurrence */
              ClusterOccurrence occ;
              occ.dSimilarity = m_vvAllNeighborsSim[j][k];
              occ.nCategory = m_nCateg;
              if( nPose != -1 )
                occ.nPose = nPose;
              else if( m_bSavePose )
                occ.nPose = m_nPose;
              else
                occ.nPose = -1;
              
              occ.dScale     = m_vPointsInside[j].scale;
              occ.dPosX      = m_vPointsInside[j].x - center_x;
              occ.dPosY      = m_vPointsInside[j].y - center_y;
              occ.nOccMapIdx = -1;
              occ.nImgNumber = i;
              occ.dWeight    = 1.0;
              occ.dAngle     = m_vPointsInside[j].angle;
              if( fabs(m_vPointsInside[j].l2) >= 0.01 )
                occ.dAxisRatio = m_vPointsInside[j].l1/m_vPointsInside[j].l2;
              else
                occ.dAxisRatio = m_vPointsInside[j].l1/0.01;
              occ.dBBRatio   = 1.0;
              
              /* store only the occurrence, no segm. map */
              vvOccurrences[m_vvAllNeighbors[j][k]].push_back( occ );
              nCountOccs++;
            }
        } // end else (no maps available)
    } // end forall extracted patches
    cout << "    found " << nCountOccs << " occurrences for this image." 
         << endl;

    /* store the occurrences */
    m_ismReco.addOccurrences( vvOccurrences, vOccMaps, nOccMapIdx );
  }
  cout << "  done." << endl;

  /* compute the occurrence weights */
  cout << "  Computing occurrence weights..." << endl;
  m_ismReco.finishOccurrences();

  cout << "done." << endl;
}


void ISMReco::saveOccurrences()
  /*******************************************************************/
  /* Save the current occurrences (using the FeatureVector file for- */
  /* mat).                                                           */
  /*******************************************************************/
{
  QString qsFileName = 
    QFileDialog::getSaveFileName( DIR_CL_FVECS.c_str(), 
                                  "Vectors (*.fls *.flz);;All files (*.*)",
                                  this);
  if ( qsFileName.isEmpty() )
    return;
  
  m_ismReco.saveOccurrences( qsFileName.latin1() );
}


void ISMReco::saveOccurrencesMatlab()
  /*******************************************************************/
  /* Save the current occurrences as a plain ASCII table.            */
  /*******************************************************************/
{
  QString qsFileName = 
    QFileDialog::getSaveFileName( DIR_CL_FVECS.c_str(), 
                                  "Vectors (*.fls *.flz);;All files (*.*)",
                                  this);
  if ( qsFileName.isEmpty() )
    return;
  
  m_ismReco.saveOccurrencesMatlab( qsFileName.latin1() );
}


void ISMReco::loadOccurrences()
  /*******************************************************************/
  /* Load a new set of occurrences from disk.                        */
  /*******************************************************************/
{ 
  QString qsFileName = 
    QFileDialog::getOpenFileName( DIR_CL_FVECS.c_str(), 
                                  "Vectors (*.fls *.flz);;All files (*.*)",
                                  this);
  if ( qsFileName.isEmpty() )
    return;
  
  m_ismReco.loadOccurrences( qsFileName.latin1(), 
                             m_cbCodebook.getNumClusters() );
}


/*---------------------------------------------------------*/
/*                  Processing a Test Image                */
/*---------------------------------------------------------*/

void ISMReco::processTestImg(  QString qsFileName, int nImgNumber,
                               vector<Hypothesis>  &vResultHypos,
                               vector<Hypothesis>  &vResultHyposTight,
                               vector<OpGrayImage> &vResultImgSegment,
                               vector<OpGrayImage> &vResultImgPFig,
                               vector<OpGrayImage> &vResultImgPGnd,
                               bool bDisplayResults )
{
  /***************************************/
  /*   Initialize the global variables   */
  /***************************************/
  m_vImagePatches.clear();
  m_vFeatures.clear();
  m_vPoints.clear();
  m_vPointsInside.clear();
  m_vActiveVotes.clear();

  /******************************************************************/
  /*   Load the next image, calculate the interest points and ex-   */
  /*   tract all patches.                                           */
  /******************************************************************/
  processImage( qsFileName );

  /***************************************************/
  /*   Match the extracted patches to the codebook   */
  /***************************************************/
  cout << "    Comparing image patches with all matches..." << endl;
  compareFeatures( false );

  /*******************************************************/
  /*   Apply the voting procedure to obtain hypotheses   */
  /*******************************************************/
  vResultHypos.clear();
  vResultHyposTight.clear();
  vResultImgSegment.clear();
  vResultImgPFig.clear();
  vResultImgPGnd.clear();
 
  float dMSMESizeX    = m_parReco.params()->m_dMSMESizeX;
  float dMSMESizeY    = m_parReco.params()->m_dMSMESizeY;
  float dMSMESizeS    = m_parReco.params()->m_dMSMESizeS;
  int   nObjWidth     = m_parReco.params()->m_nObjWidth;
  int   nObjHeight    = m_parReco.params()->m_nObjHeight;
  float dRecoScaleMin = m_parReco.params()->m_dRecoScaleMin;
  float dRecoScaleMax = m_parReco.params()->m_dRecoScaleMax;
  int   nImgWidth     = m_grayImg.width();
  int   nImgHeight    = m_grayImg.height();

  float dMaxScaleFactor = m_grayImg.width() / ((float) nObjWidth);
  float dMaxScaleLevel  = ( (floor(dMaxScaleFactor / dMSMESizeS)+1.0)*
                            dMSMESizeS );
  cout << "  Image size: (" << m_grayImg.width() << "," << m_grayImg.height()
       << ")" << endl;
  cout << "    => max. scale factor: " << dMaxScaleFactor << endl;
  cout << "    => max. scale level : " << dMaxScaleLevel << endl;
  cout << endl;

  /*--------------------------------*/
  /*   Initialize the VotingSpace   */
  /*--------------------------------*/
  float dScaleMin = dRecoScaleMin - dMSMESizeS/2.0;
  float dScaleMax = min( dRecoScaleMax, dMaxScaleLevel) + dMSMESizeS/2.0;
  int   nScaleSteps = (int)floor((dScaleMax - dScaleMin)/
                                 dMSMESizeS) + 1;

  m_ismReco.setRecoParams    ( m_parReco );
  m_ismReco.createVotingSpace( m_grayImg.width(), m_grayImg.height(),
                               SIZE_VOTINGBINS, 
                               dScaleMin, dScaleMax, nScaleSteps, true );

  /*==========================*/
  /* Apply patch-based voting */
  /*==========================*/
  m_ismReco.doPatchVoting( m_vPointsInside, 
                           m_vvAllNeighbors, m_vvAllNeighborsSim,
                           m_parMatching.params()->m_dRejectionThresh, true );

  cout << "================================" << endl;
  
  
  /*-----------------------------*/
  /* Retrieve initial hypotheses */
  /*-----------------------------*/
  vResultHypos = getPatchHypotheses( m_bDisplayVS );


  /*------------------------------------*/
  /* Convert to fixed bounding box size */
  /*------------------------------------*/
  vResultHypos = setHypoBBox( vResultHypos, nObjWidth, nObjHeight );

  /*----------------------------*/
  /* Remove multiple hypotheses */
  /*----------------------------*/
  cout << "  Reducing the number of hypotheses from " << vResultHypos.size();
  vector<Hypothesis> vReducedHypos;
  vector<bool>       vDropped( vResultHypos.size(), false );
  for( int i=0; i<(int)vResultHypos.size(); i++ )
    if( !vDropped[i] && 
        (vResultHypos[i].dScore>=m_parReco.params()->m_dScoreThreshSingle) ) {
      Hypothesis hypo = vResultHypos[i];
      //int nNumFound = 1;

      /* check all other hypotheses if they are similar */
      for( int j=i+1; j<(int)vResultHypos.size(); j++ )
        if( !vDropped[j] ) 
          if( (fabs((double)vResultHypos[j].x - hypo.x) < dMSMESizeX) &&
              (fabs((double)vResultHypos[j].y - hypo.y) < dMSMESizeY) &&
              (fabs((double)vResultHypos[j].dScale - hypo.dScale) 
               < dMSMESizeS) ) {
            /* found similar hypothesis => drop the weaker one */
            vDropped[j] = true;

            /* found similar hypothesis => average the scale */
            //hypo.dScale = ( (hypo.dScale*nNumFound + vResultHypos[j].dScale)/
            //                ((float)nNumFound+1) );
            //hypo.x      = (int)floor((hypo.x*nNumFound + vResultHypos[j].x) /
            //                         ((float)nNumFound+1) );
            //hypo.y      = (int)floor((hypo.y*nNumFound + vResultHypos[j].y) /
            //                         ((float)nNumFound+1) );
            //nNumFound++;
            //vDropped[j] = true;
          }

      vReducedHypos.push_back( hypo );
    }
  cout << " to " << vReducedHypos.size() << "." << endl;
  vResultHypos = vReducedHypos;


  /*================================*/
  /* Apply MDL hypothesis selection */
  /*================================*/
  vector<Hypothesis> vHyposMDL;
  vector<Hypothesis> vResultsMDL;
  for( int i=0; i<(int)vResultHypos.size(); i++ )
    if( vResultHypos[i].dScore > m_parReco.params()->m_dScoreThreshSingle ) {
      Hypothesis hypo = vResultHypos[i];
      /* convert to fixed bounding box size */
//       int width  = (int) floor(nObjWidth*hypo.dScale + 0.5);
//       int height = (int) floor(nObjHeight*hypo.dScale + 0.5);
//       hypo.nBoxX1 = (int)(hypo.x - width/2);
//       hypo.nBoxY1 = (int)(hypo.y - height/2);
//       hypo.nBoxWidth = width;
//       hypo.nBoxHeight = height;

      vHyposMDL.push_back( hypo );
    }
  vResultHypos = vHyposMDL;

  if( m_parReco.params()->m_bDoMDL ) {
    //vector<OpGrayImage> vImgSegment;
    //vector<OpGrayImage> vImgPFig;
    //vector<OpGrayImage> vImgPGnd;
    //vector<float>       vSumPFig;
    vector<Segmentation> vSegmentations;

    if( m_bRefineHypothesis ) {
      /*---------------------------------*/
      /* apply MDL on refined hypotheses */
      /*---------------------------------*/
      m_parReco.params()->m_bDoMDL = false;

      m_vHyposSingle = vHyposMDL;
      cout << "  Refining the top " << m_vHyposSingle.size() 
           << " hypotheses..." << endl;
      refineHypotheses( bDisplayResults );
      vHyposMDL = m_vHyposSingle;

      m_parReco.params()->m_bDoMDL = true;
    }

    /*-------------------------------*/
    /* Compute the hypothesis images */
    /*-------------------------------*/
    vector<Hypothesis> vHyposSegmented;
    float dMinPFig        = m_parReco.params()->m_dMinPFig;
    float dMinPFigRefined = m_parReco.params()->m_dMinPFigRefined;
    float dWeightPFig     = m_parReco.params()->m_dWeightPFig;
    cout << "  Computing top-down segmentations..." << endl;
    for( int i=0; i<(int)vHyposMDL.size(); i++ ) {
      //cout << "    for hypothesis " << i << "..." << endl;
      /* extract the hypothesis support */
      FeatureVector fvWindowPos( 3 );
      fvWindowPos.setValue( 0, vHyposMDL[i].x );
      fvWindowPos.setValue( 1, vHyposMDL[i].y );
      fvWindowPos.setValue( 2, vHyposMDL[i].dScale );
      
      /* get the supporting votes */
      vector<HoughVote> vSupporting;
      vSupporting = m_ismReco.getSupportingVotes_v( fvWindowPos );
      //cout << "      #votes: " << vSupporting.size() << endl;
      
      vSupporting = filterVotes( vHyposMDL[i], vSupporting );

      OpGrayImage imgSeg;
      OpGrayImage imgPFig;
      OpGrayImage imgPGnd;
      //m_ismReco.drawSegmentation( vSupporting, m_vPointsInside, m_fcCue,
      //                            imgPFig, imgPGnd, imgSeg, true );

      int nWidth      = vHyposMDL[i].nBoxWidth;
      int nHeight     = vHyposMDL[i].nBoxHeight;
      int nHypoWidth  = (int)floor(nWidth*vHyposMDL[i].dScale*1.75 + 0.5);
      int nHypoHeight = (int)floor(nHeight*vHyposMDL[i].dScale*1.75+ 0.5);
      int nSegOffX    = max( 0, vHyposMDL[i].x - nHypoWidth/2 );
      int nSegOffY    = max( 0, vHyposMDL[i].y - nHypoHeight/2 );
      int nSegWidth   = min( nHypoWidth, nImgWidth-nSegOffX );
      int nSegHeight  = min( nHypoHeight, nImgHeight-nSegOffY );
      //cout << "    Drawing segmentation for (" << vHyposMDL[i].x 
      //     << "," << vHyposMDL[i].y << "," << vHyposMDL[i].dScale 
      //     << ") => (" << nSegOffX << "," << nSegOffY
      //     << "," << nSegWidth << "," << nSegHeight << ")..." << endl;
      Segmentation segNew = m_ismReco.drawSegmentationOffset( vSupporting, 
                                                              m_vPointsInside, 
                                                              m_fcCue,
                                                              nSegOffX, 
                                                              nSegOffY,
                                                              1.0, 
                                                              nSegWidth, 
                                                              nSegHeight,
                                                              true );

      
      //float dSumPFig = imgPFig.getSum();
      //float dFigArea = imgSeg.getSum()/255.0;
      float dSumPFig = segNew.getSumPFig();
      float dFigArea = segNew.getSumSegArea();
      float dScore   = m_ismReco.getMDLScore( dSumPFig, dFigArea, 
                                              vHyposMDL[i].dScale );
      //cout << "      pfig=" << dSumPFig << ", area=" << dFigArea 
      //     << ", score=" << dScore << endl; 

      if( (m_bRefineHypothesis  && (dSumPFig >= dMinPFigRefined)) ||
          (!m_bRefineHypothesis && (dScore >= dMinPFig)) ) {
        //vImgSegment.push_back( imgSeg );
        //vImgPFig.push_back( imgPFig );
        //vImgPGnd.push_back( imgPGnd );
        //vSumPFig.push_back( dSumPFig );
        vSegmentations.push_back( segNew );
        vHyposSegmented.push_back( vHyposMDL[i] );
      }

      vSupporting.clear();
    }
    vHyposMDL = vHyposSegmented;

    cout << "  Performing MDL Selection..." << endl;
    vector<int>  vRanks;
    if( m_bRefineHypothesis )
      vResultsMDL = m_ismReco.doMDLSelection( vHyposMDL, 
                                              //vImgSegment, 
                                              //vImgPFig, vImgPGnd, vSumPFig,
                                              vSegmentations,
                                              dMinPFigRefined, dWeightPFig,
                                              vRanks, false, true );
    else
     //vResultsMDL = doMDLSelExact( vHyposMDL, 
      vResultsMDL = m_ismReco.doMDLSelection( vHyposMDL, 
                                              vSegmentations,
                                              //vImgSegment, 
                                              //vImgPFig, vImgPGnd, vSumPFig,
                                              dMinPFig, dWeightPFig, 
                                              vRanks, false, true );

    vResultHypos = vResultsMDL;

    /*------------------------------*/
    /* compute tight bounding boxes */
    /*------------------------------*/
    for( int i=0; i<(int)vRanks.size(); i++ ) {
      int idx = vRanks[i];
      
      //vResultHyposTight.push_back( computeTightBBox( vImgSegment[idx] ) );
      //vResultImgSegment.push_back( vImgSegment[idx] );
      //vResultImgPFig.push_back( vImgPFig[idx] );
      //vResultImgPGnd.push_back( vImgPGnd[idx] );
      OpGrayImage imgSeg = vSegmentations[idx].getImgSeg();
      int nOffX = vSegmentations[idx].getOffsetX();
      int nOffY = vSegmentations[idx].getOffsetY();
      vResultHyposTight.push_back( computeTightBBox( imgSeg, nOffX, nOffY )); 
      if( m_bDisplaySegment )
        vResultImgSegment.push_back( vSegmentations[idx].getFullImgSeg() );
      else
        vResultImgSegment.push_back( vSegmentations[idx].getImgSeg() );
      vResultImgPFig.push_back( vSegmentations[idx].getImgPFig() );
      vResultImgPGnd.push_back( vSegmentations[idx].getImgPGnd() );
    }
      
    
    //vImgSegment.clear();
    //vImgPFig.clear();
    //vImgPGnd.clear();
    vSegmentations.clear();

  } else {

    /*-----------------------------------------*/
    /* TEMPORARY: compute tight bounding boxes */
    /*-----------------------------------------*/
    vResultHyposTight.clear();
    for( int i=0; i<(int)vResultHypos.size(); i++ ) {
      /* extract the hypothesis support */
      FeatureVector fvWindowPos( 3 );
      fvWindowPos.setValue( 0, vResultHypos[i].x );
      fvWindowPos.setValue( 1, vResultHypos[i].y );
      fvWindowPos.setValue( 2, vResultHypos[i].dScale );
      
      vector<HoughVote> vSupporting;
      vSupporting = m_ismReco.getSupportingVotes_v( fvWindowPos );
      
      OpGrayImage imgSeg;
      OpGrayImage imgPFig;
      OpGrayImage imgPGnd;
      m_ismReco.drawSegmentation( vSupporting, m_vPointsInside, m_fcCue,
                                  imgPFig, imgPGnd, imgSeg, true );
      
      /* compute tight bounding boxes */
      vResultHyposTight.push_back( computeTightBBox( imgSeg ) );
      vResultImgSegment.push_back( imgSeg );
      vResultImgPFig.push_back( imgPFig );
      vResultImgPGnd.push_back( imgPGnd );
    }
 
    //vResultHyposTight = vResultHypos;
  }

  
  /*==================================*/
  /* Check for overlapping hypotheses */
  /*==================================*/
  /* prepare the display */
  rsSourceImg->loadImage( m_qsourceImg, m_grayImg );
  rsSourceImg->display();
  qApp->processEvents();

  vector<Hypothesis> vHyposOverlap;
  vector<Hypothesis> vHyposOverlapTight;
  float dScoreThreshSingle = m_parReco.params()->m_dScoreThreshSingle;
  bool  bRejectOverlap     = m_parReco.params()->m_bRejectOverlap;
  float dMaxOverlap        = m_parReco.params()->m_dMaxOverlap;
  for( int i=0; i<(int)vResultHypos.size(); i++ )
    if( vResultHypos[i].dScore > dScoreThreshSingle ) {
      Hypothesis hypo = vResultHypos[i];
      /* apply user-specified bounding box size */
//       int width  = (int) floor(nObjWidth*hypo.dScale + 0.5);
//       int height = (int) floor(nObjHeight*hypo.dScale + 0.5);
//       hypo.nBoxX1 = (int)(hypo.x - width/2);
//       hypo.nBoxY1 = (int)(hypo.y - height/2);
//       hypo.nBoxWidth = width;
//       hypo.nBoxHeight = height;
      
      /* check if the hypothesis overlaps with higher-ranking hypos */
      bool bOverlaps = false;
      if( bRejectOverlap )
        for( int j=0; j<(int)vHyposOverlap.size() && !bOverlaps; j++ ) {
          float dOverlap = computeBoundingBoxOverlap( vHyposOverlap[j],
                                                      hypo );
          if( dOverlap >= dMaxOverlap )
            bOverlaps = true;
        }
      
      /* Draw a rectangle around the detection */
      //int nScaleWidth  = (int) floor(nObjWidth*vResultHypos[i].dScale);
      //int nScaleHeight = (int) floor(nObjHeight*vResultHypos[i].dScale);
      QColor qcol; 
      if( bOverlaps ) {
        /* rejected => draw a red rectangle */
        qcol = QColor::QColor(255, 0, 0);
        if( m_bDrawRejectedHypos )
          //rsSourceImg->drawRect( vResultHypos[i].x - nScaleWidth/2,
          //                       vResultHypos[i].y - nScaleHeight/2,
          //                       nScaleWidth, nScaleHeight, qcol, true );
          rsSourceImg->drawRect( vResultHypos[i].nBoxX1,
                                 vResultHypos[i].nBoxY1,
                                 vResultHypos[i].nBoxWidth, 
                                 vResultHypos[i].nBoxHeight, qcol, true );

      } else {
        /* accepted => draw a green rectangle */
        qcol = QColor::QColor(0, 255, 0);
        
        //rsSourceImg->drawRect( vResultHypos[i].x - nScaleWidth/2,
        //                       vResultHypos[i].y - nScaleHeight/2,
        //                       nScaleWidth, nScaleHeight, qcol, true );
          rsSourceImg->drawRect( vResultHypos[i].nBoxX1,
                                 vResultHypos[i].nBoxY1,
                                 vResultHypos[i].nBoxWidth, 
                                 vResultHypos[i].nBoxHeight, qcol, true );
        
        if( m_bDrawTightBB ) {
          /* draw the tight bounding box => yellow rectangle */
          qcol = QColor::QColor(250, 250, 0);
          Hypothesis &hTight = vResultHyposTight[i];
          rsSourceImg->drawRect( hTight.nBoxX1, hTight.nBoxY1, 
                                 hTight.nBoxWidth, hTight.nBoxHeight, 
                                 qcol, true );
        }
      }
      
      if( !bOverlaps ) {
        vHyposOverlap.push_back( hypo );
        vHyposOverlapTight.push_back( vResultHyposTight[i] );
      }
    }
  vResultHypos      = vHyposOverlap;
  vResultHyposTight = vHyposOverlapTight;
  qApp->processEvents();


  /*==================================*/
  /* Display the accepted hypotheses */
  /*==================================*/
  cout << "=======================================" << endl;
  cout << "Final Hypotheses:" << endl;
  for( int k=0; k<(int)vResultHypos.size(); k++ ) {
    cout << "  " << setw(2) << k+1 << ". ";
    printHypothesisMDL( vResultHypos[k] );
  }
  cout << "=======================================" << endl;
  cout << endl;
}


void ISMReco::processTestImgStd()
  /*******************************************************************/
  /* Apply the recognition procedure to a test image. This function  */
  /* just opens a file dialog to ask for a file to process, then it  */
  /* calls the more general function below.                          */
  /*******************************************************************/
{
  cout << "    m_dScaleFactor: " << m_fcCue.params()->m_dScaleFactor << endl;
  //cout << "    Seg size:       " << (m_ismReco.getOccMaps())[0].width() 
  //     << endl;

  m_qsLastImage = QFileDialog::getOpenFileName( m_qsLastImage, 
					      "Images (*.png *.xpm *.jpg *.ppm);;all files (*.*)",
                 this);
  if ( m_qsLastImage.isEmpty() )
    return;

  ofstream ofDummy;
  processTestImgStd( m_qsLastImage, 0, m_vHyposSingle, ofDummy );
}


void ISMReco::processTestImgStd( QString qsFileName, int nImgNumber,
                                 vector<Hypothesis> &vResultHypos,
                                 ofstream &ofileSingle, 
                                 bool bDisplayResults )
  /*******************************************************************/
  /* Apply the recognition procedure to the given test image. The    */
  /* function first calls the various preprocessing steps (loading   */
  /* an image, extracting patches, matching to the codebook, etc.)   */
  /* sequentially, then generates votes from the matches and sear-   */
  /* ches for maxima in the Hough space. If the corresponding option */
  /* is selected in the interface, it the applies the MDL-based      */
  /* hypothesis verification stage.                                  */
  /* Results are written into the provided vectors and to disk in an */
  /* ASCII file format.                                              */
  /*******************************************************************/
{
  /*---------------------------*/
  /* Initialize some variables */
  /*---------------------------*/
  //int   nObjWidth     = m_parReco.params()->m_nObjWidth;
  //int   nObjHeight    = m_parReco.params()->m_nObjHeight;

  /*------------------------*/
  /* Process the test image */
  /*------------------------*/
  vResultHypos.clear();
  vector<Hypothesis>  vResultHyposTight;
  vector<OpGrayImage> vResultImgSeg;
  vector<OpGrayImage> vResultImgPFig;
  vector<OpGrayImage> vResultImgPGnd;
  processTestImg( qsFileName, nImgNumber, vResultHypos, vResultHyposTight,
                  vResultImgSeg, vResultImgPFig, vResultImgPGnd, 
                  bDisplayResults ); 

  vResultImgPFig.clear();
  vResultImgPGnd.clear();
    
  /*------------------------------*/
  /* Adapt the bounding box sizes */
  /*------------------------------*/
//   for( int i=0; i<(int)vResultHypos.size(); i++ ) {
//     Hypothesis hypo = vResultHypos[i];
//     /* apply user-specified bounding box size */
//     int width  = (int) floor(nObjWidth*hypo.dScale + 0.5);
//     int height = (int) floor(nObjHeight*hypo.dScale + 0.5);
//     hypo.nBoxX1 = (int)(hypo.x - width/2);
//     hypo.nBoxY1 = (int)(hypo.y - height/2);
//     hypo.nBoxWidth = width;
//     hypo.nBoxHeight = height;

//     vResultHypos[i] = hypo;
//   }   
    

  /*------------------------------------*/
  /* Write the results to a result file */
  /*------------------------------------*/
  writeResultsToDiskScore( ofileSingle, nImgNumber+1, vResultHypos );
  

  /*-------------------------------*/
  /* Display the results on-screen */
  /*-------------------------------*/
  displayRecoResults( vResultHypos, vResultImgSeg, bDisplayResults );


  /*--------------------------------*/
  /* Apply the Chamfer verification */
  /*--------------------------------*/
  if( m_parVeri.params()->m_bDoVerif && (vResultHypos.size() > 0) ) {

    vector<QImage>     vQImgs;
    vector<Hypothesis> vVerifiedHypos;
    vector<Hypothesis> vVerifiedHyposTight;
    vector<EdgePtVec>  vVerTemplates;
    vector<int>        vVerTemplateIds;

    int nVerifMethod = m_parVeri.params()->m_nVerifMethod;
    switch( nVerifMethod ) {
    case VERI_HARRIS:
      verifyHyposHarris( vResultHypos, vVerifiedHypos, vVerifiedHyposTight, 
                         vQImgs );
      break;

    case VERI_CHAMFER:
      //verifyHyposChamfer( vResultHypos, vVerifiedHypos, vQImgs );
      verifyHyposTemplate( vResultHypos, vResultHyposTight, 
                           vResultImgSeg, vResultImgPFig, vResultImgPGnd,
                           vVerifiedHypos, vVerifiedHyposTight,
                           vVerTemplates, vVerTemplateIds,
                           vQImgs );
      break;
      
    default:
      cerr << "  Error in ISMReco::processTestImgStd(): "
           << "Unknown verification method (" << nVerifMethod << ")!" << endl;
    }
 

    /*==================================*/
    /* Display the accepted hypotheses */
    /*==================================*/
    cout << "=======================================" << endl;
    cout << "Final Hypotheses:" << endl;
    for( int k=0; k<(int)vVerifiedHypos.size(); k++ ) {
      cout << "  " << setw(2) << k+1 << ". ";
      printHypothesisMDL( vVerifiedHypos[k] );
    }
    cout << "=======================================" << endl;

    /* draw verified hypotheses */
    rsSourceImg->loadImage( m_grayImg.getQtImage(), m_grayImg );
    rsSourceImg->display();
    for( int i=0; i<(int)vVerifiedHyposTight.size(); i++ ) {
      QColor qcol = QColor::QColor(255, 255, 0);

      Hypothesis &hTight = vVerifiedHyposTight[i];
      rsSourceImg->drawRect( hTight.nBoxX1, hTight.nBoxY1, 
                             hTight.nBoxWidth, hTight.nBoxHeight, 
                             qcol, true );
      /* draw the template */
      int pos_x = hTight.nBoxX1;
      int pos_y = hTight.nBoxY1;
      float dScale = hTight.dScale/m_parVeri.params()->m_dTemplateScale;

      // draw template on output //
      OpGrayImage imgScTempl = m_vSilhouettes[vVerTemplateIds[i]];
      int nNewWidth = (int)floor( imgScTempl.width()*dScale + 0.5 );
      imgScTempl = imgScTempl.opRescaleToWidth( nNewWidth );

      int tpl_h = imgScTempl.height();
      int tpl_w = imgScTempl.width();
      int img_h = m_grayImg.height();
      int img_w = m_grayImg.width();

      int minx = max(0, pos_x);
      int miny = max(0, pos_y);
      int maxx = min(pos_x + tpl_w, img_w);
      int maxy = min(pos_y + tpl_h, img_h);
      for( int y = miny; y < maxy; y++ )
        for( int x = minx; x < maxx;  x++ ) {
          float dVal = imgScTempl(x-pos_x, y-pos_y).value();
          if(  dVal != 0.0 ) {
            //if( dVal >= 0.5 )
            int nColVal = (int)floor(255.0*(0.5 + dVal/2.0) + 0.5);
            QColor qcol = QColor::QColor(nColVal, nColVal, 0);
            rsSourceImg->drawPoint( x, y, qcol, true );
          }
        }

    }
    vResultHypos = vVerifiedHyposTight;
    qApp->processEvents();

    if( !vQImgs.empty() && bDisplayResults ) {
      QtImgBrowser *qtCutOutBrowser = new QtImgBrowser( 0,"CutOuts"); 
      qtCutOutBrowser->setGeometry( 950, 550, 300, 350 );
      qtCutOutBrowser->load( vQImgs );
      qtCutOutBrowser->show();
    }
  }
}
    

void ISMReco::processTestImgUIUC( QString qsFileName, int nImgNumber,
                                    vector<Hypothesis> &vResultHypos,
                                    ofstream &ofileSingle, 
                                    ofstream &ofileScore, 
                                    bool bDisplayResults )
  /*******************************************************************/
  /* Apply the recognition procedure to the given test image. The    */
  /* function first calls the various preprocessing steps (loading   */
  /* an image, extracting patches, matching to the codebook, etc.)   */
  /* sequentially, then generates votes from the matches and sear-   */
  /* ches for maxima in the Hough space. If the corresponding option */
  /* is selected in the interface, it the applies the MDL-based      */
  /* hypothesis verification stage.                                  */
  /* Results are written into the provided vectors and to disk in a  */
  /* special file format that is compatible with Agarwal & Roth's    */
  /* evaluation program for the UIUC database.                       */
  /*******************************************************************/
{
  /*---------------------------*/
  /* Initialize some variables */
  /*---------------------------*/
  int   nObjWidth     = m_parReco.params()->m_nObjWidth;
  int   nObjHeight    = m_parReco.params()->m_nObjHeight;

  /*------------------------*/
  /* Process the test image */
  /*------------------------*/
  vResultHypos.clear();
  vector<Hypothesis>  vResultHyposTight;
  vector<OpGrayImage> vResultImgSeg;
  vector<OpGrayImage> vResultImgPFig;
  vector<OpGrayImage> vResultImgPGnd;
  processTestImg( qsFileName, nImgNumber, vResultHypos, vResultHyposTight, 
                  vResultImgSeg, vResultImgPFig, vResultImgPGnd,
                  bDisplayResults ); 


  /*-----------------------------------------------*/
  /* Convert result hypotheses to UIUC image sizes */
  /*-----------------------------------------------*/
  vector<Hypothesis> vResultHyposRaw;
  for( int i=0; i<(int)vResultHypos.size(); i++ ) {
    /* make sure the right score is saved to disk later */
    if( m_parReco.params()->m_bDoMDL )
      vResultHypos[i].dScore = vResultHypos[i].dScoreMDL;

    Hypothesis hypo = vResultHypos[i];
    /* convert to UIUC image sizes */
    //int width  = (int) floor(nObjWidth*hypo.dScale + 0.5);
    //int height = (int) floor(nObjHeight*hypo.dScale + 0.5);
    hypo.nBoxX1 = (int)floor((hypo.x -nObjWidth/2)/2.5 + 0.5);
    hypo.nBoxY1 = (int)floor((hypo.y - nObjHeight/2)/2.5 + 0.5);
    hypo.nBoxWidth = nObjWidth; 
    //(int)floor(width/(hypo.dScale*2.5) + 0.5);
    hypo.nBoxHeight = nObjHeight; 
    //(int)floor(height/(hypo.dScale*2.5) + 0.5);
    
    hypo.x = (int)floor(hypo.x/2.5 + 0.5);
    hypo.y = (int)floor(hypo.y/2.5 + 0.5);

    vResultHyposRaw.push_back( vResultHypos[i] );
    vResultHypos[i] = hypo;
  }


  /*------------------------------------*/
  /* Write the results to a result file */
  /*------------------------------------*/
  writeResultsToDiskScore( ofileScore, nImgNumber, vResultHyposRaw );

  writeResultsToDiskUIUC ( ofileSingle, nImgNumber, vResultHypos );
  
  
  /*-------------------------------*/
  /* Display the results on-screen */
  /*-------------------------------*/
  /* adapt the hypotheses to fixed bounding boxes */
  for( int i=0; i<(int)vResultHyposRaw.size(); i++ ) {
    int width  = (int) floor(nObjWidth*vResultHyposRaw[i].dScale + 0.5);
    int height = (int) floor(nObjHeight*vResultHyposRaw[i].dScale + 0.5);
    vResultHyposRaw[i].nBoxX1 = (vResultHyposRaw[i].x - width/2);
    vResultHyposRaw[i].nBoxY1 = (vResultHyposRaw[i].y - height/2);
    vResultHyposRaw[i].nBoxWidth  = width;
    vResultHyposRaw[i].nBoxHeight = height;
  }
 
  displayRecoResults( vResultHyposRaw, vResultImgSeg, bDisplayResults );
}
    

void ISMReco::processTestImgIDL( QString qsFileName, int nImgNumber,
                                   vector<Hypothesis> &vResultHypos,
                                   ImgDescr &idInitial, ImgDescr &idTight, 
                                   bool bDisplayResults )
  /*******************************************************************/
  /* Apply the recognition procedure to the given test image. The    */
  /* function first calls the various preprocessing steps (loading   */
  /* an image, extracting patches, matching to the codebook, etc.)   */
  /* sequentially, then generates votes from the matches and sear-   */
  /* ches for maxima in the Hough space. If the corresponding option */
  /* is selected in the interface, it the applies the MDL-based      */
  /* hypothesis verification stage.                                  */
  /*******************************************************************/
{
  /*---------------------------*/
  /* Initialize some variables */
  /*---------------------------*/
  //int   nObjWidth     = m_parReco.params()->m_nObjWidth;
  //int   nObjHeight    = m_parReco.params()->m_nObjHeight;

  /*------------------------*/
  /* Process the test image */
  /*------------------------*/
  vResultHypos.clear();
  vector<Hypothesis>  vResultHyposTight;
  vector<OpGrayImage> vResultImgSeg;
  vector<OpGrayImage> vResultImgPFig;
  vector<OpGrayImage> vResultImgPGnd;
  processTestImg( qsFileName, nImgNumber, vResultHypos, vResultHyposTight, 
                  vResultImgSeg, vResultImgPFig, vResultImgPGnd,
                  bDisplayResults ); 

    
  /*------------------------------*/
  /* Adapt the bounding box sizes */
  /*------------------------------*/
//   for( int i=0; i<(int)vResultHypos.size(); i++ ) {
//     Hypothesis hypo = vResultHypos[i];
//     /* apply user-specified bounding box size */
//     int width  = (int) floor(nObjWidth*hypo.dScale + 0.5);
//     int height = (int) floor(nObjHeight*hypo.dScale + 0.5);
//     hypo.nBoxX1 = (int)(hypo.x - width/2);
//     hypo.nBoxY1 = (int)(hypo.y - height/2);
//     hypo.nBoxWidth = width;
//     hypo.nBoxHeight = height;

//     vResultHypos[i] = hypo;
//   }   
    

  /*------------------------------------*/
  /* Write the results to the idl files */
  /*------------------------------------*/
  idInitial.vRectList.clear();
  idTight.vRectList.clear();
  for( int i=0; i<(int)vResultHypos.size(); i++ ) {
    Hypothesis hypo = vResultHypos[i];

    float dScore = hypo.dScore;
    if( m_parReco.params()->m_bDoMDL )
      dScore = hypo.dScoreMDL;

    idInitial.vRectList.push_back( Rect( hypo.nBoxX1, hypo.nBoxY1,
                                         hypo.nBoxX1+hypo.nBoxWidth,
                                         hypo.nBoxY1+hypo.nBoxHeight,
                                         dScore,
                                         hypo.nTemplateId ) );

    hypo = vResultHyposTight[i];
    idTight.vRectList.push_back( Rect( hypo.nBoxX1, hypo.nBoxY1,
                                       hypo.nBoxX1+hypo.nBoxWidth,
                                       hypo.nBoxY1+hypo.nBoxHeight,
                                       dScore,
                                       hypo.nTemplateId ) );
  }

  /*-------------------------------*/
  /* Display the results on-screen */
  /*-------------------------------*/
  displayRecoResults( vResultHypos, vResultImgSeg, bDisplayResults );


  /*-----------------------------------*/
  /* Perform single-scale verification */
  /*-----------------------------------*/
  if( m_parVeri.params()->m_bDoVerif && (vResultHypos.size() > 0) ) {

    vector<QImage>     vQImgs;
    vector<Hypothesis> vVerifiedHypos;
    vector<Hypothesis> vVerifiedHyposTight;
    vector<EdgePtVec>  vVerTemplates;
    vector<int>        vVerTemplateIds;

    int nVerifMethod = m_parVeri.params()->m_nVerifMethod;
    switch( nVerifMethod ) {
    case VERI_HARRIS:
      verifyHyposHarris( vResultHypos, vVerifiedHypos, vVerifiedHyposTight, 
                         vQImgs );
      break;

    case VERI_CHAMFER:
      //verifyHyposChamfer( vResultHypos, vVerifiedHypos, vQImgs );
      verifyHyposTemplate( vResultHypos, vResultHyposTight, 
                           vResultImgSeg, vResultImgPFig, vResultImgPGnd,
                           vVerifiedHypos, vVerifiedHyposTight,
                           vVerTemplates, vVerTemplateIds,
                           vQImgs );
      break;
      
    default:
      cerr << "  Error in ISMReco::processTestImgStd(): "
           << "Unknown verification method (" << nVerifMethod << ")!" << endl;
    }

 
    /*==================================*/
    /* Display the accepted hypotheses */
    /*==================================*/
    cout << "=======================================" << endl;
    cout << "Final Hypotheses:" << endl;
    for( int k=0; k<(int)vVerifiedHypos.size(); k++ ) {
      cout << "  " << setw(2) << k+1 << ". ";
      printHypothesisMDL( vVerifiedHypos[k] );
    }
    cout << "=======================================" << endl;
    
    /* draw verified hypotheses */
    rsSourceImg->loadImage( m_grayImg.getQtImage(), m_grayImg );
    rsSourceImg->display();
    for( int i=0; i<(int)vVerifiedHypos.size(); i++ ) {
      QColor qcol = QColor::QColor(255, 255, 0);
      
      Hypothesis &hTight = vVerifiedHyposTight[i];
      rsSourceImg->drawRect( hTight.nBoxX1, hTight.nBoxY1, 
                             hTight.nBoxWidth, hTight.nBoxHeight, 
                             qcol, true );
      /* draw the template */
      int pos_x = hTight.nBoxX1;
      int pos_y = hTight.nBoxY1;
      float dScale = hTight.dScale/m_parVeri.params()->m_dTemplateScale;

      //for( int j=0; j<(int)vVerTemplates[i].size(); j++ ) {
      //  int cx = (int)floor(pos_x + vVerTemplates[i][j].x()*hTight.dScale+0.5);
      //  int cy = (int)floor(pos_y + vVerTemplates[i][j].y()*hTight.dScale+0.5);
      //  rsSourceImg->drawPoint( cx, cy, qcol, true );
      //}

      // draw template on output
      OpGrayImage imgScTempl = m_vSilhouettes[vVerTemplateIds[i]];
      int nNewWidth = (int)floor( imgScTempl.width()*dScale + 0.5 );
      imgScTempl = imgScTempl.opRescaleToWidth( nNewWidth );

      int tpl_h = imgScTempl.height();
      int tpl_w = imgScTempl.width();
      int img_h = m_grayImg.height();
      int img_w = m_grayImg.width();

      int minx = max(0, pos_x);
      int miny = max(0, pos_y);
      int maxx = min(pos_x + tpl_w, img_w);
      int maxy = min(pos_y + tpl_h, img_h);
      for( int y = miny; y < maxy; y++ )
        for( int x = minx; x < maxx;  x++ ) {
          float dVal = imgScTempl(x-pos_x, y-pos_y).value();
          if(  dVal != 0.0 ) {
            //if( dVal >= 0.5 )
            int nColVal = (int)floor(255.0*(0.5 + dVal/2.0) + 0.5);
            QColor qcol = QColor::QColor(nColVal, nColVal, 0);
            rsSourceImg->drawPoint( x, y, qcol, true );
          }
        } 
    }
    qApp->processEvents();

    /* write verified hypotheses to the result files */
    /* (and overwrite initial hypotheses...)         */
    idInitial.vRectList.clear();
    idTight.vRectList.clear();
    for( int i=0; i<(int)vVerifiedHypos.size(); i++ ) {
      Hypothesis hypo = vVerifiedHypos[i];
      
      float dScore = hypo.dScore;
      if( m_parReco.params()->m_bDoMDL )
        dScore = hypo.dScoreMDL;
      
      if( m_parVeri.params()->m_bDoVerif )
        dScore = hypo.dScoreMDL;
      
      idInitial.vRectList.push_back( Rect( hypo.nBoxX1, hypo.nBoxY1,
                                           hypo.nBoxX1+hypo.nBoxWidth,
                                           hypo.nBoxY1+hypo.nBoxHeight,
                                           dScore, hypo.nTemplateId ) );
      
      hypo = vVerifiedHyposTight[i];
      idTight.vRectList.push_back( Rect( hypo.nBoxX1, hypo.nBoxY1,
                                         hypo.nBoxX1+hypo.nBoxWidth,
                                         hypo.nBoxY1+hypo.nBoxHeight,
                                         dScore, hypo.nTemplateId ) );

    }
  }  
}
    

void ISMReco::displayRecoResults( const vector<Hypothesis> &vResultHypos,
                                  const vector<OpGrayImage> &vResultImgSeg,
                                  bool bDisplayResults )
{
  /* prepare for displaying the results */
  vector<QImage> vResultImgs;
  vector<QImage> vRefResultImgs;

  /********************************/
  /* Draw the accepted hypotheses */
  /********************************/
  vector<HoughVote> vAllSupporting;
  for( int i=0; i<(int)vResultHypos.size(); i++ ) {
    
    /*--------------------------------*/
    /* Extract the hypothesis support */
    /*--------------------------------*/
    FeatureVector fvWindowPos( 3 );
    if( bDisplayResults ) {
      fvWindowPos.setValue( 0, vResultHypos[i].x );
      fvWindowPos.setValue( 1, vResultHypos[i].y );
      fvWindowPos.setValue( 2, vResultHypos[i].dScale );
      
      vector<HoughVote> vSupporting;
      if( m_bDisplaySegment || m_bDisplaySupport ) {
        vSupporting = m_ismReco.getSupportingVotes_v( fvWindowPos );
        vSupporting = filterVotes( vResultHypos[i], vSupporting );
      }
      
      OpGrayImage imgSeg;
      OpGrayImage imgPFig;
      OpGrayImage imgPGnd;

      if( m_bDisplaySegment ) {
        /* draw segmentation */
        //m_ismReco.drawSegmentation( vSupporting, m_vPointsInside, m_fcCue,
        //                            imgPFig, imgPGnd, imgSeg, true );
        //vRefResultImgs.push_back( imgSeg.getQtImage() );
      }
      vRefResultImgs.push_back( vResultImgSeg[i].getQtImage() );
       
      if( m_bDisplaySupport ) {
        if( !m_bMapsOnManually ) { 
          /* draw hypothesis support */
          OpGrayImage img = drawVotePatches( vSupporting, m_bMapsOnManually, 
                                             m_bDrawConfidence );
          
          vResultImgs.push_back( img.getQtImage() ); 
          
        } else { 
          if( m_bDrawConfidence )
            vResultImgs.push_back( imgPFig.getQtImage() ); 
          else
            vResultImgs.push_back( imgSeg.getQtImage() ); 
        }
      }

      if( m_bDisplaySegment ) {                  
        /* save the supporting votes for a complete result image */
        vAllSupporting.insert( vAllSupporting.end(), vSupporting.begin(), 
                               vSupporting.end() );
      }
      
    } else {
      //fvWindowPos.setValue( 0, vResultHypos[i].x );
      //fvWindowPos.setValue( 1, vResultHypos[i].y );
      //fvWindowPos.setValue( 2, vResultHypos[i].dScale );
      
      //vector<HoughVote> vSupporting;
      //vSupporting = m_ismReco.getSupportingVotes( fvWindowPos );
      
      /* update cluster contribution statistics */
      //updateOccurrenceStats( vSupporting, m_hClusterContrib );
    }
  }
  qApp->processEvents();

      
  /**********************************************/
  /* Display the detections in a browser window */
  /**********************************************/
  if( bDisplayResults && m_bDisplaySupport && (vResultImgs.size() > 0) ) {
    QtImgBrowser *qtResultBrowser = new QtImgBrowser( 0,"Reco Results"); 
    qtResultBrowser->setGeometry( 950, 200, 300, 350 );
    qtResultBrowser->load( vResultImgs );
    qtResultBrowser->show();
  }
  
  if( bDisplayResults && m_bDisplaySegment && (vRefResultImgs.size() > 0) ) {
    /* create a scene segmentation */
    OpGrayImage imgSceneSeg, imgDummy;
    m_ismReco.drawSegmentation( vAllSupporting, m_vPointsInside, m_fcCue,
                                imgDummy, imgDummy, imgSceneSeg, true );
    vRefResultImgs.push_back( imgSceneSeg.getQtImage() );

    m_vActiveVotes = vAllSupporting;

    /* create a grayscale segmentation image */
    OpGrayImage imgSegGray = m_grayImg.mul( imgSceneSeg ).div( 255.0 );
    vRefResultImgs.push_back( imgSegGray.getQtImage() );

		/* create a colored segmentation image */
    imgSceneSeg.opThresholdOutside ( 100.0, 255.0 );
		QPixmap pmImg;
		pmImg.convertFromImage( m_img ); 
    QBitmap bmMask;
		bmMask.operator=( imgSceneSeg.getQtImage() ); 
		pmImg.setMask( bmMask );
    vRefResultImgs.push_back( pmImg.convertToImage() );

    rsResultImg->loadImage( pmImg.convertToImage() );
    rsResultImg->display();
    qApp->processEvents();
  }

  if( bDisplayResults && (vRefResultImgs.size() > 0) ) {
    QtImgBrowser *qtRefResultBrowser = new QtImgBrowser( 0,
                                                        "Reco Results(Ref)"); 
    qtRefResultBrowser->setGeometry( 950, 600, 300, 350 );
    qtRefResultBrowser->load( vRefResultImgs );
    qtRefResultBrowser->show();
  } 
}


void ISMReco::refineHypotheses( bool bDisplayResults )
  /*******************************************************************/
  /* Refine the current hypotheses (as defined by the votes contain- */
  /* ed in m_vActiveVotes) by uniform sampling.                      */
  /*******************************************************************/
{
  if( (m_vHyposSingle.size() == 0) ) {
    cerr << "  No hypotheses to refine!" << endl;
    return;
  } else
    cout << "  Refining " << m_vHyposSingle.size() << " hypotheses..." << endl;

  /*---------------------------*/
  /* Initialize some variables */
  /*---------------------------*/
  int   nObjWidth     = m_parReco.params()->m_nObjWidth;
  int   nObjHeight    = m_parReco.params()->m_nObjHeight;

  /***************************************/
  /*   Initialize the global variables   */
  /***************************************/
  m_vImagePatches.clear();
  m_vFeatures.clear();
  m_vPointsInside.clear();

  /******************************************************************/
  /*   Extract all patches around the current hypothesis.           */
  /******************************************************************/
  vector<InterestPoint> vPointsToRefine;
  for( int i=0; i<(int)m_vHyposSingle.size(); i++ ) {
    Hypothesis hypo = m_vHyposSingle[i];
    /* collect all points that fall into the extended bounding box */
    int x1 = hypo.nBoxX1-hypo.nBoxWidth/10;
    int y1 = hypo.nBoxY1-hypo.nBoxHeight/10;
    int x2 = (int)(hypo.nBoxX1+hypo.nBoxWidth*1.2);
    int y2 = (int)(hypo.nBoxY1+hypo.nBoxHeight*1.2);

    m_vPoints.clear();
    int minx = max( x1, m_fcCue.params()->m_nPatchSize );
    int miny = max( y1, m_fcCue.params()->m_nPatchSize );
    int maxx = min( x2, m_img.width()-m_fcCue.params()->m_nPatchSize );
    int maxy = min( y2, m_img.height()-m_fcCue.params()->m_nPatchSize );
    for (int y=miny; y < maxy; y+=m_fcCue.params()->m_nStepSize)
      for (int x=minx; x < maxx; x+=m_fcCue.params()->m_nStepSize) {
        InterestPoint ptNew;
        ptNew.x = x;
        ptNew.y = y;
        ptNew.value = 1.0;
        ptNew.scale = 1.0;
        ptNew.angle = 0.0;
        ptNew.l1    = ptNew.scale;
        ptNew.l2    = ptNew.scale;
        m_vPoints.push_back( ptNew );
      }

    /* add those points that are new */
    int nSizeBefore = (int)vPointsToRefine.size();
    for( int j=0; j<(int)m_vPoints.size(); j++ ) {
      bool found = false;
      for( int k=0; k<nSizeBefore && !found; k++ )
        if( (m_vPoints[j].x == vPointsToRefine[k].x) &&
            (m_vPoints[j].y == vPointsToRefine[k].y) )
          found = true;
      
      if( !found )
        vPointsToRefine.push_back( m_vPoints[j] );
    }
  }
  qApp->processEvents();

  /* extract the corresponding patches */
  m_vPoints       = vPointsToRefine;
  m_vPointsInside = vPointsToRefine;
  extractAllPatches(true);

  /***************************************************/
  /*   Match the extracted patches to the codebook   */
  /***************************************************/
  cout << "    Comparing image patches with all matches..." << endl;
  compareFeatures( false );
  
  /*******************************************************/
  /*   Apply the voting procedure to obtain hypotheses   */
  /*******************************************************/
  vector<Hypothesis> vResultHypos;

  /*--------------------------------*/
  /*   Initialize the VotingSpace   */
  /*--------------------------------*/
  m_ismReco.setRecoParams    ( m_parReco );
  m_ismReco.createVotingSpace( m_grayImg.width(), m_grayImg.height(),
                               SIZE_VOTINGBINS, true );

  /*==========================*/
  /* Apply patch-based voting */
  /*==========================*/
  m_ismReco.doPatchVoting( m_vPointsInside, 
                           m_vvAllNeighbors, m_vvAllNeighborsSim,
                           m_parMatching.params()->m_dRejectionThresh, true );
    
  cout << "================================" << endl;

  /*--------------------------*/
  /* Test single-patch voting */
  /*--------------------------*/
  vResultHypos = m_ismReco.refinePatchHypotheses( m_vHyposSingle, 
                                                  m_vPointsInside,
                                                  bDisplayResults );

  /* adapt the hypotheses to fixed bounding boxes */
  for( int i=0; i<(int)vResultHypos.size(); i++ ) {
    vResultHypos[i].nBoxX1 = (vResultHypos[i].x - nObjWidth/2);
    vResultHypos[i].nBoxY1 = (vResultHypos[i].y - nObjHeight/2);
    vResultHypos[i].nBoxWidth  = nObjWidth;
    vResultHypos[i].nBoxHeight = nObjHeight;
  }
  
  /* prepare for displaying the results */
  FeatureVector fvWindowPos( 2 );
  vector<QImage> vPwResultImgs;
  vector<QImage> vPwSegmentImgs;
  rsSourceImg->loadImage( m_qsourceImg, m_grayImg );
  rsSourceImg->display();
  qApp->processEvents();

  
  /* initialize the results */
  m_vHyposSingle.clear();

  /* prepare a "scene image" */
  OpGrayImage imgAllSupport( m_grayImg.width(), m_grayImg.height() );
  OpGrayImage imgAllSegment( m_grayImg.width(), m_grayImg.height() );
  vector<HoughVote> vAllSupporting;
  vector<OpGrayImage> vImgSegment;
  vector<OpGrayImage> vImgPFig;
  vector<OpGrayImage> vImgPGnd;
  vector<float> vFigArea( vResultHypos.size() );
  vector<float> vSumPFig( vResultHypos.size() );
  int nCount = 0;
  if( m_parReco.params()->m_bDoMDL ) {
    cout << "=======================================" << endl;
    cout << "Refined Hypotheses:" << endl;
  }
  for( int i=0; i<(int)vResultHypos.size(); i++ )
    if( vResultHypos[i].dScore >= m_parReco.params()->m_dScoreThreshSingle ) {

      /* check if the hypothesis overlaps with higher-ranking hypos */
      bool bOverlaps = false;
      if( m_parReco.params()->m_bRejectOverlap )
        for( int j=0; j<i && !bOverlaps; j++ ) {
          float dOverlap = computeBoundingBoxOverlap( vResultHypos[j],
                                                      vResultHypos[i]);
          if( dOverlap >= m_parReco.params()->m_dMaxOverlap )
            bOverlaps = true;
        }
          
      QColor qcol; 
      if( !bOverlaps ) {
        m_vHyposSingle.push_back( vResultHypos[i] );

        /* draw a green rectangle around the detection */
        qcol = QColor::QColor(0, 255, 0);
      
        rsSourceImg->drawRect( vResultHypos[i].x - nObjWidth/2,
                               vResultHypos[i].y - nObjHeight/2,
                               nObjWidth, nObjHeight, qcol, true );
      
        /* extract the hypothesis support */
        fvWindowPos.setValue( 0, vResultHypos[i].x );
        fvWindowPos.setValue( 1, vResultHypos[i].y );
        
        vector<HoughVote> vSupporting;
        vSupporting = m_ismReco.getSupportingVotes_v( fvWindowPos );
        
        OpGrayImage imgSupport = drawVotePatches( vSupporting, 
                                                  m_bMapsOnManually, 
                                                  m_bDrawConfidence );
        
        /* set the necessary flags */
        bool bMapsOnManually = m_bMapsOnManually;
        slotSetMapsOnOff( 1 );
        OpGrayImage imgSegment = drawVotePatches( vSupporting, true, false ); 

        /*-----------------------------------------------------------*/
        /* for MDL selection, compute additional segmentation images */
        /*-----------------------------------------------------------*/
        if( m_parReco.params()->m_bDoMDL ) {
          /* one segmentation with zero background */
          vImgSegment.push_back( drawVotePatches(vSupporting,true,false,true,
                                                 true));
          /* and one p(figure) image */
          vImgPFig.push_back( drawVotePatches( vSupporting, true, true, true,
                                               true ));

          /* and one p(ground) image */
          vImgPGnd.push_back( drawVotePatches( vSupporting, true, true,false,
                                               true ));

          /* compute some hypothesis attributes: */
          /*   - figure area                     */
          /*   - sum(p(figure))                  */
          float dFigArea = vImgSegment[i].getSum()/255.0;
          float dSumPFig = vImgPFig[i].getSum();
          cout << "  " << setw(2) << i+1 << ". ";
          printHypothesis( vResultHypos[i] );
          cout << "          "
               << "FigArea=" << (int) dFigArea 
               << ", Sum(pfig)=" << (int) dSumPFig << endl;

          vFigArea[i] = dFigArea;
          vSumPFig[i] = dSumPFig;
          
        }

        /* reset the flags to their initial values */
        slotSetMapsOnOff( bMapsOnManually );
        qApp->processEvents();
        
        vPwResultImgs.push_back( imgSupport.getQtImage() ); 
        vPwSegmentImgs.push_back( imgSegment.getQtImage() );
        
        /* Prepare a "scene picture" */
        vAllSupporting.insert( vAllSupporting.end(), vSupporting.begin(),
                               vSupporting.end() );

        imgAllSupport = imgAllSupport.add( imgSupport );
        imgAllSegment = imgAllSegment.add( imgSegment );
        //for( int yy=0; yy<imgSegment.height(); yy++ )
        //  for( int xx=0; xx<imgSegment.width(); xx++ )
        //    imgAllSegment(xx,yy) = ( imgAllSegment(xx,yy).value() + 
        //                             imgSegment(xx,yy).value() );
        nCount++;
      }
    }
  
  if( m_parReco.params()->m_bDoMDL ) {
    cout << "---------------------------------------" << endl;
    cout << "Interactions:" << endl;
    for( int j=0; j<(int)m_vHyposSingle.size(); j++ )
      for( int k=0; k<j; k++ ) {
        /* compute the overlapping area */
        float dFigAreaOverlap = 0.0;
        float dSumPFigOverlap = 0.0;
        OpGrayImage imgAreaOverlap( m_grayImg.width(), m_grayImg.height() );
        OpGrayImage imgPFigOverlap( m_grayImg.width(), m_grayImg.height() );
        for( int y=0; y<m_grayImg.height(); y++ )
          for( int x=0; x<m_grayImg.width(); x++ ) {
            float dMinSeg  = min( vImgSegment[j](x,y).value(), 
                                  vImgSegment[k](x,y).value() );
            imgAreaOverlap(x,y) = dMinSeg;
            dFigAreaOverlap += dMinSeg;
            
            float dMinPFig = min( vImgPFig[j](x,y).value(), 
                                  vImgPFig[k](x,y).value() );
            imgPFigOverlap(x,y) = dMinPFig;
            dSumPFigOverlap += dMinPFig;
          }
        dFigAreaOverlap /= 255.0;
        cout << "  " << k+1 << " <-> " << j+1 << ": Overlapping " << setw(6) 
             << "FigArea=" << dFigAreaOverlap 
             << ", Sum(pfig)=" << dSumPFigOverlap << endl;
        
        //vImgVisualize.push_back( imgAreaOverlap );
        //vImgVisualize.push_back( imgPFigOverlap );
      }
    

    /*------------------------------*/
    /* Select consistent hypotheses */
    /*------------------------------*/
    if( m_parReco.params()->m_bRejectPFig ) {
      cout << "---------------------------------------" << endl;
      cout << "Selection:" << endl;
      
      int nChosen = 0;
      vector<bool>  vChosen( vResultHypos.size(), false );
      bool bFinished = false;
      while( nChosen<(int)vResultHypos.size() && !bFinished ) {
        
        /* find the hypothesis with max. SumPFig */
        float dMaxVal = 0.0;
        int   nMaxIdx = 0;
        for( int k=0; k<(int)vResultHypos.size(); k++ )
          if( !vChosen[k] )
            if( vSumPFig[k] > dMaxVal ) {
              dMaxVal = vSumPFig[k];
              nMaxIdx = k;
            }
        
        if( dMaxVal < m_parReco.params()->m_dMinPFigRefined )
          bFinished = true;
        
        else {
          /* select this hypothesis */
          vChosen[nMaxIdx] = true;
          nChosen++;
          cout << "  Selected hypothesis " << nMaxIdx+1 << endl;
          
          /* update the remaining hypotheses */
          for( int k=0; k<(int)vResultHypos.size(); k++ )
            if( !vChosen[k] ) {
              
              /* remove the overlapping area */
              for( int y=0; y<m_grayImg.height(); y++ )
                for( int x=0; x<m_grayImg.width(); x++ ) //{
                  if( vImgPFig[nMaxIdx](x,y).value() > 
                      vImgPGnd[nMaxIdx](x,y).value() ) {
                    /* pixel is better explained by selected hypothesis */
                    /* => remove it from this hypothesis */
                  //vImgSegment[k](x,y) = min(vImgSegment[k](x,y).value(), 
                  //                          vImgSegment[nMaxIdx](x,y).value());
                  //vImgPFig[k](x,y)    = min(vImgPFig[k](x,y).value(), 
                  //                          vImgPFig[nMaxIdx](x,y).value());
                  vImgSegment[k](x,y) = 0.0;
                  vImgPFig[k](x,y)    = 0.0;
                }
              vFigArea[k] = vImgSegment[k].getSum()/255.0;
              vSumPFig[k] = vImgPFig[k].getSum();
              
              cout << "  => " << setw(2) << k+1 << ". ";
              printHypothesis( vResultHypos[k] );
              cout << "             "
                   << "FigArea=" << vFigArea[k] 
                   << ", Sum(pfig)=" << vSumPFig[k] << endl;
            }
        }
      }
    }
    
    cout << "=======================================" << endl;
  }

  /* finish the "scene picture" */
  imgAllSupport = imgAllSupport.div( (float) nCount );
  imgAllSegment = imgAllSegment.div( (float) nCount );
  vPwResultImgs.push_back( imgAllSupport.getQtImage() ); 
  vPwSegmentImgs.push_back( imgAllSegment.getQtImage() );

  /* ...and display it */
  m_resultImg = imgAllSegment;
  m_qresultImg = imgAllSegment.getQtImage();
  rsResultImg->loadImage( m_qresultImg, m_resultImg );
  rsResultImg->display();
  qApp->processEvents();
  
  m_vActiveVotes = vAllSupporting;

  if( bDisplayResults && (vPwResultImgs.size() > 0) ) {
    /* show the support area in one browser... */
    QtImgBrowser *qtPwResultBrowser = new QtImgBrowser( 0,"Reco Results (Refined)"); 
    qtPwResultBrowser->setGeometry( 950, 200, 300, 350 );
    qtPwResultBrowser->load( vPwResultImgs );
    qtPwResultBrowser->show();

    /* ...and the segmentation in another one */
    QtImgBrowser *qtPwSegmentBrowser = new QtImgBrowser( 0,"Segmentation Results (Refined)"); 
    qtPwSegmentBrowser->setGeometry( 950, 600, 300, 350 );
    qtPwSegmentBrowser->load( vPwSegmentImgs );
    qtPwSegmentBrowser->show();
  }
}


void ISMReco::refineHypothesesMultiScale( bool bDisplayResults )
  /*******************************************************************/
  /* Refine the current hypotheses (as defined by the votes contain- */
  /* ed in m_vActiveVotes) by uniform sampling (using scale votes).  */
  /*******************************************************************/
{
  if( (m_vHyposSingle.size() == 0) ) {
    cerr << "  No hypotheses to refine!" << endl;
    return;
  } else
    cout << "  Refining " << m_vHyposSingle.size() 
         << " hypotheses (multi-scale)..." << endl;

  /***************************************/
  /*   Initialize the global variables   */
  /***************************************/
  m_vImagePatches.clear();
  m_vFeatures.clear();
  m_vPointsInside.clear();

  /***********************/
  /* Get the occurrences */
  /***********************/
  VecVecOccurrence vvOccurrences = m_ismReco.getOccurrences();

  /*************************************************/
  /*   Look up all possibly contributing patches   */
  /*************************************************/
  /* for all hypotheses */
  PointVector vPoints;
  for( int i=0; i<(int)m_vHyposSingle.size(); i++ ) {
    Hypothesis hypo = m_vHyposSingle[i];
    
    /* go through all occurrences */
    for( int j=0; j<(int)vvOccurrences.size(); j++ )
      for( int k=0; k<(int)vvOccurrences[j].size(); k++ ) {
        ClusterOccurrence occ = vvOccurrences[j][k];

        /* compute the corresponding patch location and scale */
        InterestPoint pt;
        pt.x     = (int) floor(hypo.x + (occ.dPosX * hypo.dScale) + 0.5);
        pt.y     = (int) floor(hypo.y + (occ.dPosY * hypo.dScale) + 0.5);
        pt.value = 1.0;
        pt.scale = hypo.dScale * occ.dScale;
        pt.angle = 0.0;
        pt.l1    = pt.scale;
        pt.l2    = pt.scale;
        
        /* add the point to the list */
        if( (pt.scale >= m_fcCue.params()->m_dMinScale) && 
            (pt.scale <= m_fcCue.params()->m_dMaxScale) )
          vPoints.push_back( pt );
      }   
  }

  if( vPoints.size() == 0 )
    return;

  /* sort the interest point list */
  stable_sort( vPoints.begin(), vPoints.end(), compInterestPtsX() );
  stable_sort( vPoints.begin(), vPoints.end(), compInterestPtsY() );
  stable_sort( vPoints.begin(), vPoints.end(), compInterestPtsScale() );

  /* transfer all unique points to a new list */
  m_vPoints.clear();
  int nLastX       = vPoints[0].x;
  int nLastY       = vPoints[0].y;
  float dLastScale = vPoints[0].scale;
  InterestPoint ptCurrent = vPoints[0];
  for( int i=1; i<(int)vPoints.size(); i++ )
    if( (vPoints[i].x != nLastX) || (vPoints[i].y != nLastY) ||
        (vPoints[i].scale != dLastScale) ) {
      m_vPoints.push_back( ptCurrent );

      nLastX     = vPoints[i].x;
      nLastY     = vPoints[i].y;
      dLastScale = vPoints[i].scale;
      ptCurrent  = vPoints[i];
    }
  m_vPoints.push_back( ptCurrent );

  /* extract the corresponding patches */
  extractAllPatches( true );

  /***************************************************/
  /*   Match the extracted patches to the codebook   */
  /***************************************************/
  cout << "    Comparing image patches with all matches..." << endl;
  compareFeatures( false );
  
  /*******************************************************/
  /*   Apply the voting procedure to obtain hypotheses   */
  /*******************************************************/
  vector<Hypothesis> vResultHypos;

  /*==========================*/
  /* Apply patch-based voting */
  /*==========================*/
  //float dMSMESizeX    = m_parReco.params()->m_dMSMESizeX;
  //float dMSMESizeY    = m_parReco.params()->m_dMSMESizeY;
  float dMSMESizeS    = m_parReco.params()->m_dMSMESizeS;
  int   nObjWidth     = m_parReco.params()->m_nObjWidth;
  int   nObjHeight    = m_parReco.params()->m_nObjHeight;
  float dRecoScaleMin = m_parReco.params()->m_dRecoScaleMin;
  float dRecoScaleMax = m_parReco.params()->m_dRecoScaleMax;

  float dMaxScaleFactor = m_grayImg.width() / ((float) nObjWidth);
  float dMaxScaleLevel  = ( (floor(dMaxScaleFactor / dMSMESizeS)+1.0)*
                            dMSMESizeS );

  float dScoreThreshSingle = m_parReco.params()->m_dScoreThreshSingle;
  bool  bRejectOverlap     = m_parReco.params()->m_bRejectOverlap;
  float dMaxOverlap        = m_parReco.params()->m_dMaxOverlap;

  /*--------------------------------*/
  /*   Initialize the VotingSpace   */
  /*--------------------------------*/
  float dScaleMin = dRecoScaleMin - dMSMESizeS/2.0;
  float dScaleMax = min( dRecoScaleMax, dMaxScaleLevel) + dMSMESizeS/2.0;
  int   nScaleSteps = (int)floor((dScaleMax - dScaleMin)/
                                 dMSMESizeS) + 1;

  m_ismReco.setRecoParams    ( m_parReco );
  m_ismReco.createVotingSpace( m_grayImg.width(), m_grayImg.height(),
                               SIZE_VOTINGBINS, 
                               dScaleMin, dScaleMax, nScaleSteps, true );

  /*==========================*/
  /* Apply patch-based voting */
  /*==========================*/
  cout << "    Applying voting procedure..." << endl;
  m_ismReco.doPatchVoting( m_vPointsInside, 
                           m_vvAllNeighbors, m_vvAllNeighborsSim,
                           m_parMatching.params()->m_dRejectionThresh, true );
    
  cout << "================================" << endl;

  /*--------------------------*/
  /* Test single-patch voting */
  /*--------------------------*/
  cout << "    Refining hypotheses using the new votes..." << endl;
  vResultHypos = m_ismReco.refinePatchHypotheses( m_vHyposSingle, 
                                                  m_vPointsInside,
                                                  bDisplayResults );

  /* adapt the hypotheses to fixed bounding boxes */
  for( int i=0; i<(int)vResultHypos.size(); i++ ) {
    int width  = (int) floor(nObjWidth*vResultHypos[i].dScale + 0.5);
    int height = (int) floor(nObjHeight*vResultHypos[i].dScale + 0.5);
    vResultHypos[i].nBoxX1 = (vResultHypos[i].x - width/2);
    vResultHypos[i].nBoxY1 = (vResultHypos[i].y - height/2);
    vResultHypos[i].nBoxWidth  = width;
    vResultHypos[i].nBoxHeight = height;
  }
  
  /* prepare for displaying the results */
  vector<QImage> vResultImgs;
  vector<QImage> vSegmentImgs;
  rsSourceImg->loadImage( m_qsourceImg, m_grayImg );
  rsSourceImg->display();
  qApp->processEvents();

  
  /* initialize the results */
  m_vHyposSingle.clear();

  /* prepare a "scene image" */
  cout << "    Displaying the result..." << endl;
  FeatureVector fvWindowPos( 3 );
  OpGrayImage imgAllSupport( m_grayImg.width(), m_grayImg.height() );
  OpGrayImage imgAllSegment( m_grayImg.width(), m_grayImg.height() );
  vector<HoughVote> vAllSupporting;
  int nCount = 0;
  for( int i=0; i<(int)vResultHypos.size(); i++ )
    if( vResultHypos[i].dScore >= dScoreThreshSingle ) {

      /* check if the hypothesis overlaps with higher-ranking hypos */
      bool bOverlaps = false;
      if( bRejectOverlap )
        for( int j=0; j<i && !bOverlaps; j++ ) {
          float dOverlap = computeBoundingBoxOverlap( vResultHypos[j],
                                                      vResultHypos[i]);
          if( dOverlap >= dMaxOverlap )
            bOverlaps = true;
        }
          
      QColor qcol; 
      int width  = (int) floor(nObjWidth*vResultHypos[i].dScale + 0.5);
      int height = (int) floor(nObjHeight*vResultHypos[i].dScale + 0.5);
      if( !bOverlaps ) {
        m_vHyposSingle.push_back( vResultHypos[i] );

        /* draw a green rectangle around the detection */
        qcol = QColor::QColor(0, 255, 0);
      
        rsSourceImg->drawRect( vResultHypos[i].x - width/2,
                               vResultHypos[i].y - height/2,
                               width, height, qcol, true );
      
        /* extract the hypothesis support */
        fvWindowPos.setValue( 0, vResultHypos[i].x );
        fvWindowPos.setValue( 1, vResultHypos[i].y );
        fvWindowPos.setValue( 2, vResultHypos[i].dScale );
        
        vector<HoughVote> vSupporting;
        vSupporting = m_ismReco.getSupportingVotes_v( fvWindowPos );
        
        /* draw a support image */
        OpGrayImage imgSupport = drawVotePatches( vSupporting, 
                                                  m_bMapsOnManually, 
                                                  m_bDrawConfidence );
        
        /* draw the segmentation */
        OpGrayImage imgSeg;
        OpGrayImage imgPFig;
        OpGrayImage imgPGnd;
        m_ismReco.drawSegmentation( vSupporting, m_vPointsInside, m_fcCue, 
                                    imgPFig, imgPGnd, imgSeg, true );

        vResultImgs.push_back( imgSupport.getQtImage() ); 
        vSegmentImgs.push_back( imgSeg.getQtImage() );
        
        /* Prepare a "scene picture" */
        vAllSupporting.insert( vAllSupporting.end(), vSupporting.begin(),
                               vSupporting.end() );

        imgAllSupport = imgAllSupport.add( imgSupport );
        imgAllSegment = imgAllSegment.add( imgSeg );
        nCount++;
      }
    }
  
        
  cout << "=======================================" << endl;
  
  /* finish the "scene picture" */
  imgAllSupport = imgAllSupport.div( (float) nCount );
  imgAllSegment = imgAllSegment.div( (float) nCount );
  vResultImgs.push_back( imgAllSupport.getQtImage() ); 
  vSegmentImgs.push_back( imgAllSegment.getQtImage() );

  /* ...and display it */
  m_resultImg = imgAllSegment;
  m_qresultImg = imgAllSegment.getQtImage();
  rsResultImg->loadImage( m_qresultImg, m_resultImg );
  rsResultImg->display();
  qApp->processEvents();
  
  m_vActiveVotes = vAllSupporting;

  if( bDisplayResults && (vResultImgs.size() > 0) ) {
    /* show the support area in one browser... */
    QtImgBrowser *qtResultBrowser = new QtImgBrowser( 0,"Reco Results (Refined)"); 
    qtResultBrowser->setGeometry( 950, 200, 300, 350 );
    qtResultBrowser->load( vResultImgs );
    qtResultBrowser->show();

    /* ...and the segmentation in another one */
    QtImgBrowser *qtSegmentBrowser = new QtImgBrowser( 0,"Segmentation Results (Refined)"); 
    qtSegmentBrowser->setGeometry( 950, 600, 300, 350 );
    qtSegmentBrowser->load( vSegmentImgs );
    qtSegmentBrowser->show();
  }
}


void ISMReco::extractAllPatches( bool process )
  /*******************************************************************/
  /* Extract an image patch for each selected point location.        */
  /*******************************************************************/
{
  if (!process) {
    m_vImagePatches.clear();
    m_vFeatures.clear();
    m_vPointsInside.clear();
  }

  /*------------------------------------*/
  /* Extract all patches from the image */
  /*------------------------------------*/
  for (int i=0; i < (int)m_vPoints.size(); i++) {
    // compute the image patch size
    int nPatchSize = (int) floor(m_vPoints[i].scale*
                                 m_fcCue.params()->m_dScaleFactor + 0.5);
    //int nPatchArea = (2*nPatchSize+1)*(2*nPatchSize+1);

    // check if image patch is fully inside image
    if ( (m_vPoints[i].x - nPatchSize >= 0) && 
         (m_vPoints[i].y - nPatchSize >= 0) &&
         (m_vPoints[i].x + nPatchSize < m_grayImg.width()) &&
         (m_vPoints[i].y + nPatchSize < m_grayImg.height()) ) {
      OpGrayImage img = m_grayImg.extractRegion( m_vPoints[i].x - nPatchSize,
                                                 m_vPoints[i].y - nPatchSize,
                                                 m_vPoints[i].x + nPatchSize,
                                                 m_vPoints[i].y + nPatchSize );

      if( nPatchSize != m_fcCue.params()->m_nPatchSize )
        img = img.opRescaleToWidth( 2*m_fcCue.params()->m_nPatchSize+1 );

      m_vImagePatches.push_back( img );
      m_vPointsInside.push_back( m_vPoints[i] );
    }
  }
  cout << "Number of image patches taken: " << m_vImagePatches.size() << endl;


  /*------------------------------------------------*/
  /* If desired, filter the patches with a Gaussian */
  /*------------------------------------------------*/
  if( m_fcCue.params()->m_bFilterPatches )
    for( int i=0; i < (int)m_vImagePatches.size(); i++) {
      m_vImagePatches[i] = m_vImagePatches[i].opFastGauss( 1.0 );
    }


  /*----------------------------------------*/
  /* Convert the patches to feature vectors */
  /*----------------------------------------*/
  for(int i=0; i < (int)m_vImagePatches.size(); i++) {
    m_vFeatures.push_back( m_vImagePatches[i].getData() );
  }
  
  /* set the feature type */
  m_nFeatureType = FEATURE_PATCH;
  

  /*-------------------------------*/
  /* Display the extracted patches */
  /*-------------------------------*/
  if (!process) {
    displayPatchesForBrowsing(m_vImagePatches);
  }
}


vector<Hypothesis> ISMReco::getPatchHypotheses( bool bDisplayResults )
  /*******************************************************************/
  /* Extract the object hypotheses as maxima from the Hough voting   */
  /* space and refine them using MSME (version for scale votes).     */
  /*******************************************************************/
{
  /******************************************/
  /*   Find maxima of patch voting scores   */
  /******************************************/
  vector<OpGrayImage> vImgPatchVotes;
  vector<Hypothesis> vPatchHypos = 
    m_ismReco.getPatchHypotheses ( m_vPointsInside, SIZE_VOTINGBINS,
                                   vImgPatchVotes, true );

  
  /*******************************/
  /*   Show the voting results   */
  /*******************************/
  if( bDisplayResults ) {
    vector<OpGrayImage> vHistoValues;
    vector<QImage>      vImgs;

    for( int i=0; i<(int)vImgPatchVotes.size(); i++ ) {
      OpGrayImage imgHisto = vImgPatchVotes[i]; 
        
      /* add vote image for scale i */
      vImgs.push_back( imgHisto.getQtImage() );
      vHistoValues.push_back( imgHisto );
    }

    /* add original image */
    vImgs.push_back( m_grayImg.getQtImage() );
    vHistoValues.push_back( m_grayImg );
        
    if( true ) {
      /* create a scale histogram */
      VisualHistogram hScales     ( 100, 0.0, 5.0 );
      VisualHistogram hScaleScores( 100, 0.0, 5.0 );
      vector<HoughVote> vVotes;
      float dRecoScaleMin = m_parReco.params()->m_dRecoScaleMin;
      float dRecoScaleMax = m_parReco.params()->m_dRecoScaleMax;
      
      /* get all votes in the VotingSpace */
      FeatureVector fvWindowPos( 3 );
      fvWindowPos.setValue( 0, m_grayImg.width()/2 );
      fvWindowPos.setValue( 1, m_grayImg.height()/2 );
      fvWindowPos.setValue( 2, dRecoScaleMin + (dRecoScaleMax-dRecoScaleMin)/2 );
      FeatureVector fvWindowSize( 3 );
      fvWindowSize.setValue( 0, m_grayImg.width() );
      fvWindowSize.setValue( 1, m_grayImg.height() );
      fvWindowSize.setValue( 2, dRecoScaleMax-dRecoScaleMin );
      
      vVotes = m_ismReco.getSupportingVotes_v( fvWindowPos, fvWindowSize );
      
      for( int i=0; i<(int)vVotes.size(); i++ ) {
	if(vVotes[i].getValue()>=0){
	   hScales.insertValue( vVotes[i].getCoords().at(2) );
	   hScaleScores.incrementValue( vVotes[i].getCoords().at(2),
					     vVotes[i].getValue() );
	}
      }
      QImage imgQScaleHisto; 
      hScales.drawHistogram( imgQScaleHisto );
      vImgs.push_back( imgQScaleHisto );
      vHistoValues.push_back( OpGrayImage( imgQScaleHisto ) );
      hScaleScores.drawHistogram( imgQScaleHisto );
      vImgs.push_back( imgQScaleHisto );
      vHistoValues.push_back( OpGrayImage( imgQScaleHisto ) );
    }

    /* display the images in a browser window */
    QtImgBrowser *qtHoughBrowser = new QtImgBrowser( 0, "Hough Results" ); 
    qtHoughBrowser->setGeometry( 950, 200, 300, 350 );
    qtHoughBrowser->load( vImgs, vHistoValues );
    connect( qtHoughBrowser, SIGNAL(imageClicked(int, int, int)), 
             this, SLOT(showSupportingPatches(int, int, int)) );
    
    qtHoughBrowser->show();
  }  

  return vPatchHypos;
}
  

vector<Hypothesis> ISMReco::setHypoBBox( const vector<Hypothesis> &vHypos,
                                         int nObjWidth, int nObjHeight )
{
  vector<Hypothesis> vHyposBox;
  for( int i=0; i<(int)vHypos.size(); i++ )
    if( vHypos[i].dScore > m_parReco.params()->m_dScoreThreshSingle ) {
      Hypothesis hypo = vHypos[i];

      /* set fixed bbox size */
      int width  = (int) floor(nObjWidth*hypo.dScale + 0.5);
      int height = (int) floor(nObjHeight*hypo.dScale + 0.5);
      hypo.nBoxX1 = (int)(hypo.x - width/2);
      hypo.nBoxY1 = (int)(hypo.y - height/2);
      hypo.nBoxWidth = width;
      hypo.nBoxHeight = height;

      /* adjust for different aspects (if selected) */
      if( hypo.dAspect>0.0 ) {
        if( m_parReco.params()->m_nFixObjDim==OBJDIM_WIDTH ) { // w fixed
          height = (int)round((float)width/hypo.dAspect);
        } else {                                               // h fixed
          width  = (int)round((float)height*hypo.dAspect);
        }
        hypo.nBoxX1 = (int)(hypo.x - width/2);
        hypo.nBoxY1 = (int)(hypo.y - height/2);
        hypo.nBoxWidth = width;
        hypo.nBoxHeight = height;
      }

      vHyposBox.push_back( hypo );
    }

  return vHyposBox;
}


vector<HoughVote> ISMReco::filterVotes( const Hypothesis &hypo, 
                                        const vector<HoughVote> &vVotes)
{
  if( !m_parReco.params()->m_bRecoverRotation || 
      !m_parReco.params()->m_bUseAspect )
    return vVotes;

  float dMSMESizeR = m_parReco.params()->m_dMSMESizeR*(M_PI/180.0);
  float dMinAngle  = hypo.dAngle - dMSMESizeR;
  float dMaxAngle  = hypo.dAngle + dMSMESizeR;
  float dMinAngle2 = dMinAngle - 2.0*M_PI;
  float dMaxAngle2 = dMaxAngle - 2.0*M_PI;
  float dMinAngle3 = dMinAngle + 2.0*M_PI;
  float dMaxAngle3 = dMaxAngle + 2.0*M_PI;

  float dMSMESizeA = m_parReco.params()->m_dMSMESizeA*(M_PI/180.0);
  float dAspect    = atan(hypo.dAspect);
  float dMinAspect = tan(dAspect - dMSMESizeA);
  float dMaxAspect = tan(dAspect + dMSMESizeA);

  VecVecOccurrence vvOccurrences = m_ismReco.getOccurrences();

  /* Filter the votes to the selected rotation and aspect */
  vector<HoughVote> vResults;
  for(unsigned k=0; k<vVotes.size(); k++ ) {
    int   nImgPointId = vVotes[k].getImgPointId();
    int   nClusterId  = vVotes[k].getClusterId();
    int   nOccNumber  = vVotes[k].getOccNumber(); 
    //float dWeight     = vVotes[k].getValue();
    float dAngle      = ( m_vPointsInside[nImgPointId].angle - 
                          vvOccurrences[nClusterId][nOccNumber].dAngle );
    float dBBRatio    = vvOccurrences[nClusterId][nOccNumber].dBBRatio;
    
    bool  bValid = true;
    if( m_parReco.params()->m_bRecoverRotation )
      if( !((dAngle>=dMinAngle  && dAngle<=dMaxAngle) ||
            (dAngle>=dMinAngle2 && dAngle<=dMaxAngle2) ||
            (dAngle>=dMinAngle3 && dAngle<=dMaxAngle3)) )
        bValid = false;

    if( m_parReco.params()->m_bUseAspect )
      if( !(dBBRatio>=dMinAspect && dBBRatio<=dMaxAspect) )
        bValid = false;
      
    if( bValid )
      vResults.push_back( vVotes[k] );
  }

  return vResults;
}


Hypothesis ISMReco::computeTightBBox( OpGrayImage imgSeg, 
                                      int nOffX, int nOffY )
  /* Compute a tight bounding box from the segmentation */
{
  Hypothesis result;

  int nObjHeight = m_parReco.params()->m_nObjHeight;
  Histogram hProjX( imgSeg.width(), 0, imgSeg.width()-1 );
  Histogram hProjY( imgSeg.height(), 0, imgSeg.height()-1 );
  for( int y=0; y<imgSeg.height(); y++ )
    for( int x=0; x<imgSeg.width(); x++ ) {
      hProjX.incrementValue( x, imgSeg(x,y).value() );
      hProjY.incrementValue( y, imgSeg(x,y).value() );
    }
  result.nBoxX1     = ((int)hProjX.getQuantile( 0.01, true ) + nOffX);
  result.nBoxWidth  = ((int)hProjX.getQuantile( 0.01, false ) + nOffX - 
                       result.nBoxX1);
  result.nBoxY1     = ((int)hProjY.getQuantile( 0.01, true ) + nOffY);
  result.nBoxHeight = ((int)hProjY.getQuantile( 0.01, false ) +nOffY - 
                       result.nBoxY1);

  result.x      = result.nBoxX1 + result.nBoxWidth/2;
  result.y      = result.nBoxY1 + result.nBoxHeight/2;
  result.dScale = ( (result.nBoxHeight/(float)nObjHeight) * 1.02 ); 
                   // 0.5*(result.nBoxWidth/(float)m_nObjWidth + 
                   //      result.nBoxHeight/(float)m_nObjHeight);

  return result;
}


/*---------------------------------------------------------*/
/*                   Supporting Functions                  */
/*---------------------------------------------------------*/

void ISMReco::showSupportingPatches( int page, int x, int y )
  /*******************************************************************/
  /* Show the patches supporting the hypothesis shown in cell (x,y)  */
  /* of the Hough accumulator histogram visible at page <page> of    */
  /* the result QImgBrowser window.                                  */
  /*******************************************************************/
{
  float dRecoScaleMin = m_parReco.params()->m_dRecoScaleMin;
  float dRecoScaleMax = m_parReco.params()->m_dRecoScaleMax;
  float dMSMESizeS    = m_parReco.params()->m_dMSMESizeS;
  int   nObjWidth     = m_parReco.params()->m_nObjWidth;
  int   nObjHeight    = m_parReco.params()->m_nObjHeight;

  int   nScaleSteps= (int)floor((dRecoScaleMax - dRecoScaleMin)/
                                dMSMESizeS) + 1;
  float dScaleMin  = dRecoScaleMin - dMSMESizeS/2.0;
  float dScaleMax  = dRecoScaleMax + dMSMESizeS/2.0;
  float dScaleRange= dScaleMax - dScaleMin;

  float dCellSizeX = (float)m_grayImg.width() / (float)(m_grayImg.width() /
                                                        SIZE_VOTINGBINS);
  float dCellSizeY = (float)m_grayImg.height() / (float)(m_grayImg.height() /
                                                         SIZE_VOTINGBINS);
  float dCellSizeS = ( dScaleRange / (float)nScaleSteps );

  FeatureVector fvWindowPos( 3 );
  fvWindowPos.setValue( 0, (x+0.5)*dCellSizeX );
  fvWindowPos.setValue( 1, (y+0.5)*dCellSizeY );
  fvWindowPos.setValue( 2, dScaleMin+(page+0.5)*dCellSizeS );

  cout << "    Showing hypothesis support for (" << fvWindowPos.at(0)
       << "," << fvWindowPos.at(1) << "," << fvWindowPos.at(2) << ")..." 
       << endl;

  showSupportingPatches( fvWindowPos, m_bMapsOnManually );

  /* create a single hypothesis for this position */
  /* (in case it should be refined).              */
  Hypothesis hypo;
  hypo.x      = (int)floor(fvWindowPos.at(0) + 0.5);
  hypo.y      = (int)floor(fvWindowPos.at(1) + 0.5);
  hypo.dScale = fvWindowPos.at(2);
  hypo.nBoxX1 = (int)floor(hypo.x - 0.5*(nObjWidth*hypo.dScale) +0.5);
  hypo.nBoxY1 = (int)floor(hypo.y - 0.5*(nObjHeight*hypo.dScale) +0.5);
  hypo.nBoxWidth = (int)floor(nObjWidth*hypo.dScale + 0.5);
  hypo.nBoxHeight= (int)floor(nObjHeight*hypo.dScale + 0.5);
  hypo.dScore    = -1.0;
  hypo.dScoreMDL = -1.0;
  hypo.nCategory = -1;
  hypo.nPose     = -1;
  hypo.nTemplateId = -1;
  m_vHyposSingle.clear();
  m_vHyposSingle.push_back( hypo );

  /* draw a rectangle with the selected object scale */
  QColor qcol( 0, 0, 255 );
  int width  = (int) floor(nObjWidth*fvWindowPos.at(2));
  int height = (int) floor(nObjHeight*fvWindowPos.at(2));
  rsSourceImg->drawRect( (int)fvWindowPos.at(0) - width/2,
                         (int)fvWindowPos.at(1) - height/2,
                         width, height, qcol, false );

  qApp->processEvents();
  cout << "    done." << endl;
}


void ISMReco::showSupportingPatches( FeatureVector fvWindowPos, 
                                     bool bDrawMaps )
  /*******************************************************************/
  /* Show the patches supporting the hypothesis described by the     */
  /* Hough window around fvWindowPos.                                */
  /*******************************************************************/
{
  /********************************/
  /*   Get the supporting votes   */
  /********************************/
  vector<HoughVote> vSupporting;

  vSupporting = m_ismReco.getSupportingVotes_v( fvWindowPos );

  m_vActiveVotes = vSupporting;
  cout << "      #Active votes: " << m_vActiveVotes.size() << endl;

//  displayVotePatches( vSupporting, bDrawMaps, m_bDrawConfidence );
  cout << "      #Patches have been displayed" << endl;      
/* draw a segmentation and compute the SumPFig score
  OpGrayImage imgSeg;
  OpGrayImage imgPFig;
  OpGrayImage imgPGnd;
  m_ismReco.drawSegmentation( vSupporting, m_vPointsInside, m_fcCue, 
                              imgPFig, imgPGnd, imgSeg, true );
  
  float dFigArea = imgSeg.getSum()/255.0;
  float dSumPFig = imgPFig.getSum();
  cout << "      FigArea=" << dFigArea << ", Sum(pfig)=" << dSumPFig << endl;
*/
}


OpGrayImage ISMReco::drawMatchedPatches()
  /*******************************************************************/
  /* Draw the patches that were matched to the codebook. For each    */
  /* patch, the nearest match is displayed.                          */
  /*******************************************************************/
{
  float dBackVal;
  if ( m_bMapsOnManually )
    dBackVal = 200.0;
  else
    dBackVal = 255.0;
  
  /* prepare the result image */
  OpGrayImage imgResult( m_resultImg.width(), m_resultImg.height() );
  for( int y=0; y<m_resultImg.height(); y++ )
    for( int x=0; x<m_resultImg.width(); x++ )
      imgResult(x,y) = dBackVal;

  vector<int> vClustersTaken;
  //vector<OpGrayImage> vClusterPatches = m_cbCodebook.getClusterPatches();
  int nTotalClusters = 0;
  for( int i=0; i <(int)m_vPointsInside.size(); i++ ) {
    /* draw patch if it has a good similarity, else reject it */
    if( m_vNearestNeighborSim[i]>m_parMatching.params()->m_dRejectionThresh ) {
      int nClusterId =  m_vNearestNeighbor[i];
      int nDetectedSize = (int) floor(m_vPointsInside[i].scale*
                                      m_fcCue.params()->m_dScaleFactor + 0.5);
      int nTargetSize = 2*nDetectedSize+1; 

      vClustersTaken.push_back( nClusterId );
      nTotalClusters++;
 
      /* prepare the information to draw: cluster or segm. map */
      int imgsize    = 2*m_fcCue.params()->m_nPatchSize+1;
      OpGrayImage imgPatch;
      //imgCluster.loadFromData( imgsize, imgsize, 
      //                         m_vClusters[ nClusterId ].getData() ); 
      imgPatch = m_cbCodebook.getClusterPatch( nClusterId );
      
      //cout << "  Processing patch " << i << "..."  << endl;
      //cout << "    (scale=" << m_vPointsInside[i].scale
      //     << ", l1=" << m_vPointsInside[i].l1
      //     << ", l2=" << m_vPointsInside[i].l2 << ")" << endl;
      /* rescale the matched cluster to the detected size */
      if( m_vPointsInside[i].l1 == m_vPointsInside[i].l2 ) {
        /*-=-=-=-=-=-=-=-=-*/
        /* Circular region */
        /*-=-=-=-=-=-=-=-=-*/
        if( nTargetSize != imgsize )
          imgPatch = imgPatch.opRescaleToWidth( nTargetSize );

      } else {
          /*-=-=-=-=-=-=-=-=-=-*/
          /* Elliptical region */
          /*-=-=-=-=-=-=-=-=-=-*/
          //cout << "    Deforming patch..." << endl;
          imgPatch = m_ismReco.createAffinePatch( imgPatch, m_vPointsInside[i],
                                                  m_fcCue );
          nTargetSize = imgPatch.width();
        }
      //cout << "    Drawing patch..." << endl;

      /* copy the rescaled cluster to the result image */
      int posx = m_vPointsInside[i].x;
      int posy = m_vPointsInside[i].y;
      int minx = max( 0, posx - nDetectedSize );
      int miny = max( 0, posy - nDetectedSize );
      int maxx = min( imgResult.width(),  posx + nTargetSize );
      int maxy = min( imgResult.height(), posy + nTargetSize );
      int minxx= nTargetSize - min( nTargetSize, posx ); 
      int minyy= nTargetSize - min( nTargetSize, posy ); 
      int maxxx= min( nTargetSize, maxx-posx ); 
      int maxyy= min( nTargetSize, maxy-posy );
      /* draw the matched patch */
      for( int y=miny, yy=minyy; (y<maxy) && (yy<maxyy); y++, yy++ )
        for( int x=minx, xx=minxx; (x<maxx) && (xx<maxxx); x++, xx++ ) {
          float dPatchValRaw = imgPatch(xx,yy).value();
          if( dPatchValRaw >= 0.0 )
            imgResult(x,y)  = dPatchValRaw;
        }
      
    }
  }
  cout << "  done. Drawn " << nTotalClusters << " patches." << endl;
  
  return imgResult;
}


void ISMReco::displayVotePatches( vector<HoughVote> vVotes, bool bDrawMaps,
                                  bool bDrawConfidence, bool bDrawFigure )
  /*******************************************************************/
  /* Shortcut for drawing the support of the given votes and direct- */
  /* ly displaying it in the user interface.                         */
  /*******************************************************************/
{
  /* draw the vote patches into an image */
  OpGrayImage imgResult = drawVotePatches( vVotes, bDrawMaps, bDrawConfidence,
                                           bDrawFigure );

  /* convert back to OpGrayImage and draw it */
  m_resultImg  = imgResult;
  m_qresultImg = m_resultImg.getQtImage();

  rsResultImg->loadImage( m_qresultImg, m_resultImg );
  rsResultImg->display();
}


OpGrayImage ISMReco::drawVotePatches( vector<HoughVote> vVotes, bool bDrawMaps,
                                      bool bDrawConfidence, bool bDrawFigure,
                                      bool bBackgroundZero )
  /*******************************************************************/
  /* Shortcut for drawing the support of the given votes and direct- */
  /* ly displaying it in the user interface.                         */
  /*******************************************************************/
{
  /* set the drawing style */
  int nDrawStyle;
  if( !bDrawMaps )
    nDrawStyle = ISM::DRAW_SUPPORT;
  else if( !bDrawConfidence )
    nDrawStyle = ISM::DRAW_SEGMENT;
  else if( bDrawFigure )
    nDrawStyle = ISM::DRAW_PFIG;
  else 
    nDrawStyle = ISM::DRAW_PGND;

  /* draw the vote patches into an image */
  OpGrayImage imgResult( m_grayImg.width(), m_grayImg.height() );
  vector<OpGrayImage> vClusterPatches = m_cbCodebook.getClusterPatches();
  if( nDrawStyle!=ISM::DRAW_SUPPORT || m_bUsePatches )
    imgResult = m_ismReco.drawVotePatches( vVotes, m_vPointsInside, 
                                           vClusterPatches,
                                           m_fcCue, nDrawStyle, 
                                           bBackgroundZero );

  return imgResult;
}


void ISMReco::displayVoteConfidence( vector<HoughVote> vVotes, 
                                     bool bDrawMaps )
  /*******************************************************************/
  /* Shortcut for drawing the p(figure) probability map of the given */
  /* votes and directly displaying it in the user interface.         */
  /*******************************************************************/
{
  displayVotePatches( vVotes, bDrawMaps, true );
}


void ISMReco::displayScaleFootprint()
  /*******************************************************************/
  /* Display a scale footprint of the current interest point detec-  */
  /* tor. That is, show a histogram of the scales on which interest  */
  /* points were found.                                              */
  /*******************************************************************/
{
  /* initialize scale histograms */
  VisualHistogram hPointScales( 100, 1.0, 9.0 );
  VisualHistogram hOccScales  ( 100, 1.0, 9.0 );

  /* initialize image vectors */
  vector<QImage> vQImgs;
  QImage imgQScaleHisto; 

  /* Get the occurrences */
  VecVecOccurrence vvOccurrences = m_ismReco.getOccurrences();

  /* create a scale footprint for the interest points */
  for( int i=0; i<(int)m_vPointsInside.size(); i++ )
    hPointScales.insertValue( m_vPointsInside[i].scale );
  hPointScales.drawHistogram( imgQScaleHisto );
  vQImgs.push_back( imgQScaleHisto );

  /* create a scale footprint for the occurrences */
  for( int i=0; i<(int)vvOccurrences.size(); i++ )
    for( int j=0; j<(int)vvOccurrences[i].size(); j++ )
      hOccScales.insertValue( vvOccurrences[i][j].dScale );
  hOccScales.drawHistogram( imgQScaleHisto );
  vQImgs.push_back( imgQScaleHisto );

  /* display the footprints in a browser window */
  QtImgBrowser *qtBrowser = new QtImgBrowser( 0, "Scale Footprints" ); 
  qtBrowser->setGeometry( 950, 200, 300, 350 );
  qtBrowser->load( vQImgs );
  
  qtBrowser->show();  
}


int ISMReco::transformPoint( InterestPoint &ipt )
  /*******************************************************************/
  /* Support function: Transform a patch point to the vector repre-  */
  /* senting the result image.                                       */
  /*******************************************************************/
{
  int pos;
  pos = ( ipt.y * m_qresultImg.width() );
  pos += ipt.x;
  return pos;
}


int  ISMReco::transformPoint( int w, int h )
  /*******************************************************************/
  /* Support function: Transform patch coordinates to the correspon- */
  /* ding vector index.                                              */
  /*******************************************************************/
{
  int pos;
  pos = h * m_qresultImg.width();
  pos += w;
  return pos;
}


float ISMReco::computeBoundingBoxOverlap( Hypothesis h1, Hypothesis h2 )
  /*******************************************************************/
  /* Compute the overlap between two bounding boxes with the         */
  /* intersection criterion.                                         */
  /*******************************************************************/
{
  int common_x1 = max( h1.nBoxX1, h2.nBoxX1 );
  int common_y1 = max( h1.nBoxY1, h2.nBoxY1 );
  int common_x2 = min( h1.nBoxX1+h1.nBoxWidth,  h2.nBoxX1+h2.nBoxWidth );
  int common_y2 = min( h1.nBoxY1+h1.nBoxHeight, h2.nBoxY1+h2.nBoxHeight );

  float area1 = (float)h1.nBoxWidth * h1.nBoxHeight;
  float area2 = (float)h2.nBoxWidth * h2.nBoxHeight;
  float common_area;
  if( (common_x2 > common_x1) && (common_y2 > common_y1) )
    common_area = (common_x2-common_x1)*(common_y2-common_y1);
  else
    common_area = 0.0;

  float inter = 0.5*(common_area/area1 + common_area/area2);
  return inter;
}


/*---------------------------------------------------------*/
/*                        Test Series                      */
/*---------------------------------------------------------*/

void ISMReco::performUIUCTestSeries()
  /*******************************************************************/
  /* Perform a test series on the UIUC car database and write a      */
  /* protocol to disk in a file format compatible with Agarwal &     */
  /* Roth's evaluation tool.                                         */
  /*******************************************************************/
{ 
  /****************************/
  /*  Open the result files   */
  /****************************/
  QString qsDBDir = 
    QFileDialog::getExistingDirectory( DIR_UIUC_DATA.c_str(), 
                                       this, "save1", 
                                       "Select UIUC database directory" );

  if( qsDBDir == "" ) {
    cerr << "ERROR: No database directory selected!" << endl;
    return;
  }

  QString qsResultFile1 = 
    QFileDialog::getSaveFileName( DIR_RESULTS.c_str(), 
                                  "Result files (*.txt);;All files (*.*)",  
                                  this, "save1", 
                                  "Select Result File for Single Voting" );

  ofstream ofSingle( qsResultFile1 );
  if( ofSingle == 0 ) {
    cerr << "ERROR: Couldn't open file " << qsResultFile1 << "!" << endl;
    return;
  }

  QString qsResultFile2 = 
    QFileDialog::getSaveFileName( DIR_RESULTS.c_str(), 
                                  "Result files (*.txt);;All files (*.*)",  
                                  this, "save1", 
                                  "Select Result File for Full Scores" );

  ofstream ofScore( qsResultFile2 );
  if( ofScore == 0 ) {
    cerr << "ERROR: Couldn't open file " << qsResultFile2 << "!" << endl;
    return;
  }


  /***********************************/
  /*   Prepare the image file list   */
  /***********************************/
  vector<string> vImgNames;
  for( int i=0; i<NUM_UIUC_IMAGES; i++ ) {
  char sNum[5];
  sprintf(sNum,"%d", i);

    string sName = string(qsDBDir.latin1()) + "/" + "test-" + sNum + ".png";
    vImgNames.push_back( sName );
  }

  /*******************************/
  /*   Process all test images   */
  /*******************************/
  vector< vector<Hypothesis> > vvHypoSingle  ( vImgNames.size() );

  /* process all test images */
  for( int i=m_nUIUCFrom; i<(int)vImgNames.size(); i++ ) {
    cout << "  Processing image " << i+1 << " of " << vImgNames.size() 
         << "..." << endl;
    cout << endl;
    string sFileName = vImgNames[i];
    processTestImgUIUC( sFileName.c_str(), i,
                        vvHypoSingle[i], 
                        ofSingle, ofScore,
                        false );
    
    /* free some memory */
    m_vActiveVotes.clear();
    m_vHyposSingle.clear();
  }


  /******************************/
  /*   Close the result files   */
  /******************************/
  ofSingle.close();
  ofScore.close();

  cout << "================================" << endl;
}


void ISMReco::performIDLTestSeries()
  /*******************************************************************/
  /* Perform a test series from an experiment file in the idl for-   */
  /* mat.                                                            */
  /*******************************************************************/
{ 
  /********************************/
  /*   Open the experiment file   */
  /********************************/
  QString qsExpFile = 
    QFileDialog::getOpenFileName( DIR_IMAGES.c_str(), 
                                  "Experiment files (*.idl);;All files (*.*)",
                                  this, "save1", 
                                  "Select Experiment File (IDL)" );
  if( qsExpFile == "" ) {
    cerr << "ERROR: No experiment file selected!" << endl;
    return;
  }
  
  /*****************************/
  /*   Open the result files   */
  /*****************************/
  QString qsResultFile1 = 
    QFileDialog::getSaveFileName( DIR_RESULTS.c_str(), 
                                  "Result files (*.idl);;All files (*.*)",  
                                  this, "save1", 
                                  "Select Result File for Initial Voting" );

  ofstream ofInitial( qsResultFile1 );
  if( ofInitial == 0 ) {
    cerr << "ERROR: Couldn't open file " << qsResultFile1 << "!" << endl;
    return;
  }
  ofInitial.close();

  QString qsResultFile2 = 
    QFileDialog::getSaveFileName( qsResultFile1, 
                                  "Result files (*.idl);;All files (*.*)",  
                                  this, "save1", 
                                  "Select Result File for Tight BBoxes" );

  ofstream ofRefined( qsResultFile2 );
  if( ofRefined == 0 ) {
    cerr << "ERROR: Couldn't open file " << qsResultFile2 << "!" << endl;
    return;
  }
  ofRefined.close();
 

  /********************************/
  /*   Load the experiment file   */
  /********************************/
  ImgDescrList idlExperiment( qsExpFile.latin1() );

  /* and make two copies for the results */
  ImgDescrList idlInitial( idlExperiment );
  ImgDescrList idlRefined( idlExperiment );

  /* extract the path from the idl file name */
  string sFileName( qsExpFile.latin1() );
  string sPath;
  int pos = sFileName.rfind( "/" );
  if( pos != (int)string::npos )
    sPath = sFileName.substr( 0, pos + 1 );


  /*******************************/
  /*   Process all test images   */
  /*******************************/
  vector< vector<Hypothesis> > vvHypoSingle  ( idlExperiment.size() );

  cout << "    Debugging info for idlExperiment:" << endl;
  idlExperiment.print();

  /* process all test images */
  for( int i=0; i<idlExperiment.size(); i++ ) {
    cout << "  Processing image " << i+1 << " of " << idlExperiment.size() 
         << "..." << endl;
    cout << endl;
    string sFileName = sPath + idlExperiment[i].sName;
    idlInitial[i].sName = sFileName;
    idlRefined[i].sName = sFileName;

    processTestImgIDL( sFileName.c_str(), i,
                       vvHypoSingle[i], 
                       idlInitial[i], idlRefined[i],
                       false );
    
    /* free some memory */
    m_vActiveVotes.clear();
    m_vHyposSingle.clear();
  }


  /*****************************/
  /*   Save the result files   */
  /*****************************/
  idlInitial.save( qsResultFile1.latin1() );
  idlRefined.save( qsResultFile2.latin1() );

  cout << "================================" << endl;
}


void ISMReco::processImageSeries()
  /*******************************************************************/
  /* Process a series of images (specified by an experiment file, as */
  /* described below) and write result hypotheses and segmentations  */
  /* to disk for every image.                                        */
  /*******************************************************************/
{ 
  QString qsFileName = 
    QFileDialog::getOpenFileName( DIR_EXPERIMENTS.c_str(), 
                                  "Experiment files (*.txt);;All files (*.*)",
                                  this, "testseries", 
                                  "Load 'Test series' file");
  if ( qsFileName.isEmpty() )
    return;
  
  QString qsSaveDirName = 
    QFileDialog::getExistingDirectory( DIR_RESULTS.c_str(), 
                                       this, "testseries-savedir", 
                                       "Specify directory for result files");
  if ( qsSaveDirName.isEmpty() )
    return;
  
  /********************************/
  /*   Load the experiment file   */
  /********************************/
  /* (with image names and annotations) */
  vector<string>               vImgNames;
  vector< vector<Hypothesis> > vvAnnots;

  loadExperimentFile( qsFileName, vImgNames, vvAnnots );

  /* extract the path from the file name */
  string sFileName( qsFileName.latin1() );
  string sPath;
  int pos = sFileName.rfind( "/" );
  if( pos != (int)string::npos )
    sPath = sFileName.substr( 0, pos + 1 );

  /*******************************************/
  /*   Print ground truth for verification   */
  /*******************************************/
  cout << "  Path='" << sPath << "'." << endl;
  for( int i=0; i<(int)vImgNames.size(); i++ ) {
    cout << "  " << i+1 << ". file='" << vImgNames[i] << "'";

    for( int j=0; j<(int)vvAnnots[i].size(); j++ )
      cout << ", Categ=" << vvAnnots[i][j].nCategory << " at (" 
           << vvAnnots[i][j].x << "," << vvAnnots[i][j].y << ")";
    cout << endl;
  }
  cout << endl;

  /****************************/
  /*  Open the result files   */
  /****************************/
  QString qsResultFile1 = 
    QFileDialog::getSaveFileName( DIR_RESULTS.c_str(), 
                                  "Result files (*.tab);;All files (*.*)",  
                                  this, "save1", 
                                  "Select Result File for Single Voting" );

  ofstream ofSingle( qsResultFile1 );
  if( ofSingle == 0 ) {
    cerr << "ERROR: Couldn't open file " << qsResultFile1 << "!" << endl;
    return;
  }

  QString qsResultFile3;
  ofstream ofDetect;
  if( m_bWriteDetections ) {
    qsResultFile3 = 
      QFileDialog::getSaveFileName( DIR_RESULTS.c_str(), 
                                    "Result files (*.tab);;All files (*.*)",  
                                    this, "save1", 
                                    "Select Protocol File for Detections" );
    
    ofDetect.open( qsResultFile3 );
    if( ofDetect == 0 ) {
      cerr << "ERROR: Couldn't open file " << qsResultFile3 << "!" << endl;
      return;
    }
  }


  /*******************************/
  /*   Process all test images   */
  /*******************************/
  for( int i=0; i<(int)vImgNames.size(); i++ ) {
    cout << "  Processing image " << i+1 << " of " << vImgNames.size() 
         << "..." << endl;
    cout << endl;
    string sFileName = sPath + vImgNames[i];
    processTestImgStd( sFileName.c_str(), i, 
                       m_vHyposSingle, ofSingle, false );

    /*------------------------------*/
    /* Write the detection protocol */
    /*------------------------------*/
    if( m_bWriteDetections ) {
      ofDetect << sFileName << endl;
      ofDetect << m_vHyposSingle.size() << endl;
    }
    
    /*------------------------------------------------*/
    /* create the segmentation for the top hypotheses */
    /*------------------------------------------------*/
    /* prepare the file name */
    int posDir = sFileName.rfind( '/', string::npos );
    string sSaveFileName;
    if( posDir != (int)string::npos )
      sSaveFileName = sFileName.substr( posDir+1, sFileName.length()-posDir-1);
    int posDot = sSaveFileName.rfind( '.', string::npos );
    if( posDot != (int)string::npos )
      sSaveFileName.erase( posDot, string::npos );
    QString qsSaveFileName = sSaveFileName.c_str();
    
    /*--------------------------------*/
    /* Save the image with detections */
    /*--------------------------------*/
    QString qsExtension;
    qsExtension = "-detections.png";
    rsSourceImg->getImage().save( qsSaveDirName + "/" + qsSaveFileName + 
                                  qsExtension, "PNG" );

    FeatureVector fvWindowPos( 3 );
    OpGrayImage imgAllSupport( m_grayImg.width(), m_grayImg.height() );
    OpGrayImage imgAllSegment( m_grayImg.width(), m_grayImg.height() );
    OpGrayImage imgTemp( m_grayImg.width(), m_grayImg.height() );
    vector<OpGrayImage> vImgSupport;
    vector<OpGrayImage> vImgSegment;
    vector<OpGrayImage> vImgPFig;
    vector<OpGrayImage> vImgPGnd;
    vector<OpGrayImage> vImgVisualize;
    vector<float> vFigArea( m_vHyposSingle.size() );
    vector<float> vSumPFig( m_vHyposSingle.size() );
    vector<HoughVote> vAllSupporting;
    for( int j=0; j<(int)m_vHyposSingle.size(); j++ ) {
      cout << "  Processing hypothesis " << j+1 << " of " 
           << m_vHyposSingle.size() << "..." << endl;

      /*------------------------------*/
      /* Write the detection protocol */
      /*------------------------------*/
      if( m_bWriteDetections ) {
        ofDetect << m_vHyposSingle[j].dScore << " "
                 << m_vHyposSingle[j].dScoreMDL << " "
                 << m_vHyposSingle[j].x << " "
                 << m_vHyposSingle[j].y << " "
                 << m_vHyposSingle[j].dScale << " "
                 << m_vHyposSingle[j].nBoxX1 << " " 
                 << m_vHyposSingle[j].nBoxY1 << " " 
                 << m_vHyposSingle[j].nBoxWidth << " " 
                 << m_vHyposSingle[j].nBoxHeight << " "
                 << m_vHyposSingle[j].nTemplateId << endl;
      }

      /* recover the hypothesis positions */
      fvWindowPos.setValue(0, m_vHyposSingle[j].x );
      fvWindowPos.setValue(1, m_vHyposSingle[j].y );
      fvWindowPos.setValue(2, m_vHyposSingle[j].dScale );

      vector<HoughVote> vSupporting;
      vSupporting = m_ismReco.getSupportingVotes_v( fvWindowPos );

      /*-----------------------------*/
      /* Draw the hypothesis support */
      /*-----------------------------*/
      /* create one support image with gray background */
     // cout << "    Drawing support image..." << endl;
     // OpGrayImage imgSupport = drawVotePatches( vSupporting, 
     //                                           m_bMapsOnManually, 
     //                                           m_bDrawConfidence );

      /* and one with zero background */
     // cout << "    Drawing support image with zero background..." << endl;
      //vImgSupport.push_back( drawVotePatches( vSupporting, 
      //                                        m_bMapsOnManually, 
      //                                        m_bDrawConfidence, true, true ));

      //showSupportingPatches( fvWindowPos, m_bMapsOnManually );

      /*-----------------------*/
      /* Draw the segmentation */
      /*-----------------------*/
      /* set the necessary flags */
     // bool bMapsOnManually = m_bMapsOnManually;
      //slotSetMapsOnOff( 1 );

      /* create one segmentation with gray background */
      //cout << "    Drawing segmentation image..." << endl;
      //OpGrayImage imgSegment = drawVotePatches( vSupporting,true,false );

      /* and one with zero background */
      //cout << "    Drawing segmentation image with zero background..." << endl;
      //vImgSegment.push_back(drawVotePatches(vSupporting,true,false,true,true));
      //cout << "    Drawing pfig image with zero background..." << endl;
      //vImgPFig.push_back( drawVotePatches( vSupporting,true, true,true,true));

      //cout << "    Drawing pgnd image with zero background..." << endl;
      //vImgPGnd.push_back( drawVotePatches( vSupporting, true,true,false,true));

      /* reset the flags to their initial values */
     // slotSetMapsOnOff( bMapsOnManually );
      qApp->processEvents();

      /*-----------------------------------*/
      /* Save the individual segmentations */
      /*-----------------------------------*/
     // cout << "    Saving segmentation images..." << endl;      
      //QString qsExtension;
      //qsExtension.sprintf("-detect%02d", j );
      //m_vActiveVotes = vSupporting;
      //saveSegmentationsMatlab( qsSaveDirName + "/" + qsSaveFileName + 
      //                         qsExtension );
      //QString qsMatlabFName = ( qsSaveDirName + "/" + qsSaveFileName + 
      //                          qsExtension );
        
      /* set the necessary flags */
      //bMapsOnManually = m_bMapsOnManually;
      //slotSetMapsOnOff( 1 );
      
      /* generate the segmentation */
      //displayVotePatches( vSupporting, true, false );
      //saveImageAscii( m_resultImg, (qsMatlabFName + "-seg.tab").latin1() );
      //saveImage( m_resultImg, (qsMatlabFName + "-seg.png").latin1() );
      
      /* generate the probabilities for "figure" */
      //displayVotePatches( vSupporting, true, true, true );
      //saveImageAscii( m_resultImg, (qsMatlabFName + "-pfig.tab").latin1() );
      //saveImage( m_resultImg, (qsMatlabFName + "-pfig.png").latin1() );
      
      /* generate the probabilities for "ground" */
      //displayVotePatches( vSupporting, true, true, false );
      //saveImageAscii( m_resultImg, (qsMatlabFName + "-pgnd.tab").latin1() );
      //saveImage( m_resultImg, (qsMatlabFName + "-pgnd.png").latin1() );
      
      /* reset the flags top their initial values */
     // slotSetMapsOnOff( bMapsOnManually );


      /*---------------------------*/
      /* Prepare a "scene picture" */
      /*---------------------------*/
      /* save the supporting votes for a complete result image */
      //cout << "    Appending supporting votes..." << endl;
      //vAllSupporting.insert( vAllSupporting.end(), vSupporting.begin(), 
      //                       vSupporting.end() );
    }
    
    /*---------------------------*/
    /* Save the "scene pictures" */
    /*---------------------------*/
    /* create a scene segmentation */
/*    OpGrayImage imgDummy;
    m_ismReco.drawSegmentation( vAllSupporting, m_vPointsInside, m_fcCue, 
                                imgDummy, imgDummy, imgAllSegment, true );

    saveImage( imgAllSegment, string((qsSaveDirName + "/" + qsSaveFileName + 
                                      "-scene-segment.png" ).latin1()) );    
*/
    /* and a second scene segmentation with the max operator */
  /*  OpGrayImage imgSegMax( imgAllSegment.width(), imgAllSegment.height() );
    for( int y=0; y<imgSegMax.height(); y++ )
      for( int x=0; x<imgSegMax.width(); x++ ) {
        float dMax = 0.0;
        for( int k=0; k<(int)vImgSegment.size(); k++ )
          if( vImgSegment[k](x,y).value() > dMax ) 
            dMax = vImgSegment[k](x,y).value();
        imgSegMax(x,y) = dMax;
      }

    saveImage( imgSegMax, string((qsSaveDirName + "/" + qsSaveFileName + 
                                  "-scene-seg-max.png" ).latin1()) );    
*/


    /*---------------------------*/
    /*   Refine the hypotheses   */
    /*---------------------------*/
   /* if( m_bRefineHypothesis && (m_vHyposSingle.size()>0) ) {
      refineHypotheses( false );
      
      saveImage( m_resultImg, string((qsSaveDirName + "/" + qsSaveFileName + 
                                      "-scene-refinedseg.png" ).latin1()) );
      saveSegmentationsMatlab( qsSaveDirName + "/" + qsSaveFileName + 
                               "-scene-refinedseg.tab" );
    }
*/
  }


  /******************************/
  /*   Close the result files   */
  /******************************/
  ofSingle.close();
  if( m_bWriteDetections )
    ofDetect.close();
}


void ISMReco::loadExperimentFile( QString qsFileName, 
                                  vector<string> &vImgNames, 
                                  vector< vector<Hypothesis> > &vvAnnots )
  /*******************************************************************/
  /* Read in an experiment file containing a list of images to be    */
  /* processed.                                                      */
  /*******************************************************************/
{
  cout << "ISMReco::loadExperimentFile() called." << endl;

  ifstream ifile( qsFileName.latin1() );
  if ( !ifile ) {
    cerr << "  No corresponding experiment file (*.txt) found." << endl;
    return;
  }
  
  vImgNames.clear();
  vvAnnots.clear();
  vector<Hypothesis> tmp;
  int nCountImgs = 0;

  while( ifile.peek() != EOF ) {
    string line;
    getline(ifile, line );
    
    /* process the current line */
    cout << "  Processing line " << nCountImgs << "..." << endl;
    vector<string> vTokens = extractListItems( line );
    cout << "    found " << vTokens.size() << " entries in line... " << endl;
    
    if( (vTokens.size() < 1) || (vTokens[0].empty()) )
      continue;
    else {
      cout << "    found image name:'" << vTokens[0] << "'." << endl;
      vImgNames.push_back( vTokens[0] );
      nCountImgs++;

      vvAnnots.push_back( tmp );

      if( vTokens.size() < 6 ) // no annotations
        continue;

      cout << "    Preparing Annotations...." << endl;
      /* extract the annotations */
      int nCount = 0;
      while( (int)vTokens.size() >= 1+(nCount+1)*5 ) {
        cout << "    Extracting Annotation " << nCount << "...." << endl;
        Hypothesis newAnnot;
        
        int nCategory = atoi(vTokens[1+nCount*5 + 0].c_str());
        int nPosX1    = atoi(vTokens[1+nCount*5 + 1].c_str());
        int nPosY1    = atoi(vTokens[1+nCount*5 + 2].c_str());
        int nWidth    = atoi(vTokens[1+nCount*5 + 3].c_str());
        int nHeight   = atoi(vTokens[1+nCount*5 + 4].c_str());
      
        newAnnot.nBoxX1     = nPosX1;
        newAnnot.nBoxY1     = nPosY1;
        newAnnot.nBoxWidth  = nWidth;
        newAnnot.nBoxHeight = nHeight;

        newAnnot.x = nPosX1 + nWidth/2;
        newAnnot.y = nPosY1 + nHeight/2;
        newAnnot.dScore    = -1.0;
        newAnnot.nCategory = nCategory;
        newAnnot.nPose     = -1;
        vvAnnots[nCountImgs-1].push_back( newAnnot );
        nCount++;
      }
    }
  }
  cout << "  found " << nCountImgs << " entries." << endl;
  
  cout << "ISMReco::loadExperimentFile() done." << endl;  
}
